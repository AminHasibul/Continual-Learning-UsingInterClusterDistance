{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "V6E1",
      "collapsed_sections": [
        "Hv6F90hqhXDF",
        "m_1AAwnQho4d",
        "bVD7dP18zJ7Y",
        "AB_bzMwni0ly",
        "RvumdKPrqLcH",
        "lfAAS1mVfxnj"
      ],
      "authorship_tag": "ABX9TyNDmroXKLjsPNov5jK+boP4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/AminHasibul/Continual-Learning-/blob/main/Solving_Catastrophic_fogetting_for_continual_learning_using_custom_ResNET_and_ICF.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Core framework"
      ],
      "metadata": {
        "id": "z4MvD5XMhWcU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install avalanche-lib --quiet"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rkN9VqyuipFI",
        "outputId": "aa04b5ee-53a0-4b7f-87ea-62fe6d7be572"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m134.2/134.2 kB\u001b[0m \u001b[31m7.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m993.4/993.4 kB\u001b[0m \u001b[31m43.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.5/5.5 MB\u001b[0m \u001b[31m186.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m119.7/119.7 kB\u001b[0m \u001b[31m13.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m585.2/585.2 kB\u001b[0m \u001b[31m44.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m981.9/981.9 kB\u001b[0m \u001b[31m75.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m22.2/22.2 MB\u001b[0m \u001b[31m129.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m208.2/208.2 kB\u001b[0m \u001b[31m21.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m356.7/356.7 kB\u001b[0m \u001b[31m32.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.6/6.6 MB\u001b[0m \u001b[31m158.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m224.5/224.5 kB\u001b[0m \u001b[31m24.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m92.0/92.0 kB\u001b[0m \u001b[31m10.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m87.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.6/13.6 MB\u001b[0m \u001b[31m113.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m594.5/594.5 kB\u001b[0m \u001b[31m53.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m220.1/220.1 kB\u001b[0m \u001b[31m24.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.8/62.8 kB\u001b[0m \u001b[31m6.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.3/2.3 MB\u001b[0m \u001b[31m102.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m172.4/172.4 kB\u001b[0m \u001b[31m18.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m345.3/345.3 kB\u001b[0m \u001b[31m31.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.1/2.1 MB\u001b[0m \u001b[31m79.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m99.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.4/1.4 MB\u001b[0m \u001b[31m77.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m548.4/548.4 kB\u001b[0m \u001b[31m36.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.4/10.4 MB\u001b[0m \u001b[31m145.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m166.5/166.5 kB\u001b[0m \u001b[31m20.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Building wheel for gputil (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cjhTBTg9hD1V"
      },
      "outputs": [],
      "source": [
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Datasets & transforms"
      ],
      "metadata": {
        "id": "Hv6F90hqhXDF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "from torch.utils.data import DataLoader, Subset\n",
        "import torchvision.datasets as datasets\n",
        "import torchvision.transforms as transforms\n"
      ],
      "metadata": {
        "id": "uEcwG8uKhXzL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "# Continual‐learning library"
      ],
      "metadata": {
        "id": "XuhhLo6Jhkft"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Avalanche version:\", __import__('avalanche').__version__)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hMmFe-LXiqj2",
        "outputId": "2d3d94f6-7459-46af-ed7b-297a098a7e0c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Avalanche version: 0.6.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "from avalanche.benchmarks import SplitCIFAR10, nc_benchmark\n",
        "from avalanche.training.supervised import Naive, EWC\n",
        "from avalanche.training.plugins import EvaluationPlugin\n",
        "from avalanche.evaluation.metrics import accuracy_metrics, forgetting_metrics\n"
      ],
      "metadata": {
        "id": "q7CYc0cDhkw4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "# Clustering for RICS"
      ],
      "metadata": {
        "id": "m_1AAwnQho4d"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "from sklearn.cluster import KMeans\n",
        "import numpy as np\n",
        "\n",
        "#device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n"
      ],
      "metadata": {
        "id": "41JuE5rWhpVL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Define MLP Model\n",
        "\n",
        "A two‑layer CNN with pooling, then a 256‑unit dense layer. return_feats lets us extract the feature vector for RICS clustering."
      ],
      "metadata": {
        "id": "bVD7dP18zJ7Y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class SimpleMLP(nn.Module):\n",
        "    def __init__(self, input_dim, hidden=256, total_classes=10):\n",
        "        super().__init__()\n",
        "        self.fc1 = nn.Linear(input_dim, hidden)\n",
        "        self.fc2 = nn.Linear(hidden, hidden)\n",
        "        self.fc3 = nn.Linear(hidden, total_classes)\n",
        "    def forward(self, x):\n",
        "        x = x.view(x.size(0), -1)\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = F.relu(self.fc2(x))\n",
        "        return self.fc3(x)"
      ],
      "metadata": {
        "id": "qnlNYLOOzRdk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Define CNN Model\n",
        "\n",
        "A two‑layer CNN with pooling, then a 256‑unit dense layer. return_feats lets us extract the feature vector for RICS clustering."
      ],
      "metadata": {
        "id": "AB_bzMwni0ly"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Updated CNN that adapts to image size\n",
        "class simpleCNN(nn.Module):\n",
        "    def __init__(self, in_ch, num_classes, img_size):\n",
        "        super().__init__()\n",
        "        self.conv1 = nn.Conv2d(in_ch, 32, 3, padding=1)\n",
        "        self.conv2 = nn.Conv2d(32, 64, 3, padding=1)\n",
        "        self.pool  = nn.MaxPool2d(2, 2)\n",
        "        # After two pools, spatial dims = img_size / 4\n",
        "        conv_out = img_size // 4\n",
        "        self.fc1 = nn.Linear(64 * conv_out * conv_out, 256)\n",
        "        self.fc2 = nn.Linear(256, num_classes)\n",
        "\n",
        "    def forward(self, x, return_feats=False):\n",
        "        x = F.relu(self.conv1(x)); x = self.pool(x)\n",
        "        x = F.relu(self.conv2(x)); x = self.pool(x)\n",
        "        feats = x.view(x.size(0), -1)\n",
        "        out   = self.fc2(F.relu(self.fc1(feats)))\n",
        "        return (out, feats) if return_feats else out\n",
        "\n"
      ],
      "metadata": {
        "id": "jOf29tjNi9yv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#RICS: Centroid Computation & Loss\n",
        "\n",
        "After each task we store class centroids in the model’s feature space. During the next task, we recluster new features and penalize the shift of each centroid—this is the RICS regularizer."
      ],
      "metadata": {
        "id": "HAg5WDWajgmf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import DataLoader\n",
        "from avalanche.training.templates import SupervisedTemplate\n",
        "from typing import Dict"
      ],
      "metadata": {
        "id": "O_w-YVJwE6vN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "# ----------------------------\n",
        "# Simple CNN Model\n",
        "# ----------------------------\n",
        "class SimpleCNN(nn.Module):\n",
        "    def __init__(self, in_channels=3, num_classes=10, feat_dim=256):\n",
        "        super().__init__()\n",
        "        self.conv1 = nn.Conv2d(in_channels, 32, 3, padding=1)\n",
        "        self.conv2 = nn.Conv2d(32, 64, 3, padding=1)\n",
        "        self.pool = nn.MaxPool2d(2)\n",
        "        self.fc1 = nn.Linear(64 * 8 * 8, feat_dim)\n",
        "        self.fc2 = nn.Linear(feat_dim, num_classes)\n",
        "\n",
        "    def forward(self, x, return_feats=False):\n",
        "        x = self.pool(F.relu(self.conv1(x)))\n",
        "        x = self.pool(F.relu(self.conv2(x)))\n",
        "        x = x.view(x.size(0), -1)\n",
        "        feats = F.relu(self.fc1(x))\n",
        "        logits = self.fc2(feats)\n",
        "        return (feats, logits) if return_feats else logits"
      ],
      "metadata": {
        "id": "SBqotgLCZrP2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#  Wrap RICS as an Avalanche Strategy\n",
        "\n",
        "You’ll subclass Avalanche’s BaseStrategy to inject the RICS penalty into the training loop. Below is a sketch—you’ll fill in the details:"
      ],
      "metadata": {
        "id": "GRdbQAu_jsoA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "SupervisedTemplate gives you hooks like before_training_exp, after_training_exp, and criterion to insert your logic.\n",
        "In after_training_exp, we compute and store the centroids of the just-learned task.\n",
        "In criterion, we add the RICS penalty using those stored centroids."
      ],
      "metadata": {
        "id": "e7jmen-emyyF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from avalanche.training.templates import SupervisedTemplate"
      ],
      "metadata": {
        "id": "zm5ACyE4mi0A"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#  Define Benchmarks\n",
        "\n",
        "Explanation:\n",
        "\n",
        "Class‑IL tests completely new labels.\n",
        "\n",
        "Domain‑IL tests same labels under input shifts.\n",
        "\n",
        "Similar‑Class tests fine‑grained, semantically related classes.\n"
      ],
      "metadata": {
        "id": "-7dyE06HkL6n"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "A. Class‑IL on CIFAR‑10 (Disjoint)"
      ],
      "metadata": {
        "id": "3KZdOrwTlPDN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "benchmark_class_il = SplitCIFAR10(\n",
        "    n_experiences=5,\n",
        "    return_task_id= False,\n",
        "    fixed_class_order=list(range(10))\n",
        ")\n"
      ],
      "metadata": {
        "id": "vvv24S-3kN4s",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a8fbfe24-f578-4e49-ba9b-e0815171c88a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 170M/170M [00:09<00:00, 17.5MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Class‑IL experiences:\", len(benchmark_class_il.train_stream))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tvACIIEIohPY",
        "outputId": "42a75677-2adc-4250-c301-6d1271777b1b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Class‑IL experiences: 2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "B. Domain‑IL on CIFAR‑10 (Permuted)"
      ],
      "metadata": {
        "id": "EhWz__PPkV3U"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n"
      ],
      "metadata": {
        "id": "AUwsWFYMkhp3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "Create two pixel‑permuted variants"
      ],
      "metadata": {
        "id": "rOKNpcU2kkt0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "# Download base"
      ],
      "metadata": {
        "id": "RvumdKPrqLcH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "base_train = datasets.CIFAR10(root='./data', train=True, download=True,\n",
        "                              transform=transforms.ToTensor())\n",
        "base_test  = datasets.CIFAR10(root='./data', train=False,download=True,\n",
        "                              transform=transforms.ToTensor())"
      ],
      "metadata": {
        "id": "jjcIiqD8qF9y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torchvision.datasets import CIFAR10\n",
        "from avalanche.benchmarks import nc_benchmark"
      ],
      "metadata": {
        "id": "Xrt_LNllq5XZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "perms = [np.random.permutation(32 * 32 * 3) for _ in range(2)]"
      ],
      "metadata": {
        "id": "G0kEwwvJ0ph6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Helper: permuted dataset\n",
        "class PermutedCIFAR10(CIFAR10):\n",
        "    def __init__(self, base_ds, perm):\n",
        "        super().__init__(base_ds.root, train=base_ds.train, download=False, transform=base_ds.transform)\n",
        "        flat = base_ds.data.reshape(-1, 32*32*3)\n",
        "        self.data = flat[:, perm].reshape(-1, 32, 32, 3)\n",
        "        self.targets = base_ds.targets\n",
        "\n",
        "\n",
        "\n",
        "train_sets = [PermutedCIFAR10(base_train, p) for p in perms]\n",
        "test_sets  = [PermutedCIFAR10(base_test,  p) for p in perms]\n",
        "\n",
        "# Create Avalanche benchmark (no task_names parameter)\n",
        "benchmark_domain_il = nc_benchmark(\n",
        "    train_sets,\n",
        "    test_sets,\n",
        "    2,\n",
        "    task_labels=[0, 1],        # two tasks\n",
        "    shuffle=False\n",
        ")\n",
        "\n"
      ],
      "metadata": {
        "id": "IGJSCy-Gkavr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Domain‑IL experiences:\", len(benchmark_domain_il.train_stream))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z8_40ZdqqaFz",
        "outputId": "b56609c4-53e2-4321-d8bd-7d23e6b53dfa"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Domain‑IL experiences: 2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "C.  Similar‑Class Variation (Vehicle Subclasses)"
      ],
      "metadata": {
        "id": "Hna4M8_skphF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import Subset\n"
      ],
      "metadata": {
        "id": "lMoRyNVwk7VE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Vehicle classes: 0=airplane,1=automobile,8=ship,9=truck"
      ],
      "metadata": {
        "id": "gA8y35AWlCJ_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "group1, group2 = [0,1], [8,9]\n",
        "\n",
        "def subset_by_classes(ds, classes):\n",
        "    idx = [i for i,y in enumerate(ds.targets) if y in classes]\n",
        "    return Subset(ds, idx)\n",
        "\n",
        "train_sets = [subset_by_classes(base_train, group1),\n",
        "              subset_by_classes(base_train, group2)]\n",
        "test_sets  = [subset_by_classes(base_test,  group1),\n",
        "              subset_by_classes(base_test,  group2)]\n",
        "\n",
        "benchmark_similar = nc_benchmark(\n",
        "    train_sets,\n",
        "    test_sets,\n",
        "    2,\n",
        "    task_labels=[0,1],\n",
        "    shuffle=False)\n"
      ],
      "metadata": {
        "id": "RrVnaMugkrw0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Similar‑Class IL experiences:\", len(benchmark_similar.train_stream))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uB3HFzPLsyVc",
        "outputId": "15a01777-053a-4ddd-a41c-0a7b354e44ee"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Similar‑Class IL experiences: 2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Run Strategies & Collect Results\n",
        "\n",
        "This loop runs all 3 strategies on each of the 3 scenarios; Avalanche handles the “train then test on all seen tasks” logic and collects accuracy/forgetting metrics automatically."
      ],
      "metadata": {
        "id": "gfKKYaMDlzCw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "device = \"cpu\""
      ],
      "metadata": {
        "id": "_Sa4bU1odjfZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "Common evaluation plugin"
      ],
      "metadata": {
        "id": "7nf-bCjbpP48"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Run Strategies on All Scenarios\n"
      ],
      "metadata": {
        "id": "sPlrX-QGpcHA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from avalanche.evaluation.metrics import accuracy_metrics, loss_metrics, forgetting_metrics, timing_metrics\n",
        "from avalanche.logging import InteractiveLogger\n",
        "from avalanche.training.plugins import EvaluationPlugin\n",
        "\n",
        "# Define logger\n",
        "logger = InteractiveLogger()\n",
        "\n",
        "# Create evaluation plugin\n",
        "eval_plugin = EvaluationPlugin(\n",
        "    accuracy_metrics(epoch=True, experience=True, stream=True),\n",
        "    loss_metrics(epoch=True, experience=True, stream=True),\n",
        "    loggers=[logger]\n",
        ")"
      ],
      "metadata": {
        "id": "c0qWvUYhZGWv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Scenarios Class‑IL"
      ],
      "metadata": {
        "id": "pDjKkUtsbk4A"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "bench = benchmark_class_il\n",
        "in_ch = 3\n",
        "\n",
        "print(f\"\\n=== Scenario: Class‑IL (CIFAR‑10) ===\")\n",
        "\n",
        "print(f\"\\n-- Model: CNN | Strategy: Naive --\")"
      ],
      "metadata": {
        "id": "DInrxsG6eHXI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "435acd02-3642-4dce-a1fb-dda82f0941c9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "=== Scenario: Class‑IL (CIFAR‑10) ===\n",
            "\n",
            "-- Model: CNN | Strategy: Naive --\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Naive"
      ],
      "metadata": {
        "id": "OA-0hx02bvgZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "strategy = Naive(**common)\n",
        "\n",
        "# train & eval\n",
        "\n",
        "  for experience in bench.train_stream:\n",
        "      current_classes = list(set(experience.dataset.targets))\n",
        "      print(f\"Training on classes: {current_classes}\")\n",
        "      print(\"Training on experience\", experience.current_experience)\n",
        "\n",
        "      strategy.train(experience)\n",
        "\n",
        "      print(\"Evaluating on all seen tasks...\")\n",
        "      strategy.eval(bench.test_stream[: experience.current_experience + 1])\n"
      ],
      "metadata": {
        "id": "3ckGmNgTbswk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "EWC"
      ],
      "metadata": {
        "id": "lSQzalyqegxv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "strategy = EWC(**common, ewc_lambda=0.5)\n",
        "\n",
        "print(f\"\\n-- Model: CNN | Strategy: EWC --\")\n",
        "\n",
        "# train & eval\n",
        "\n",
        "  for experience in bench.train_stream:\n",
        "      current_classes = list(set(experience.dataset.targets))\n",
        "      print(f\"Training on classes: {current_classes}\")\n",
        "      print(\"Training on experience\", experience.current_experience)\n",
        "\n",
        "      strategy.train(experience)\n",
        "\n",
        "      print(\"Evaluating on all seen tasks...\")\n",
        "      strategy.eval(bench.test_stream[: experience.current_experience + 1])"
      ],
      "metadata": {
        "id": "AbEj_RwFehUc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Our Model RICS"
      ],
      "metadata": {
        "id": "rVJyS7l-er39"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "strategy = RICSStrategy(**common, ewc_lambda=0.5)\n",
        "\n",
        "print(f\"\\n-- Model: CNN | Strategy: RICS --\")\n",
        "\n",
        "# train & eval\n",
        "\n",
        "  for experience in bench.train_stream:\n",
        "      current_classes = list(set(experience.dataset.targets))\n",
        "      print(f\"Training on classes: {current_classes}\")\n",
        "      print(\"Training on experience\", experience.current_experience)\n",
        "\n",
        "      strategy.train(experience)\n",
        "\n",
        "      print(\"Evaluating on all seen tasks...\")\n",
        "      strategy.eval(bench.test_stream[: experience.current_experience + 1])"
      ],
      "metadata": {
        "id": "B2B_u9ZYesB3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Sample labels in this task:\", set(exp.dataset.targets))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 139
        },
        "id": "tNDlmyQgW6GQ",
        "outputId": "180adebe-d0d9-4829-b48e-d6fc17323efa"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'exp' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-15-4240051689.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Sample labels in this task:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtargets\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'exp' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Scenario Domain IL"
      ],
      "metadata": {
        "id": "lfAAS1mVfxnj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "bench = benchmark_domain_il\n",
        "bench = benchmark_class_il\n",
        "in_ch = 3\n",
        "\n",
        "print(f\"\\n=== Scenario: Domain‑IL (CIFAR‑10) ===\")\n",
        "\n",
        "print(f\"\\n-- Model: CNN | Strategy: Naive --\")"
      ],
      "metadata": {
        "id": "1NIzMHXJf1FW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Naive"
      ],
      "metadata": {
        "id": "MjXLzxcwf_m0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "strategy = Naive(**common)\n",
        "\n",
        "# train & eval\n",
        "\n",
        "  for experience in bench.train_stream:\n",
        "      current_classes = list(set(experience.dataset.targets))\n",
        "      print(f\"Training on classes: {current_classes}\")\n",
        "      print(\"Training on experience\", experience.current_experience)\n",
        "\n",
        "      strategy.train(experience)\n",
        "\n",
        "      print(\"Evaluating on all seen tasks...\")\n",
        "      strategy.eval(bench.test_stream[: experience.current_experience + 1])\n"
      ],
      "metadata": {
        "id": "cnVOI6l5gUxZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "EWC"
      ],
      "metadata": {
        "id": "JjpUT3wFf_pc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "strategy = EWC(**common, ewc_lambda=0.5)\n",
        "\n",
        "print(f\"\\n-- Model: CNN | Strategy: EWC --\")\n",
        "\n",
        "# train & eval\n",
        "\n",
        "  for experience in bench.train_stream:\n",
        "      current_classes = list(set(experience.dataset.targets))\n",
        "      print(f\"Training on classes: {current_classes}\")\n",
        "      print(\"Training on experience\", experience.current_experience)\n",
        "\n",
        "      strategy.train(experience)\n",
        "\n",
        "      print(\"Evaluating on all seen tasks...\")\n",
        "      strategy.eval(bench.test_stream[: experience.current_experience + 1])"
      ],
      "metadata": {
        "id": "N681E6Z6gXp3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "RICS"
      ],
      "metadata": {
        "id": "AOxUeSdUf_sU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "strategy = RICSStrategy(**common, ewc_lambda=0.5)\n",
        "\n",
        "print(f\"\\n-- Model: CNN | Strategy: RICS --\")\n",
        "\n",
        "# train & eval\n",
        "\n",
        "  for experience in bench.train_stream:\n",
        "      current_classes = list(set(experience.dataset.targets))\n",
        "      print(f\"Training on classes: {current_classes}\")\n",
        "      print(\"Training on experience\", experience.current_experience)\n",
        "\n",
        "      strategy.train(experience)\n",
        "\n",
        "      print(\"Evaluating on all seen tasks...\")\n",
        "      strategy.eval(bench.test_stream[: experience.current_experience + 1])"
      ],
      "metadata": {
        "id": "jiGyAjL4geiJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "ffS1oaFrf_u6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "dxWhW_d2f_xg"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "UEIxyDujf_z3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "cifar_scenarios = [\n",
        "    (\"Class‑IL\",   benchmark_class_il)\n",
        "]\n",
        "\n",
        "strategies = [(\"Naive\", Naive), (\"EWC\", EWC), (\"RICS\", RICSStrategy)]\n",
        "\n",
        "for scen_name, bench in cifar_scenarios:\n",
        "    print(f\"\\n=== Scenario: {scen_name} (CIFAR‑10) ===\")\n",
        "\n",
        "    for strat_name, Strat in strategies:\n",
        "        print(f\"\\n-- Model: CNN | Strategy: {strat_name} --\")\n",
        "\n",
        "        for experience in bench.train_stream:\n",
        "            current_classes = experience.classes_in_this_experience\n",
        "            num_classes = len(set(experience.dataset.targets))\n",
        "            print(f\"Training on classes: {experience.dataset.targets}\")\n",
        "\n",
        "            # Step 4: Recreate model with matching output size\n",
        "            model = SimpleCNN(in_channels=3, num_classes=num_classes).to(device)\n",
        "            optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "            criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "            # === Strategy creation ===\n",
        "            if strat_name == \"EWC\":\n",
        "                strategy = Strat(\n",
        "                    model=model,\n",
        "                    optimizer=optimizer,\n",
        "                    criterion=criterion,\n",
        "                    ewc_lambda=0.5,\n",
        "                    train_mb_size=64,\n",
        "                    train_epochs=2,\n",
        "                    eval_mb_size=64,\n",
        "                    device=device,\n",
        "                    evaluator=eval_plugin\n",
        "                )\n",
        "            elif strat_name == \"RICS\":\n",
        "                strategy = Strat(\n",
        "                    model=model,\n",
        "                    optimizer=optimizer,\n",
        "                    criterion=criterion,\n",
        "                    rics_lambda=0.5,\n",
        "                    train_mb_size=64,\n",
        "                    train_epochs=2,\n",
        "                    eval_mb_size=64,\n",
        "                    device=device,\n",
        "                    evaluator=eval_plugin\n",
        "                )\n",
        "            else:  # Naive\n",
        "                strategy = Strat(\n",
        "                    model=model,\n",
        "                    optimizer=optimizer,\n",
        "                    criterion=criterion,\n",
        "                    train_mb_size=64,\n",
        "                    train_epochs=2,\n",
        "                    eval_mb_size=64,\n",
        "                    device=device,\n",
        "                    evaluator=eval_plugin\n",
        "                )\n",
        "            print(\"Training on experience\", experience.current_experience)\n",
        "            print(\"Model output dim:\", model.fc1.out_features)\n",
        "\n",
        "\n",
        "            # === Train & Evaluate ===\n",
        "            print(f\"\\nTraining on Task {experience.current_experience}\")\n",
        "            strategy.train(experience)\n",
        "\n",
        "            print(\"Evaluating on all seen tasks...\")\n",
        "            print(\"Evaluating on all seen tasks...\")\n",
        "            # Evaluate on all test experiences so far\n",
        "            test_experiences = (bench.test_stream)[: experience.current_experience + 1]\n",
        "            strategy.eval(test_experiences)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 996
        },
        "outputId": "563f61cd-e4f3-47c2-dd2d-c970e15b691e",
        "id": "M9LiQI4h-WLS"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "=== Scenario: Class‑IL (CIFAR‑10) ===\n",
            "\n",
            "-- Model: CNN | Strategy: Naive --\n",
            "Training on classes: [0, 1, 2, 3, 4]\n",
            "Training on experience 0\n",
            "Model output dim: 256\n",
            "\n",
            "Training on Task 0\n",
            "-- >> Start of training phase << --\n",
            "100%|██████████| 391/391 [00:08<00:00, 47.80it/s]\n",
            "Epoch 0 ended.\n",
            "\tLoss_Epoch/train_phase/train_stream/Task000 = 1.0405\n",
            "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.5738\n",
            "100%|██████████| 391/391 [00:07<00:00, 51.02it/s]\n",
            "Epoch 1 ended.\n",
            "\tLoss_Epoch/train_phase/train_stream/Task000 = 0.8256\n",
            "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.6692\n",
            "-- >> End of training phase << --\n",
            "Evaluating on all seen tasks...\n",
            "Evaluating on all seen tasks...\n",
            "-- >> Start of eval phase << --\n",
            "-- Starting eval on experience 0 (Task 0) from test stream --\n",
            "100%|██████████| 79/79 [00:00<00:00, 92.56it/s]\n",
            "> Eval on experience 0 (Task 0) from test stream ended.\n",
            "\tLoss_Exp/eval_phase/test_stream/Task000/Exp000 = 0.6889\n",
            "\tTop1_Acc_Exp/eval_phase/test_stream/Task000/Exp000 = 0.7356\n",
            "-- >> End of eval phase << --\n",
            "\tLoss_Stream/eval_phase/test_stream/Task000 = 0.6889\n",
            "\tTop1_Acc_Stream/eval_phase/test_stream/Task000 = 0.7356\n",
            "Training on classes: [5, 6, 7, 8, 9]\n",
            "Training on experience 1\n",
            "Model output dim: 256\n",
            "\n",
            "Training on Task 1\n",
            "-- >> Start of training phase << --\n",
            "0it [00:00, ?it/s]"
          ]
        },
        {
          "output_type": "error",
          "ename": "IndexError",
          "evalue": "Target 6 is out of bounds.",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-21-1973185012.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     63\u001b[0m             \u001b[0;31m# === Train & Evaluate ===\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"\\nTraining on Task {experience.current_experience}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 65\u001b[0;31m             \u001b[0mstrategy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexperience\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     66\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Evaluating on all seen tasks...\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/avalanche/training/templates/base_sgd.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, experiences, eval_streams, **kwargs)\u001b[0m\n\u001b[1;32m    211\u001b[0m         \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    212\u001b[0m     ):\n\u001b[0;32m--> 213\u001b[0;31m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexperiences\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0meval_streams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    214\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_last_metrics\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    215\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/avalanche/training/templates/base.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, experiences, eval_streams, **kwargs)\u001b[0m\n\u001b[1;32m    161\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperience\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mexperiences_list\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    162\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_before_training_exp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 163\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_train_exp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperience\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0meval_streams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    164\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_after_training_exp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    165\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_after_training\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/avalanche/training/templates/base_sgd.py\u001b[0m in \u001b[0;36m_train_exp\u001b[0;34m(self, experience, eval_streams, **kwargs)\u001b[0m\n\u001b[1;32m    337\u001b[0m                 \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    338\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 339\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtraining_epoch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    340\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_after_training_epoch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    341\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/avalanche/training/templates/update_type/sgd_update.py\u001b[0m in \u001b[0;36mtraining_epoch\u001b[0;34m(self, **kwargs)\u001b[0m\n\u001b[1;32m     33\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m             \u001b[0;31m# Loss & Backward\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 35\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     36\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_before_backward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/avalanche/training/templates/problem_type/supervised_problem.py\u001b[0m in \u001b[0;36mcriterion\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     41\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m         \u001b[0;34m\"\"\"Loss function for supervised problems.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 43\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_criterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmb_output\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmb_y\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     44\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1737\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1738\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1739\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1740\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1741\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1748\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1749\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1750\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1751\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1752\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/loss.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input, target)\u001b[0m\n\u001b[1;32m   1293\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1294\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1295\u001b[0;31m         return F.cross_entropy(\n\u001b[0m\u001b[1;32m   1296\u001b[0m             \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1297\u001b[0m             \u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mcross_entropy\u001b[0;34m(input, target, weight, size_average, ignore_index, reduce, reduction, label_smoothing)\u001b[0m\n\u001b[1;32m   3492\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0msize_average\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mreduce\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3493\u001b[0m         \u001b[0mreduction\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_Reduction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlegacy_get_string\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msize_average\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreduce\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3494\u001b[0;31m     return torch._C._nn.cross_entropy_loss(\n\u001b[0m\u001b[1;32m   3495\u001b[0m         \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3496\u001b[0m         \u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mIndexError\u001b[0m: Target 6 is out of bounds."
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 378
        },
        "id": "DJY4e_VNn8Vo",
        "outputId": "cb43e2ec-ec8d-4157-e90d-72986e639fb0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ImportError",
          "evalue": "cannot import name 'AvalancheDataset' from 'avalanche.benchmarks.utils.dataset_utils' (/usr/local/lib/python3.11/dist-packages/avalanche/benchmarks/utils/dataset_utils.py)",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-24-518234563.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mavalanche\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbenchmarks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset_utils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mAvalancheDataset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mtargets\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mexperience\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtargets\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexperience\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"targets\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mexperience\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtargets\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mtargets\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mImportError\u001b[0m: cannot import name 'AvalancheDataset' from 'avalanche.benchmarks.utils.dataset_utils' (/usr/local/lib/python3.11/dist-packages/avalanche/benchmarks/utils/dataset_utils.py)",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ],
          "errorDetails": {
            "actions": [
              {
                "action": "open_url",
                "actionText": "Open Examples",
                "url": "/notebooks/snippets/importing_libraries.ipynb"
              }
            ]
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cifar_scenarios = [\n",
        "    (\"Class‑IL\",   benchmark_class_il)\n",
        "]\n",
        "\n",
        "strategies = [(\"Naive\", Naive), (\"EWC\", EWC), (\"RICS\", RICSStrategy)]\n",
        "\n",
        "for scen_name, bench in cifar_scenarios:\n",
        "    print(f\"\\n=== Scenario: {scen_name} (CIFAR‑10) ===\")\n",
        "\n",
        "    for strat_name, Strat in strategies:\n",
        "        print(f\"\\n-- Model: CNN | Strategy: {strat_name} --\")\n",
        "\n",
        "        for experience in bench.train_stream:\n",
        "            current_classes = list(set(experience.dataset.targets))\n",
        "            num_classes = max(current_classes) + 1\n",
        "\n",
        "            print(f\"Training on classes: {current_classes}\")\n",
        "\n",
        "            # Step 4: Recreate model with matching output size\n",
        "            model = SimpleCNN(in_channels=3, num_classes=num_classes).to(device)\n",
        "            optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "            criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "            # === Strategy creation ===\n",
        "            if strat_name == \"EWC\":\n",
        "                strategy = Strat(\n",
        "                    model=model,\n",
        "                    optimizer=optimizer,\n",
        "                    criterion=criterion,\n",
        "                    ewc_lambda=0.5,\n",
        "                    train_mb_size=64,\n",
        "                    train_epochs=2,\n",
        "                    eval_mb_size=64,\n",
        "                    device=device,\n",
        "                    evaluator=eval_plugin\n",
        "                )\n",
        "            elif strat_name == \"RICS\":\n",
        "                strategy = Strat(\n",
        "                    model=model,\n",
        "                    optimizer=optimizer,\n",
        "                    criterion=criterion,\n",
        "                    rics_lambda=0.5,\n",
        "                    train_mb_size=64,\n",
        "                    train_epochs=2,\n",
        "                    eval_mb_size=64,\n",
        "                    device=device,\n",
        "                    evaluator=eval_plugin\n",
        "                )\n",
        "            else:  # Naive\n",
        "                strategy = Strat(\n",
        "                    model=model,\n",
        "                    optimizer=optimizer,\n",
        "                    criterion=criterion,\n",
        "                    train_mb_size=64,\n",
        "                    train_epochs=2,\n",
        "                    eval_mb_size=64,\n",
        "                    device=device,\n",
        "                    evaluator=eval_plugin\n",
        "                )\n",
        "            print(\"Training on experience\", experience.current_experience)\n",
        "            print(\"Model output dim:\", model.fc1.out_features)\n",
        "\n",
        "\n",
        "            # === Train & Evaluate ===\n",
        "            print(f\"\\nTraining on Task {experience.current_experience}\")\n",
        "            strategy.train(experience)\n",
        "\n",
        "            print(\"Evaluating on all seen tasks...\")\n",
        "            print(\"Evaluating on all seen tasks...\")\n",
        "            # Evaluate on all test experiences so far\n",
        "            test_experiences = list(bench.test_stream)[: experience.current_experience + 1]\n",
        "            strategy.eval(test_experiences)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5bdaf155-50df-48b4-d6c5-c4263a19b15a",
        "id": "ppIU6T8Hn9D3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "=== Scenario: Class‑IL (CIFAR‑10) ===\n",
            "\n",
            "-- Model: CNN | Strategy: Naive --\n",
            "Training on classes: [0, 1, 2, 3, 4]\n",
            "Training on experience 0\n",
            "Model output dim: 256\n",
            "\n",
            "Training on Task 0\n",
            "-- >> Start of training phase << --\n",
            "100%|██████████| 391/391 [11:23<00:00,  1.75s/it]\n",
            "Epoch 0 ended.\n",
            "\tLoss_Epoch/train_phase/train_stream/Task000 = 1.0527\n",
            "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.5704\n",
            "100%|██████████| 391/391 [00:07<00:00, 49.27it/s]\n",
            "Epoch 1 ended.\n",
            "\tLoss_Epoch/train_phase/train_stream/Task000 = 0.8332\n",
            "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.6726\n",
            "-- >> End of training phase << --\n",
            "Evaluating on all seen tasks...\n",
            "Evaluating on all seen tasks...\n",
            "-- >> Start of eval phase << --\n",
            "-- Starting eval on experience 0 (Task 0) from test stream --\n",
            "100%|██████████| 79/79 [00:00<00:00, 89.28it/s]\n",
            "> Eval on experience 0 (Task 0) from test stream ended.\n",
            "\tLoss_Exp/eval_phase/test_stream/Task000/Exp000 = 0.6892\n",
            "\tTop1_Acc_Exp/eval_phase/test_stream/Task000/Exp000 = 0.7334\n",
            "-- >> End of eval phase << --\n",
            "\tLoss_Stream/eval_phase/test_stream/Task000 = 0.6892\n",
            "\tTop1_Acc_Stream/eval_phase/test_stream/Task000 = 0.7334\n",
            "Training on classes: [5, 6, 7, 8, 9]\n",
            "Training on experience 1\n",
            "Model output dim: 256\n",
            "\n",
            "Training on Task 1\n",
            "-- >> Start of training phase << --\n",
            "100%|██████████| 391/391 [00:08<00:00, 46.66it/s]\n",
            "Epoch 0 ended.\n",
            "\tLoss_Epoch/train_phase/train_stream/Task001 = 0.8747\n",
            "\tTop1_Acc_Epoch/train_phase/train_stream/Task001 = 0.6554\n",
            "100%|██████████| 391/391 [00:08<00:00, 48.63it/s]\n",
            "Epoch 1 ended.\n",
            "\tLoss_Epoch/train_phase/train_stream/Task001 = 0.5908\n",
            "\tTop1_Acc_Epoch/train_phase/train_stream/Task001 = 0.7778\n",
            "-- >> End of training phase << --\n",
            "Evaluating on all seen tasks...\n",
            "Evaluating on all seen tasks...\n",
            "-- >> Start of eval phase << --\n",
            "-- Starting eval on experience 0 (Task 0) from test stream --\n",
            "100%|██████████| 79/79 [00:00<00:00, 88.83it/s]\n",
            "> Eval on experience 0 (Task 0) from test stream ended.\n",
            "\tLoss_Exp/eval_phase/test_stream/Task000/Exp000 = 11.2364\n",
            "\tTop1_Acc_Exp/eval_phase/test_stream/Task000/Exp000 = 0.0000\n",
            "-- Starting eval on experience 1 (Task 1) from test stream --\n",
            "100%|██████████| 79/79 [00:00<00:00, 86.99it/s]\n",
            "> Eval on experience 1 (Task 1) from test stream ended.\n",
            "\tLoss_Exp/eval_phase/test_stream/Task001/Exp001 = 0.4997\n",
            "\tTop1_Acc_Exp/eval_phase/test_stream/Task001/Exp001 = 0.8074\n",
            "-- >> End of eval phase << --\n",
            "\tLoss_Stream/eval_phase/test_stream/Task001 = 5.8681\n",
            "\tTop1_Acc_Stream/eval_phase/test_stream/Task001 = 0.4037\n",
            "\n",
            "-- Model: CNN | Strategy: EWC --\n",
            "Training on classes: [0, 1, 2, 3, 4]\n",
            "Training on experience 0\n",
            "Model output dim: 256\n",
            "\n",
            "Training on Task 0\n",
            "-- >> Start of training phase << --\n",
            "100%|██████████| 391/391 [00:07<00:00, 49.65it/s]\n",
            "Epoch 0 ended.\n",
            "\tLoss_Epoch/train_phase/train_stream/Task000 = 1.0588\n",
            "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.5647\n",
            "100%|██████████| 391/391 [00:08<00:00, 47.68it/s]\n",
            "Epoch 1 ended.\n",
            "\tLoss_Epoch/train_phase/train_stream/Task000 = 0.8170\n",
            "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.6780\n",
            "-- >> End of training phase << --\n",
            "Evaluating on all seen tasks...\n",
            "Evaluating on all seen tasks...\n",
            "-- >> Start of eval phase << --\n",
            "-- Starting eval on experience 0 (Task 0) from test stream --\n",
            "100%|██████████| 79/79 [00:00<00:00, 90.91it/s]\n",
            "> Eval on experience 0 (Task 0) from test stream ended.\n",
            "\tLoss_Exp/eval_phase/test_stream/Task000/Exp000 = 0.6861\n",
            "\tTop1_Acc_Exp/eval_phase/test_stream/Task000/Exp000 = 0.7364\n",
            "-- >> End of eval phase << --\n",
            "\tLoss_Stream/eval_phase/test_stream/Task000 = 0.6861\n",
            "\tTop1_Acc_Stream/eval_phase/test_stream/Task000 = 0.7364\n",
            "Training on classes: [5, 6, 7, 8, 9]\n",
            "Training on experience 1\n",
            "Model output dim: 256\n",
            "\n",
            "Training on Task 1\n",
            "-- >> Start of training phase << --\n",
            "100%|██████████| 391/391 [00:08<00:00, 48.37it/s]\n",
            "Epoch 0 ended.\n",
            "\tLoss_Epoch/train_phase/train_stream/Task001 = 0.8511\n",
            "\tTop1_Acc_Epoch/train_phase/train_stream/Task001 = 0.6700\n",
            "100%|██████████| 391/391 [00:07<00:00, 49.38it/s]\n",
            "Epoch 1 ended.\n",
            "\tLoss_Epoch/train_phase/train_stream/Task001 = 0.5747\n",
            "\tTop1_Acc_Epoch/train_phase/train_stream/Task001 = 0.7878\n",
            "-- >> End of training phase << --\n",
            "Evaluating on all seen tasks...\n",
            "Evaluating on all seen tasks...\n",
            "-- >> Start of eval phase << --\n",
            "-- Starting eval on experience 0 (Task 0) from test stream --\n",
            "100%|██████████| 79/79 [00:00<00:00, 85.93it/s]\n",
            "> Eval on experience 0 (Task 0) from test stream ended.\n",
            "\tLoss_Exp/eval_phase/test_stream/Task000/Exp000 = 12.2197\n",
            "\tTop1_Acc_Exp/eval_phase/test_stream/Task000/Exp000 = 0.0000\n",
            "-- Starting eval on experience 1 (Task 1) from test stream --\n",
            "100%|██████████| 79/79 [00:01<00:00, 67.60it/s]\n",
            "> Eval on experience 1 (Task 1) from test stream ended.\n",
            "\tLoss_Exp/eval_phase/test_stream/Task001/Exp001 = 0.4785\n",
            "\tTop1_Acc_Exp/eval_phase/test_stream/Task001/Exp001 = 0.8256\n",
            "-- >> End of eval phase << --\n",
            "\tLoss_Stream/eval_phase/test_stream/Task001 = 6.3491\n",
            "\tTop1_Acc_Stream/eval_phase/test_stream/Task001 = 0.4128\n",
            "\n",
            "-- Model: CNN | Strategy: RICS --\n",
            "Training on classes: [0, 1, 2, 3, 4]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/avalanche/training/templates/base.py:389: UserWarning: Avalanche is transitioning to strategy constructors that accept named (keyword) arguments only. This is done to ensure that there is no confusion regarding the meaning of each argument (strategies can have many arguments). Your strategy RICSStrategy.__init__ method still has some positional-only or positional-or-keyword arguments. Consider removing them. Offending arguments: ['self', 'model', 'optimizer', 'criterion', 'rics_lambda', 'train_mb_size', 'train_epochs', 'eval_mb_size', 'device', 'evaluator']. This can be achieved by adding a * in the argument list of your __init__ method just after 'self'. More info: https://peps.python.org/pep-3102/#specification\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/avalanche/training/templates/base.py:468: PositionalArgumentsDeprecatedWarning: Avalanche is transitioning to strategy constructors that accept named (keyword) arguments only. This is done to ensure that there is no confusion regarding the meaning of each argument (strategies can have many arguments). Your are passing 3 positional arguments to the SupervisedTemplate.__init__ method. Consider passing them as names arguments. The ability to pass positional arguments will be removed in the future.\n",
            "  warnings.warn(error_str, category=PositionalArgumentsDeprecatedWarning)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training on experience 0\n",
            "Model output dim: 256\n",
            "\n",
            "Training on Task 0\n",
            "-- >> Start of training phase << --\n",
            "100%|██████████| 391/391 [00:07<00:00, 51.24it/s]\n",
            "Epoch 0 ended.\n",
            "\tLoss_Epoch/train_phase/train_stream/Task000 = 1.1118\n",
            "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.5479\n",
            "100%|██████████| 391/391 [00:08<00:00, 47.92it/s]\n",
            "Epoch 1 ended.\n",
            "\tLoss_Epoch/train_phase/train_stream/Task000 = 0.8540\n",
            "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.6620\n",
            "-- >> End of training phase << --\n",
            "Evaluating on all seen tasks...\n",
            "Evaluating on all seen tasks...\n",
            "-- >> Start of eval phase << --\n",
            "-- Starting eval on experience 0 (Task 0) from test stream --\n",
            "100%|██████████| 79/79 [00:00<00:00, 86.54it/s]\n",
            "> Eval on experience 0 (Task 0) from test stream ended.\n",
            "\tLoss_Exp/eval_phase/test_stream/Task000/Exp000 = 0.7308\n",
            "\tTop1_Acc_Exp/eval_phase/test_stream/Task000/Exp000 = 0.7098\n",
            "-- >> End of eval phase << --\n",
            "\tLoss_Stream/eval_phase/test_stream/Task000 = 0.7308\n",
            "\tTop1_Acc_Stream/eval_phase/test_stream/Task000 = 0.7098\n",
            "Training on classes: [5, 6, 7, 8, 9]\n",
            "Training on experience 1\n",
            "Model output dim: 256\n",
            "\n",
            "Training on Task 1\n",
            "-- >> Start of training phase << --\n",
            "100%|██████████| 391/391 [00:08<00:00, 47.66it/s]\n",
            "Epoch 0 ended.\n",
            "\tLoss_Epoch/train_phase/train_stream/Task001 = 0.8887\n",
            "\tTop1_Acc_Epoch/train_phase/train_stream/Task001 = 0.6560\n",
            "100%|██████████| 391/391 [00:07<00:00, 50.24it/s]\n",
            "Epoch 1 ended.\n",
            "\tLoss_Epoch/train_phase/train_stream/Task001 = 0.6087\n",
            "\tTop1_Acc_Epoch/train_phase/train_stream/Task001 = 0.7720\n",
            "-- >> End of training phase << --\n",
            "Evaluating on all seen tasks...\n",
            "Evaluating on all seen tasks...\n",
            "-- >> Start of eval phase << --\n",
            "-- Starting eval on experience 0 (Task 0) from test stream --\n",
            "100%|██████████| 79/79 [00:00<00:00, 89.40it/s]\n",
            "> Eval on experience 0 (Task 0) from test stream ended.\n",
            "\tLoss_Exp/eval_phase/test_stream/Task000/Exp000 = 11.8404\n",
            "\tTop1_Acc_Exp/eval_phase/test_stream/Task000/Exp000 = 0.0000\n",
            "-- Starting eval on experience 1 (Task 1) from test stream --\n",
            "100%|██████████| 79/79 [00:00<00:00, 87.91it/s]\n",
            "> Eval on experience 1 (Task 1) from test stream ended.\n",
            "\tLoss_Exp/eval_phase/test_stream/Task001/Exp001 = 0.4410\n",
            "\tTop1_Acc_Exp/eval_phase/test_stream/Task001/Exp001 = 0.8416\n",
            "-- >> End of eval phase << --\n",
            "\tLoss_Stream/eval_phase/test_stream/Task001 = 6.1407\n",
            "\tTop1_Acc_Stream/eval_phase/test_stream/Task001 = 0.4208\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cifar_scenarios = [\n",
        "    (\"Class‑IL\",   benchmark_class_il,   3, 32)\n",
        "]\n",
        "\n",
        "strategies = [(\"Naive\", Naive), (\"EWC\", EWC), (\"RICS\", RICSStrategy)]\n",
        "\n",
        "for scen_name, bench, in_ch, img_size in cifar_scenarios:\n",
        "    print(f\"\\n=== Scenario: {scen_name} (CIFAR‑10) ===\")\n",
        "\n",
        "    for strat_name, Strat in strategies:\n",
        "        print(f\"\\n-- Model: CNN | Strategy: {strat_name} --\")\n",
        "\n",
        "        model = SimpleCNN(in_channels=3, num_classes=10).to(device)\n",
        "        optimizer = optim.Adam(model.parameters(), lr=1e-3)\n",
        "\n",
        "        common = dict(\n",
        "            model=model, optimizer=optimizer, criterion=nn.CrossEntropyLoss(),\n",
        "            train_mb_size=64, train_epochs=5,\n",
        "            eval_mb_size=64,\n",
        "            device=device, evaluator=eval_plugin\n",
        "        )\n",
        "\n",
        "        if strat_name == \"EWC\":\n",
        "            strategy = Strat(**common, ewc_lambda=0.5)\n",
        "        elif strat_name == \"RICS\":\n",
        "            strategy = Strat(**common, rics_lambda=0.5)\n",
        "        else:\n",
        "            strategy = Strat(**common)\n",
        "\n",
        "        # train & eval\n",
        "\n",
        "        for experience in bench.train_stream:\n",
        "            current_classes = list(set(experience.dataset.targets))\n",
        "            print(f\"Training on classes: {current_classes}\")\n",
        "            print(\"Training on experience\", experience.current_experience)\n",
        "\n",
        "            strategy.train(experience)\n",
        "\n",
        "            print(\"Evaluating on all seen tasks...\")\n",
        "            strategy.eval(bench.test_stream[: experience.current_experience + 1])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qRM-Ye73cj8u",
        "outputId": "f534d89c-bcfb-49a2-cba3-9081515dc3d0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "=== Scenario: Class‑IL (CIFAR‑10) ===\n",
            "\n",
            "-- Model: CNN | Strategy: Naive --\n",
            "Training on classes: [0, 1]\n",
            "Training on experience 0\n",
            "-- >> Start of training phase << --\n",
            "100%|██████████| 157/157 [00:03<00:00, 49.74it/s]\n",
            "Epoch 0 ended.\n",
            "\tLoss_Epoch/train_phase/train_stream/Task000 = 0.4600\n",
            "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.7899\n",
            "100%|██████████| 157/157 [00:03<00:00, 49.17it/s]\n",
            "Epoch 1 ended.\n",
            "\tLoss_Epoch/train_phase/train_stream/Task000 = 0.2988\n",
            "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.8760\n",
            "100%|██████████| 157/157 [00:03<00:00, 49.46it/s]\n",
            "Epoch 2 ended.\n",
            "\tLoss_Epoch/train_phase/train_stream/Task000 = 0.2529\n",
            "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.8982\n",
            "100%|██████████| 157/157 [00:03<00:00, 49.28it/s]\n",
            "Epoch 3 ended.\n",
            "\tLoss_Epoch/train_phase/train_stream/Task000 = 0.2110\n",
            "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.9151\n",
            "100%|██████████| 157/157 [00:03<00:00, 48.50it/s]\n",
            "Epoch 4 ended.\n",
            "\tLoss_Epoch/train_phase/train_stream/Task000 = 0.1941\n",
            "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.9222\n",
            "-- >> End of training phase << --\n",
            "Evaluating on all seen tasks...\n",
            "-- >> Start of eval phase << --\n",
            "-- Starting eval on experience 0 (Task 0) from test stream --\n",
            "100%|██████████| 32/32 [00:00<00:00, 86.80it/s]\n",
            "> Eval on experience 0 (Task 0) from test stream ended.\n",
            "\tLoss_Exp/eval_phase/test_stream/Task000/Exp000 = 0.1634\n",
            "\tTop1_Acc_Exp/eval_phase/test_stream/Task000/Exp000 = 0.9400\n",
            "-- >> End of eval phase << --\n",
            "\tLoss_Stream/eval_phase/test_stream/Task000 = 0.1634\n",
            "\tTop1_Acc_Stream/eval_phase/test_stream/Task000 = 0.9400\n",
            "Training on classes: [2, 3]\n",
            "Training on experience 1\n",
            "-- >> Start of training phase << --\n",
            "100%|██████████| 157/157 [00:03<00:00, 48.05it/s]\n",
            "Epoch 0 ended.\n",
            "\tLoss_Epoch/train_phase/train_stream/Task001 = 0.9145\n",
            "\tTop1_Acc_Epoch/train_phase/train_stream/Task001 = 0.5753\n",
            "100%|██████████| 157/157 [00:03<00:00, 47.19it/s]\n",
            "Epoch 1 ended.\n",
            "\tLoss_Epoch/train_phase/train_stream/Task001 = 0.5276\n",
            "\tTop1_Acc_Epoch/train_phase/train_stream/Task001 = 0.7442\n",
            "100%|██████████| 157/157 [00:03<00:00, 51.25it/s]\n",
            "Epoch 2 ended.\n",
            "\tLoss_Epoch/train_phase/train_stream/Task001 = 0.5045\n",
            "\tTop1_Acc_Epoch/train_phase/train_stream/Task001 = 0.7622\n",
            "100%|██████████| 157/157 [00:03<00:00, 49.38it/s]\n",
            "Epoch 3 ended.\n",
            "\tLoss_Epoch/train_phase/train_stream/Task001 = 0.4883\n",
            "\tTop1_Acc_Epoch/train_phase/train_stream/Task001 = 0.7721\n",
            "100%|██████████| 157/157 [00:03<00:00, 49.61it/s]\n",
            "Epoch 4 ended.\n",
            "\tLoss_Epoch/train_phase/train_stream/Task001 = 0.4729\n",
            "\tTop1_Acc_Epoch/train_phase/train_stream/Task001 = 0.7803\n",
            "-- >> End of training phase << --\n",
            "Evaluating on all seen tasks...\n",
            "-- >> Start of eval phase << --\n",
            "-- Starting eval on experience 0 (Task 0) from test stream --\n",
            "100%|██████████| 32/32 [00:00<00:00, 92.83it/s]\n",
            "> Eval on experience 0 (Task 0) from test stream ended.\n",
            "\tLoss_Exp/eval_phase/test_stream/Task000/Exp000 = 24.3583\n",
            "\tTop1_Acc_Exp/eval_phase/test_stream/Task000/Exp000 = 0.0000\n",
            "-- Starting eval on experience 1 (Task 1) from test stream --\n",
            "100%|██████████| 32/32 [00:00<00:00, 92.29it/s]\n",
            "> Eval on experience 1 (Task 1) from test stream ended.\n",
            "\tLoss_Exp/eval_phase/test_stream/Task001/Exp001 = 0.4973\n",
            "\tTop1_Acc_Exp/eval_phase/test_stream/Task001/Exp001 = 0.7660\n",
            "-- >> End of eval phase << --\n",
            "\tLoss_Stream/eval_phase/test_stream/Task001 = 12.4278\n",
            "\tTop1_Acc_Stream/eval_phase/test_stream/Task001 = 0.3830\n",
            "Training on classes: [4, 5]\n",
            "Training on experience 2\n",
            "-- >> Start of training phase << --\n",
            "100%|██████████| 157/157 [00:03<00:00, 49.97it/s]\n",
            "Epoch 0 ended.\n",
            "\tLoss_Epoch/train_phase/train_stream/Task002 = 1.0090\n",
            "\tTop1_Acc_Epoch/train_phase/train_stream/Task002 = 0.5705\n",
            "100%|██████████| 157/157 [00:03<00:00, 49.15it/s]\n",
            "Epoch 1 ended.\n",
            "\tLoss_Epoch/train_phase/train_stream/Task002 = 0.5280\n",
            "\tTop1_Acc_Epoch/train_phase/train_stream/Task002 = 0.7350\n",
            "100%|██████████| 157/157 [00:03<00:00, 52.11it/s]\n",
            "Epoch 2 ended.\n",
            "\tLoss_Epoch/train_phase/train_stream/Task002 = 0.4870\n",
            "\tTop1_Acc_Epoch/train_phase/train_stream/Task002 = 0.7599\n",
            "100%|██████████| 157/157 [00:03<00:00, 46.75it/s]\n",
            "Epoch 3 ended.\n",
            "\tLoss_Epoch/train_phase/train_stream/Task002 = 0.4563\n",
            "\tTop1_Acc_Epoch/train_phase/train_stream/Task002 = 0.7836\n",
            "100%|██████████| 157/157 [00:03<00:00, 49.97it/s]\n",
            "Epoch 4 ended.\n",
            "\tLoss_Epoch/train_phase/train_stream/Task002 = 0.4393\n",
            "\tTop1_Acc_Epoch/train_phase/train_stream/Task002 = 0.7969\n",
            "-- >> End of training phase << --\n",
            "Evaluating on all seen tasks...\n",
            "-- >> Start of eval phase << --\n",
            "-- Starting eval on experience 0 (Task 0) from test stream --\n",
            "100%|██████████| 32/32 [00:00<00:00, 86.99it/s]\n",
            "> Eval on experience 0 (Task 0) from test stream ended.\n",
            "\tLoss_Exp/eval_phase/test_stream/Task000/Exp000 = 16.0355\n",
            "\tTop1_Acc_Exp/eval_phase/test_stream/Task000/Exp000 = 0.0000\n",
            "-- Starting eval on experience 1 (Task 1) from test stream --\n",
            "100%|██████████| 32/32 [00:00<00:00, 90.18it/s]\n",
            "> Eval on experience 1 (Task 1) from test stream ended.\n",
            "\tLoss_Exp/eval_phase/test_stream/Task001/Exp001 = 13.5748\n",
            "\tTop1_Acc_Exp/eval_phase/test_stream/Task001/Exp001 = 0.0000\n",
            "-- Starting eval on experience 2 (Task 2) from test stream --\n",
            "100%|██████████| 32/32 [00:00<00:00, 95.02it/s]\n",
            "> Eval on experience 2 (Task 2) from test stream ended.\n",
            "\tLoss_Exp/eval_phase/test_stream/Task002/Exp002 = 0.4539\n",
            "\tTop1_Acc_Exp/eval_phase/test_stream/Task002/Exp002 = 0.7780\n",
            "-- >> End of eval phase << --\n",
            "\tLoss_Stream/eval_phase/test_stream/Task002 = 10.0214\n",
            "\tTop1_Acc_Stream/eval_phase/test_stream/Task002 = 0.2593\n",
            "Training on classes: [6, 7]\n",
            "Training on experience 3\n",
            "-- >> Start of training phase << --\n",
            "100%|██████████| 157/157 [00:03<00:00, 52.27it/s]\n",
            "Epoch 0 ended.\n",
            "\tLoss_Epoch/train_phase/train_stream/Task003 = 0.9326\n",
            "\tTop1_Acc_Epoch/train_phase/train_stream/Task003 = 0.6549\n",
            "100%|██████████| 157/157 [00:03<00:00, 51.20it/s]\n",
            "Epoch 1 ended.\n",
            "\tLoss_Epoch/train_phase/train_stream/Task003 = 0.4051\n",
            "\tTop1_Acc_Epoch/train_phase/train_stream/Task003 = 0.8185\n",
            "100%|██████████| 157/157 [00:02<00:00, 52.78it/s]\n",
            "Epoch 2 ended.\n",
            "\tLoss_Epoch/train_phase/train_stream/Task003 = 0.3609\n",
            "\tTop1_Acc_Epoch/train_phase/train_stream/Task003 = 0.8420\n",
            "100%|██████████| 157/157 [00:03<00:00, 49.45it/s]\n",
            "Epoch 3 ended.\n",
            "\tLoss_Epoch/train_phase/train_stream/Task003 = 0.3339\n",
            "\tTop1_Acc_Epoch/train_phase/train_stream/Task003 = 0.8516\n",
            "100%|██████████| 157/157 [00:03<00:00, 50.24it/s]\n",
            "Epoch 4 ended.\n",
            "\tLoss_Epoch/train_phase/train_stream/Task003 = 0.2960\n",
            "\tTop1_Acc_Epoch/train_phase/train_stream/Task003 = 0.8767\n",
            "-- >> End of training phase << --\n",
            "Evaluating on all seen tasks...\n",
            "-- >> Start of eval phase << --\n",
            "-- Starting eval on experience 0 (Task 0) from test stream --\n",
            "100%|██████████| 32/32 [00:00<00:00, 86.26it/s]\n",
            "> Eval on experience 0 (Task 0) from test stream ended.\n",
            "\tLoss_Exp/eval_phase/test_stream/Task000/Exp000 = 14.2445\n",
            "\tTop1_Acc_Exp/eval_phase/test_stream/Task000/Exp000 = 0.0000\n",
            "-- Starting eval on experience 1 (Task 1) from test stream --\n",
            "100%|██████████| 32/32 [00:00<00:00, 84.85it/s]\n",
            "> Eval on experience 1 (Task 1) from test stream ended.\n",
            "\tLoss_Exp/eval_phase/test_stream/Task001/Exp001 = 14.0897\n",
            "\tTop1_Acc_Exp/eval_phase/test_stream/Task001/Exp001 = 0.0000\n",
            "-- Starting eval on experience 2 (Task 2) from test stream --\n",
            "100%|██████████| 32/32 [00:00<00:00, 84.95it/s]\n",
            "> Eval on experience 2 (Task 2) from test stream ended.\n",
            "\tLoss_Exp/eval_phase/test_stream/Task002/Exp002 = 12.0595\n",
            "\tTop1_Acc_Exp/eval_phase/test_stream/Task002/Exp002 = 0.0000\n",
            "-- Starting eval on experience 3 (Task 3) from test stream --\n",
            "100%|██████████| 32/32 [00:00<00:00, 85.76it/s]\n",
            "> Eval on experience 3 (Task 3) from test stream ended.\n",
            "\tLoss_Exp/eval_phase/test_stream/Task003/Exp003 = 0.2997\n",
            "\tTop1_Acc_Exp/eval_phase/test_stream/Task003/Exp003 = 0.8750\n",
            "-- >> End of eval phase << --\n",
            "\tLoss_Stream/eval_phase/test_stream/Task003 = 10.1733\n",
            "\tTop1_Acc_Stream/eval_phase/test_stream/Task003 = 0.2188\n",
            "Training on classes: [8, 9]\n",
            "Training on experience 4\n",
            "-- >> Start of training phase << --\n",
            "100%|██████████| 157/157 [00:03<00:00, 45.52it/s]\n",
            "Epoch 0 ended.\n",
            "\tLoss_Epoch/train_phase/train_stream/Task004 = 1.0067\n",
            "\tTop1_Acc_Epoch/train_phase/train_stream/Task004 = 0.6446\n",
            "100%|██████████| 157/157 [00:03<00:00, 49.73it/s]\n",
            "Epoch 1 ended.\n",
            "\tLoss_Epoch/train_phase/train_stream/Task004 = 0.3808\n",
            "\tTop1_Acc_Epoch/train_phase/train_stream/Task004 = 0.8255\n",
            "100%|██████████| 157/157 [00:03<00:00, 49.82it/s]\n",
            "Epoch 2 ended.\n",
            "\tLoss_Epoch/train_phase/train_stream/Task004 = 0.3245\n",
            "\tTop1_Acc_Epoch/train_phase/train_stream/Task004 = 0.8618\n",
            "100%|██████████| 157/157 [00:03<00:00, 51.03it/s]\n",
            "Epoch 3 ended.\n",
            "\tLoss_Epoch/train_phase/train_stream/Task004 = 0.2887\n",
            "\tTop1_Acc_Epoch/train_phase/train_stream/Task004 = 0.8776\n",
            "100%|██████████| 157/157 [00:03<00:00, 50.17it/s]\n",
            "Epoch 4 ended.\n",
            "\tLoss_Epoch/train_phase/train_stream/Task004 = 0.2721\n",
            "\tTop1_Acc_Epoch/train_phase/train_stream/Task004 = 0.8909\n",
            "-- >> End of training phase << --\n",
            "Evaluating on all seen tasks...\n",
            "-- >> Start of eval phase << --\n",
            "-- Starting eval on experience 0 (Task 0) from test stream --\n",
            "100%|██████████| 32/32 [00:00<00:00, 85.32it/s]\n",
            "> Eval on experience 0 (Task 0) from test stream ended.\n",
            "\tLoss_Exp/eval_phase/test_stream/Task000/Exp000 = 16.0031\n",
            "\tTop1_Acc_Exp/eval_phase/test_stream/Task000/Exp000 = 0.0000\n",
            "-- Starting eval on experience 1 (Task 1) from test stream --\n",
            "100%|██████████| 32/32 [00:00<00:00, 90.20it/s]\n",
            "> Eval on experience 1 (Task 1) from test stream ended.\n",
            "\tLoss_Exp/eval_phase/test_stream/Task001/Exp001 = 12.7809\n",
            "\tTop1_Acc_Exp/eval_phase/test_stream/Task001/Exp001 = 0.0000\n",
            "-- Starting eval on experience 2 (Task 2) from test stream --\n",
            "100%|██████████| 32/32 [00:00<00:00, 92.39it/s]\n",
            "> Eval on experience 2 (Task 2) from test stream ended.\n",
            "\tLoss_Exp/eval_phase/test_stream/Task002/Exp002 = 13.7651\n",
            "\tTop1_Acc_Exp/eval_phase/test_stream/Task002/Exp002 = 0.0000\n",
            "-- Starting eval on experience 3 (Task 3) from test stream --\n",
            "100%|██████████| 32/32 [00:00<00:00, 92.97it/s]\n",
            "> Eval on experience 3 (Task 3) from test stream ended.\n",
            "\tLoss_Exp/eval_phase/test_stream/Task003/Exp003 = 13.1829\n",
            "\tTop1_Acc_Exp/eval_phase/test_stream/Task003/Exp003 = 0.0000\n",
            "-- Starting eval on experience 4 (Task 4) from test stream --\n",
            "100%|██████████| 32/32 [00:00<00:00, 92.58it/s]\n",
            "> Eval on experience 4 (Task 4) from test stream ended.\n",
            "\tLoss_Exp/eval_phase/test_stream/Task004/Exp004 = 0.2554\n",
            "\tTop1_Acc_Exp/eval_phase/test_stream/Task004/Exp004 = 0.8895\n",
            "-- >> End of eval phase << --\n",
            "\tLoss_Stream/eval_phase/test_stream/Task004 = 11.1975\n",
            "\tTop1_Acc_Stream/eval_phase/test_stream/Task004 = 0.1779\n",
            "\n",
            "-- Model: CNN | Strategy: EWC --\n",
            "Training on classes: [0, 1]\n",
            "Training on experience 0\n",
            "-- >> Start of training phase << --\n",
            "100%|██████████| 157/157 [00:03<00:00, 49.40it/s]\n",
            "Epoch 0 ended.\n",
            "\tLoss_Epoch/train_phase/train_stream/Task000 = 0.4592\n",
            "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.7853\n",
            "100%|██████████| 157/157 [00:03<00:00, 49.25it/s]\n",
            "Epoch 1 ended.\n",
            "\tLoss_Epoch/train_phase/train_stream/Task000 = 0.2876\n",
            "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.8782\n",
            "100%|██████████| 157/157 [00:03<00:00, 45.22it/s]\n",
            "Epoch 2 ended.\n",
            "\tLoss_Epoch/train_phase/train_stream/Task000 = 0.2337\n",
            "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.9055\n",
            "100%|██████████| 157/157 [00:03<00:00, 50.96it/s]\n",
            "Epoch 3 ended.\n",
            "\tLoss_Epoch/train_phase/train_stream/Task000 = 0.2040\n",
            "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.9189\n",
            "100%|██████████| 157/157 [00:02<00:00, 53.62it/s]\n",
            "Epoch 4 ended.\n",
            "\tLoss_Epoch/train_phase/train_stream/Task000 = 0.1909\n",
            "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.9248\n",
            "-- >> End of training phase << --\n",
            "Evaluating on all seen tasks...\n",
            "-- >> Start of eval phase << --\n",
            "-- Starting eval on experience 0 (Task 0) from test stream --\n",
            "100%|██████████| 32/32 [00:00<00:00, 87.22it/s]\n",
            "> Eval on experience 0 (Task 0) from test stream ended.\n",
            "\tLoss_Exp/eval_phase/test_stream/Task000/Exp000 = 0.1624\n",
            "\tTop1_Acc_Exp/eval_phase/test_stream/Task000/Exp000 = 0.9350\n",
            "-- >> End of eval phase << --\n",
            "\tLoss_Stream/eval_phase/test_stream/Task000 = 0.1624\n",
            "\tTop1_Acc_Stream/eval_phase/test_stream/Task000 = 0.9350\n",
            "Training on classes: [2, 3]\n",
            "Training on experience 1\n",
            "-- >> Start of training phase << --\n",
            "100%|██████████| 157/157 [00:03<00:00, 46.06it/s]\n",
            "Epoch 0 ended.\n",
            "\tLoss_Epoch/train_phase/train_stream/Task001 = 0.8900\n",
            "\tTop1_Acc_Epoch/train_phase/train_stream/Task001 = 0.6156\n",
            "100%|██████████| 157/157 [00:03<00:00, 45.06it/s]\n",
            "Epoch 1 ended.\n",
            "\tLoss_Epoch/train_phase/train_stream/Task001 = 0.5259\n",
            "\tTop1_Acc_Epoch/train_phase/train_stream/Task001 = 0.7504\n",
            "100%|██████████| 157/157 [00:03<00:00, 45.05it/s]\n",
            "Epoch 2 ended.\n",
            "\tLoss_Epoch/train_phase/train_stream/Task001 = 0.4966\n",
            "\tTop1_Acc_Epoch/train_phase/train_stream/Task001 = 0.7663\n",
            "100%|██████████| 157/157 [00:03<00:00, 47.22it/s]\n",
            "Epoch 3 ended.\n",
            "\tLoss_Epoch/train_phase/train_stream/Task001 = 0.4831\n",
            "\tTop1_Acc_Epoch/train_phase/train_stream/Task001 = 0.7757\n",
            "100%|██████████| 157/157 [00:03<00:00, 43.73it/s]\n",
            "Epoch 4 ended.\n",
            "\tLoss_Epoch/train_phase/train_stream/Task001 = 0.4624\n",
            "\tTop1_Acc_Epoch/train_phase/train_stream/Task001 = 0.7891\n",
            "-- >> End of training phase << --\n",
            "Evaluating on all seen tasks...\n",
            "-- >> Start of eval phase << --\n",
            "-- Starting eval on experience 0 (Task 0) from test stream --\n",
            "100%|██████████| 32/32 [00:00<00:00, 88.41it/s]\n",
            "> Eval on experience 0 (Task 0) from test stream ended.\n",
            "\tLoss_Exp/eval_phase/test_stream/Task000/Exp000 = 19.0980\n",
            "\tTop1_Acc_Exp/eval_phase/test_stream/Task000/Exp000 = 0.0000\n",
            "-- Starting eval on experience 1 (Task 1) from test stream --\n",
            "100%|██████████| 32/32 [00:00<00:00, 88.98it/s]\n",
            "> Eval on experience 1 (Task 1) from test stream ended.\n",
            "\tLoss_Exp/eval_phase/test_stream/Task001/Exp001 = 0.4614\n",
            "\tTop1_Acc_Exp/eval_phase/test_stream/Task001/Exp001 = 0.7865\n",
            "-- >> End of eval phase << --\n",
            "\tLoss_Stream/eval_phase/test_stream/Task001 = 9.7797\n",
            "\tTop1_Acc_Stream/eval_phase/test_stream/Task001 = 0.3932\n",
            "Training on classes: [4, 5]\n",
            "Training on experience 2\n",
            "-- >> Start of training phase << --\n",
            "100%|██████████| 157/157 [00:03<00:00, 43.34it/s]\n",
            "Epoch 0 ended.\n",
            "\tLoss_Epoch/train_phase/train_stream/Task002 = 1.1212\n",
            "\tTop1_Acc_Epoch/train_phase/train_stream/Task002 = 0.5233\n",
            "100%|██████████| 157/157 [00:03<00:00, 43.20it/s]\n",
            "Epoch 1 ended.\n",
            "\tLoss_Epoch/train_phase/train_stream/Task002 = 0.5513\n",
            "\tTop1_Acc_Epoch/train_phase/train_stream/Task002 = 0.7341\n",
            "100%|██████████| 157/157 [00:03<00:00, 44.25it/s]\n",
            "Epoch 2 ended.\n",
            "\tLoss_Epoch/train_phase/train_stream/Task002 = 0.4963\n",
            "\tTop1_Acc_Epoch/train_phase/train_stream/Task002 = 0.7760\n",
            "100%|██████████| 157/157 [00:03<00:00, 44.07it/s]\n",
            "Epoch 3 ended.\n",
            "\tLoss_Epoch/train_phase/train_stream/Task002 = 0.4539\n",
            "\tTop1_Acc_Epoch/train_phase/train_stream/Task002 = 0.7970\n",
            "100%|██████████| 157/157 [00:03<00:00, 43.79it/s]\n",
            "Epoch 4 ended.\n",
            "\tLoss_Epoch/train_phase/train_stream/Task002 = 0.4342\n",
            "\tTop1_Acc_Epoch/train_phase/train_stream/Task002 = 0.8096\n",
            "-- >> End of training phase << --\n",
            "Evaluating on all seen tasks...\n",
            "-- >> Start of eval phase << --\n",
            "-- Starting eval on experience 0 (Task 0) from test stream --\n",
            "100%|██████████| 32/32 [00:00<00:00, 94.20it/s]\n",
            "> Eval on experience 0 (Task 0) from test stream ended.\n",
            "\tLoss_Exp/eval_phase/test_stream/Task000/Exp000 = 11.3041\n",
            "\tTop1_Acc_Exp/eval_phase/test_stream/Task000/Exp000 = 0.0000\n",
            "-- Starting eval on experience 1 (Task 1) from test stream --\n",
            "100%|██████████| 32/32 [00:00<00:00, 94.25it/s]\n",
            "> Eval on experience 1 (Task 1) from test stream ended.\n",
            "\tLoss_Exp/eval_phase/test_stream/Task001/Exp001 = 10.2729\n",
            "\tTop1_Acc_Exp/eval_phase/test_stream/Task001/Exp001 = 0.0000\n",
            "-- Starting eval on experience 2 (Task 2) from test stream --\n",
            "100%|██████████| 32/32 [00:00<00:00, 93.81it/s]\n",
            "> Eval on experience 2 (Task 2) from test stream ended.\n",
            "\tLoss_Exp/eval_phase/test_stream/Task002/Exp002 = 0.4020\n",
            "\tTop1_Acc_Exp/eval_phase/test_stream/Task002/Exp002 = 0.8200\n",
            "-- >> End of eval phase << --\n",
            "\tLoss_Stream/eval_phase/test_stream/Task002 = 7.3263\n",
            "\tTop1_Acc_Stream/eval_phase/test_stream/Task002 = 0.2733\n",
            "Training on classes: [6, 7]\n",
            "Training on experience 3\n",
            "-- >> Start of training phase << --\n",
            "100%|██████████| 157/157 [00:03<00:00, 41.34it/s]\n",
            "Epoch 0 ended.\n",
            "\tLoss_Epoch/train_phase/train_stream/Task003 = 0.9424\n",
            "\tTop1_Acc_Epoch/train_phase/train_stream/Task003 = 0.6454\n",
            "100%|██████████| 157/157 [00:04<00:00, 39.18it/s]\n",
            "Epoch 1 ended.\n",
            "\tLoss_Epoch/train_phase/train_stream/Task003 = 0.4422\n",
            "\tTop1_Acc_Epoch/train_phase/train_stream/Task003 = 0.8116\n",
            "100%|██████████| 157/157 [00:03<00:00, 41.38it/s]\n",
            "Epoch 2 ended.\n",
            "\tLoss_Epoch/train_phase/train_stream/Task003 = 0.3944\n",
            "\tTop1_Acc_Epoch/train_phase/train_stream/Task003 = 0.8357\n",
            "100%|██████████| 157/157 [00:03<00:00, 42.02it/s]\n",
            "Epoch 3 ended.\n",
            "\tLoss_Epoch/train_phase/train_stream/Task003 = 0.3654\n",
            "\tTop1_Acc_Epoch/train_phase/train_stream/Task003 = 0.8504\n",
            "100%|██████████| 157/157 [00:03<00:00, 42.06it/s]\n",
            "Epoch 4 ended.\n",
            "\tLoss_Epoch/train_phase/train_stream/Task003 = 0.3201\n",
            "\tTop1_Acc_Epoch/train_phase/train_stream/Task003 = 0.8714\n",
            "-- >> End of training phase << --\n",
            "Evaluating on all seen tasks...\n",
            "-- >> Start of eval phase << --\n",
            "-- Starting eval on experience 0 (Task 0) from test stream --\n",
            "100%|██████████| 32/32 [00:00<00:00, 84.87it/s]\n",
            "> Eval on experience 0 (Task 0) from test stream ended.\n",
            "\tLoss_Exp/eval_phase/test_stream/Task000/Exp000 = 25.1838\n",
            "\tTop1_Acc_Exp/eval_phase/test_stream/Task000/Exp000 = 0.0000\n",
            "-- Starting eval on experience 1 (Task 1) from test stream --\n",
            "100%|██████████| 32/32 [00:00<00:00, 83.05it/s]\n",
            "> Eval on experience 1 (Task 1) from test stream ended.\n",
            "\tLoss_Exp/eval_phase/test_stream/Task001/Exp001 = 30.5014\n",
            "\tTop1_Acc_Exp/eval_phase/test_stream/Task001/Exp001 = 0.0000\n",
            "-- Starting eval on experience 2 (Task 2) from test stream --\n",
            "100%|██████████| 32/32 [00:00<00:00, 86.25it/s]\n",
            "> Eval on experience 2 (Task 2) from test stream ended.\n",
            "\tLoss_Exp/eval_phase/test_stream/Task002/Exp002 = 16.9432\n",
            "\tTop1_Acc_Exp/eval_phase/test_stream/Task002/Exp002 = 0.0000\n",
            "-- Starting eval on experience 3 (Task 3) from test stream --\n",
            "100%|██████████| 32/32 [00:00<00:00, 86.16it/s]\n",
            "> Eval on experience 3 (Task 3) from test stream ended.\n",
            "\tLoss_Exp/eval_phase/test_stream/Task003/Exp003 = 0.2152\n",
            "\tTop1_Acc_Exp/eval_phase/test_stream/Task003/Exp003 = 0.9095\n",
            "-- >> End of eval phase << --\n",
            "\tLoss_Stream/eval_phase/test_stream/Task003 = 18.2109\n",
            "\tTop1_Acc_Stream/eval_phase/test_stream/Task003 = 0.2274\n",
            "Training on classes: [8, 9]\n",
            "Training on experience 4\n",
            "-- >> Start of training phase << --\n",
            "100%|██████████| 157/157 [00:03<00:00, 40.62it/s]\n",
            "Epoch 0 ended.\n",
            "\tLoss_Epoch/train_phase/train_stream/Task004 = 1.1408\n",
            "\tTop1_Acc_Epoch/train_phase/train_stream/Task004 = 0.6767\n",
            "100%|██████████| 157/157 [00:03<00:00, 41.06it/s]\n",
            "Epoch 1 ended.\n",
            "\tLoss_Epoch/train_phase/train_stream/Task004 = 0.3982\n",
            "\tTop1_Acc_Epoch/train_phase/train_stream/Task004 = 0.8501\n",
            "100%|██████████| 157/157 [00:03<00:00, 41.01it/s]\n",
            "Epoch 2 ended.\n",
            "\tLoss_Epoch/train_phase/train_stream/Task004 = 0.3417\n",
            "\tTop1_Acc_Epoch/train_phase/train_stream/Task004 = 0.8732\n",
            "100%|██████████| 157/157 [00:04<00:00, 39.16it/s]\n",
            "Epoch 3 ended.\n",
            "\tLoss_Epoch/train_phase/train_stream/Task004 = 0.3304\n",
            "\tTop1_Acc_Epoch/train_phase/train_stream/Task004 = 0.8748\n",
            "100%|██████████| 157/157 [00:03<00:00, 40.60it/s]\n",
            "Epoch 4 ended.\n",
            "\tLoss_Epoch/train_phase/train_stream/Task004 = 0.3087\n",
            "\tTop1_Acc_Epoch/train_phase/train_stream/Task004 = 0.8877\n",
            "-- >> End of training phase << --\n",
            "Evaluating on all seen tasks...\n",
            "-- >> Start of eval phase << --\n",
            "-- Starting eval on experience 0 (Task 0) from test stream --\n",
            "100%|██████████| 32/32 [00:00<00:00, 84.10it/s]\n",
            "> Eval on experience 0 (Task 0) from test stream ended.\n",
            "\tLoss_Exp/eval_phase/test_stream/Task000/Exp000 = 11.5663\n",
            "\tTop1_Acc_Exp/eval_phase/test_stream/Task000/Exp000 = 0.0000\n",
            "-- Starting eval on experience 1 (Task 1) from test stream --\n",
            "100%|██████████| 32/32 [00:00<00:00, 84.84it/s]\n",
            "> Eval on experience 1 (Task 1) from test stream ended.\n",
            "\tLoss_Exp/eval_phase/test_stream/Task001/Exp001 = 10.5553\n",
            "\tTop1_Acc_Exp/eval_phase/test_stream/Task001/Exp001 = 0.0000\n",
            "-- Starting eval on experience 2 (Task 2) from test stream --\n",
            "100%|██████████| 32/32 [00:00<00:00, 84.36it/s]\n",
            "> Eval on experience 2 (Task 2) from test stream ended.\n",
            "\tLoss_Exp/eval_phase/test_stream/Task002/Exp002 = 11.7319\n",
            "\tTop1_Acc_Exp/eval_phase/test_stream/Task002/Exp002 = 0.0000\n",
            "-- Starting eval on experience 3 (Task 3) from test stream --\n",
            "100%|██████████| 32/32 [00:00<00:00, 85.70it/s]\n",
            "> Eval on experience 3 (Task 3) from test stream ended.\n",
            "\tLoss_Exp/eval_phase/test_stream/Task003/Exp003 = 12.4441\n",
            "\tTop1_Acc_Exp/eval_phase/test_stream/Task003/Exp003 = 0.0000\n",
            "-- Starting eval on experience 4 (Task 4) from test stream --\n",
            "100%|██████████| 32/32 [00:00<00:00, 88.27it/s]\n",
            "> Eval on experience 4 (Task 4) from test stream ended.\n",
            "\tLoss_Exp/eval_phase/test_stream/Task004/Exp004 = 0.2621\n",
            "\tTop1_Acc_Exp/eval_phase/test_stream/Task004/Exp004 = 0.8895\n",
            "-- >> End of eval phase << --\n",
            "\tLoss_Stream/eval_phase/test_stream/Task004 = 9.3119\n",
            "\tTop1_Acc_Stream/eval_phase/test_stream/Task004 = 0.1779\n",
            "\n",
            "-- Model: CNN | Strategy: RICS --\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/avalanche/training/templates/base.py:468: PositionalArgumentsDeprecatedWarning: Avalanche is transitioning to strategy constructors that accept named (keyword) arguments only. This is done to ensure that there is no confusion regarding the meaning of each argument (strategies can have many arguments). Your are passing 3 positional arguments to the SupervisedTemplate.__init__ method. Consider passing them as names arguments. The ability to pass positional arguments will be removed in the future.\n",
            "  warnings.warn(error_str, category=PositionalArgumentsDeprecatedWarning)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training on classes: [0, 1]\n",
            "Training on experience 0\n",
            "-- >> Start of training phase << --\n",
            "100%|██████████| 157/157 [00:03<00:00, 49.31it/s]\n",
            "Epoch 0 ended.\n",
            "\tLoss_Epoch/train_phase/train_stream/Task000 = 0.4496\n",
            "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.7899\n",
            "100%|██████████| 157/157 [00:03<00:00, 48.83it/s]\n",
            "Epoch 1 ended.\n",
            "\tLoss_Epoch/train_phase/train_stream/Task000 = 0.2894\n",
            "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.8733\n",
            "100%|██████████| 157/157 [00:03<00:00, 48.32it/s]\n",
            "Epoch 2 ended.\n",
            "\tLoss_Epoch/train_phase/train_stream/Task000 = 0.2389\n",
            "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.9004\n",
            "100%|██████████| 157/157 [00:03<00:00, 49.42it/s]\n",
            "Epoch 3 ended.\n",
            "\tLoss_Epoch/train_phase/train_stream/Task000 = 0.2096\n",
            "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.9135\n",
            "100%|██████████| 157/157 [00:03<00:00, 49.36it/s]\n",
            "Epoch 4 ended.\n",
            "\tLoss_Epoch/train_phase/train_stream/Task000 = 0.1837\n",
            "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.9278\n",
            "-- >> End of training phase << --\n",
            "Evaluating on all seen tasks...\n",
            "-- >> Start of eval phase << --\n",
            "-- Starting eval on experience 0 (Task 0) from test stream --\n",
            "100%|██████████| 32/32 [00:00<00:00, 90.73it/s]\n",
            "> Eval on experience 0 (Task 0) from test stream ended.\n",
            "\tLoss_Exp/eval_phase/test_stream/Task000/Exp000 = 0.1334\n",
            "\tTop1_Acc_Exp/eval_phase/test_stream/Task000/Exp000 = 0.9460\n",
            "-- >> End of eval phase << --\n",
            "\tLoss_Stream/eval_phase/test_stream/Task000 = 0.1334\n",
            "\tTop1_Acc_Stream/eval_phase/test_stream/Task000 = 0.9460\n",
            "Training on classes: [2, 3]\n",
            "Training on experience 1\n",
            "-- >> Start of training phase << --\n",
            "100%|██████████| 157/157 [00:03<00:00, 45.80it/s]\n",
            "Epoch 0 ended.\n",
            "\tLoss_Epoch/train_phase/train_stream/Task001 = 0.8690\n",
            "\tTop1_Acc_Epoch/train_phase/train_stream/Task001 = 0.6035\n",
            "100%|██████████| 157/157 [00:03<00:00, 50.63it/s]\n",
            "Epoch 1 ended.\n",
            "\tLoss_Epoch/train_phase/train_stream/Task001 = 0.5461\n",
            "\tTop1_Acc_Epoch/train_phase/train_stream/Task001 = 0.7319\n",
            "100%|██████████| 157/157 [00:03<00:00, 48.67it/s]\n",
            "Epoch 2 ended.\n",
            "\tLoss_Epoch/train_phase/train_stream/Task001 = 0.5117\n",
            "\tTop1_Acc_Epoch/train_phase/train_stream/Task001 = 0.7595\n",
            "100%|██████████| 157/157 [00:03<00:00, 49.08it/s]\n",
            "Epoch 3 ended.\n",
            "\tLoss_Epoch/train_phase/train_stream/Task001 = 0.4925\n",
            "\tTop1_Acc_Epoch/train_phase/train_stream/Task001 = 0.7688\n",
            "100%|██████████| 157/157 [00:03<00:00, 50.30it/s]\n",
            "Epoch 4 ended.\n",
            "\tLoss_Epoch/train_phase/train_stream/Task001 = 0.4656\n",
            "\tTop1_Acc_Epoch/train_phase/train_stream/Task001 = 0.7843\n",
            "-- >> End of training phase << --\n",
            "Evaluating on all seen tasks...\n",
            "-- >> Start of eval phase << --\n",
            "-- Starting eval on experience 0 (Task 0) from test stream --\n",
            "100%|██████████| 32/32 [00:00<00:00, 92.84it/s]\n",
            "> Eval on experience 0 (Task 0) from test stream ended.\n",
            "\tLoss_Exp/eval_phase/test_stream/Task000/Exp000 = 17.6787\n",
            "\tTop1_Acc_Exp/eval_phase/test_stream/Task000/Exp000 = 0.0000\n",
            "-- Starting eval on experience 1 (Task 1) from test stream --\n",
            "100%|██████████| 32/32 [00:00<00:00, 87.84it/s]\n",
            "> Eval on experience 1 (Task 1) from test stream ended.\n",
            "\tLoss_Exp/eval_phase/test_stream/Task001/Exp001 = 0.4604\n",
            "\tTop1_Acc_Exp/eval_phase/test_stream/Task001/Exp001 = 0.7825\n",
            "-- >> End of eval phase << --\n",
            "\tLoss_Stream/eval_phase/test_stream/Task001 = 9.0695\n",
            "\tTop1_Acc_Stream/eval_phase/test_stream/Task001 = 0.3912\n",
            "Training on classes: [4, 5]\n",
            "Training on experience 2\n",
            "-- >> Start of training phase << --\n",
            "100%|██████████| 157/157 [00:03<00:00, 51.45it/s]\n",
            "Epoch 0 ended.\n",
            "\tLoss_Epoch/train_phase/train_stream/Task002 = 0.9080\n",
            "\tTop1_Acc_Epoch/train_phase/train_stream/Task002 = 0.6021\n",
            "100%|██████████| 157/157 [00:02<00:00, 52.71it/s]\n",
            "Epoch 1 ended.\n",
            "\tLoss_Epoch/train_phase/train_stream/Task002 = 0.5408\n",
            "\tTop1_Acc_Epoch/train_phase/train_stream/Task002 = 0.7158\n",
            "100%|██████████| 157/157 [00:03<00:00, 49.15it/s]\n",
            "Epoch 2 ended.\n",
            "\tLoss_Epoch/train_phase/train_stream/Task002 = 0.5171\n",
            "\tTop1_Acc_Epoch/train_phase/train_stream/Task002 = 0.7416\n",
            "100%|██████████| 157/157 [00:03<00:00, 48.11it/s]\n",
            "Epoch 3 ended.\n",
            "\tLoss_Epoch/train_phase/train_stream/Task002 = 0.4871\n",
            "\tTop1_Acc_Epoch/train_phase/train_stream/Task002 = 0.7714\n",
            "100%|██████████| 157/157 [00:02<00:00, 52.63it/s]\n",
            "Epoch 4 ended.\n",
            "\tLoss_Epoch/train_phase/train_stream/Task002 = 0.4667\n",
            "\tTop1_Acc_Epoch/train_phase/train_stream/Task002 = 0.7797\n",
            "-- >> End of training phase << --\n",
            "Evaluating on all seen tasks...\n",
            "-- >> Start of eval phase << --\n",
            "-- Starting eval on experience 0 (Task 0) from test stream --\n",
            "100%|██████████| 32/32 [00:00<00:00, 92.60it/s]\n",
            "> Eval on experience 0 (Task 0) from test stream ended.\n",
            "\tLoss_Exp/eval_phase/test_stream/Task000/Exp000 = 12.0588\n",
            "\tTop1_Acc_Exp/eval_phase/test_stream/Task000/Exp000 = 0.0000\n",
            "-- Starting eval on experience 1 (Task 1) from test stream --\n",
            "100%|██████████| 32/32 [00:00<00:00, 87.91it/s]\n",
            "> Eval on experience 1 (Task 1) from test stream ended.\n",
            "\tLoss_Exp/eval_phase/test_stream/Task001/Exp001 = 11.8280\n",
            "\tTop1_Acc_Exp/eval_phase/test_stream/Task001/Exp001 = 0.0000\n",
            "-- Starting eval on experience 2 (Task 2) from test stream --\n",
            "100%|██████████| 32/32 [00:00<00:00, 90.45it/s]\n",
            "> Eval on experience 2 (Task 2) from test stream ended.\n",
            "\tLoss_Exp/eval_phase/test_stream/Task002/Exp002 = 0.4213\n",
            "\tTop1_Acc_Exp/eval_phase/test_stream/Task002/Exp002 = 0.8130\n",
            "-- >> End of eval phase << --\n",
            "\tLoss_Stream/eval_phase/test_stream/Task002 = 8.1027\n",
            "\tTop1_Acc_Stream/eval_phase/test_stream/Task002 = 0.2710\n",
            "Training on classes: [6, 7]\n",
            "Training on experience 3\n",
            "-- >> Start of training phase << --\n",
            "100%|██████████| 157/157 [00:03<00:00, 49.44it/s]\n",
            "Epoch 0 ended.\n",
            "\tLoss_Epoch/train_phase/train_stream/Task003 = 1.1312\n",
            "\tTop1_Acc_Epoch/train_phase/train_stream/Task003 = 0.5853\n",
            "100%|██████████| 157/157 [00:03<00:00, 49.54it/s]\n",
            "Epoch 1 ended.\n",
            "\tLoss_Epoch/train_phase/train_stream/Task003 = 0.3807\n",
            "\tTop1_Acc_Epoch/train_phase/train_stream/Task003 = 0.8310\n",
            "100%|██████████| 157/157 [00:03<00:00, 51.50it/s]\n",
            "Epoch 2 ended.\n",
            "\tLoss_Epoch/train_phase/train_stream/Task003 = 0.3088\n",
            "\tTop1_Acc_Epoch/train_phase/train_stream/Task003 = 0.8735\n",
            "100%|██████████| 157/157 [00:03<00:00, 50.84it/s]\n",
            "Epoch 3 ended.\n",
            "\tLoss_Epoch/train_phase/train_stream/Task003 = 0.2291\n",
            "\tTop1_Acc_Epoch/train_phase/train_stream/Task003 = 0.9063\n",
            "100%|██████████| 157/157 [00:03<00:00, 51.01it/s]\n",
            "Epoch 4 ended.\n",
            "\tLoss_Epoch/train_phase/train_stream/Task003 = 0.1884\n",
            "\tTop1_Acc_Epoch/train_phase/train_stream/Task003 = 0.9245\n",
            "-- >> End of training phase << --\n",
            "Evaluating on all seen tasks...\n",
            "-- >> Start of eval phase << --\n",
            "-- Starting eval on experience 0 (Task 0) from test stream --\n",
            "100%|██████████| 32/32 [00:00<00:00, 86.09it/s]\n",
            "> Eval on experience 0 (Task 0) from test stream ended.\n",
            "\tLoss_Exp/eval_phase/test_stream/Task000/Exp000 = 23.1045\n",
            "\tTop1_Acc_Exp/eval_phase/test_stream/Task000/Exp000 = 0.0000\n",
            "-- Starting eval on experience 1 (Task 1) from test stream --\n",
            "100%|██████████| 32/32 [00:00<00:00, 91.44it/s]\n",
            "> Eval on experience 1 (Task 1) from test stream ended.\n",
            "\tLoss_Exp/eval_phase/test_stream/Task001/Exp001 = 19.3975\n",
            "\tTop1_Acc_Exp/eval_phase/test_stream/Task001/Exp001 = 0.0000\n",
            "-- Starting eval on experience 2 (Task 2) from test stream --\n",
            "100%|██████████| 32/32 [00:00<00:00, 95.42it/s]\n",
            "> Eval on experience 2 (Task 2) from test stream ended.\n",
            "\tLoss_Exp/eval_phase/test_stream/Task002/Exp002 = 17.6163\n",
            "\tTop1_Acc_Exp/eval_phase/test_stream/Task002/Exp002 = 0.0000\n",
            "-- Starting eval on experience 3 (Task 3) from test stream --\n",
            "100%|██████████| 32/32 [00:00<00:00, 89.39it/s]\n",
            "> Eval on experience 3 (Task 3) from test stream ended.\n",
            "\tLoss_Exp/eval_phase/test_stream/Task003/Exp003 = 0.1794\n",
            "\tTop1_Acc_Exp/eval_phase/test_stream/Task003/Exp003 = 0.9220\n",
            "-- >> End of eval phase << --\n",
            "\tLoss_Stream/eval_phase/test_stream/Task003 = 15.0744\n",
            "\tTop1_Acc_Stream/eval_phase/test_stream/Task003 = 0.2305\n",
            "Training on classes: [8, 9]\n",
            "Training on experience 4\n",
            "-- >> Start of training phase << --\n",
            "100%|██████████| 157/157 [00:03<00:00, 48.95it/s]\n",
            "Epoch 0 ended.\n",
            "\tLoss_Epoch/train_phase/train_stream/Task004 = 1.2464\n",
            "\tTop1_Acc_Epoch/train_phase/train_stream/Task004 = 0.5513\n",
            "100%|██████████| 157/157 [00:03<00:00, 49.69it/s]\n",
            "Epoch 1 ended.\n",
            "\tLoss_Epoch/train_phase/train_stream/Task004 = 0.5819\n",
            "\tTop1_Acc_Epoch/train_phase/train_stream/Task004 = 0.7000\n",
            "100%|██████████| 157/157 [00:02<00:00, 53.23it/s]\n",
            "Epoch 2 ended.\n",
            "\tLoss_Epoch/train_phase/train_stream/Task004 = 0.5349\n",
            "\tTop1_Acc_Epoch/train_phase/train_stream/Task004 = 0.7389\n",
            "100%|██████████| 157/157 [00:03<00:00, 50.53it/s]\n",
            "Epoch 3 ended.\n",
            "\tLoss_Epoch/train_phase/train_stream/Task004 = 0.5018\n",
            "\tTop1_Acc_Epoch/train_phase/train_stream/Task004 = 0.7570\n",
            "100%|██████████| 157/157 [00:03<00:00, 50.53it/s]\n",
            "Epoch 4 ended.\n",
            "\tLoss_Epoch/train_phase/train_stream/Task004 = 0.4699\n",
            "\tTop1_Acc_Epoch/train_phase/train_stream/Task004 = 0.7772\n",
            "-- >> End of training phase << --\n",
            "Evaluating on all seen tasks...\n",
            "-- >> Start of eval phase << --\n",
            "-- Starting eval on experience 0 (Task 0) from test stream --\n",
            "100%|██████████| 32/32 [00:00<00:00, 91.45it/s]\n",
            "> Eval on experience 0 (Task 0) from test stream ended.\n",
            "\tLoss_Exp/eval_phase/test_stream/Task000/Exp000 = 22.1061\n",
            "\tTop1_Acc_Exp/eval_phase/test_stream/Task000/Exp000 = 0.0000\n",
            "-- Starting eval on experience 1 (Task 1) from test stream --\n",
            "100%|██████████| 32/32 [00:00<00:00, 87.98it/s]\n",
            "> Eval on experience 1 (Task 1) from test stream ended.\n",
            "\tLoss_Exp/eval_phase/test_stream/Task001/Exp001 = 25.1631\n",
            "\tTop1_Acc_Exp/eval_phase/test_stream/Task001/Exp001 = 0.0000\n",
            "-- Starting eval on experience 2 (Task 2) from test stream --\n",
            "100%|██████████| 32/32 [00:00<00:00, 89.16it/s]\n",
            "> Eval on experience 2 (Task 2) from test stream ended.\n",
            "\tLoss_Exp/eval_phase/test_stream/Task002/Exp002 = 25.3011\n",
            "\tTop1_Acc_Exp/eval_phase/test_stream/Task002/Exp002 = 0.0000\n",
            "-- Starting eval on experience 3 (Task 3) from test stream --\n",
            "100%|██████████| 32/32 [00:00<00:00, 84.90it/s]\n",
            "> Eval on experience 3 (Task 3) from test stream ended.\n",
            "\tLoss_Exp/eval_phase/test_stream/Task003/Exp003 = 30.8471\n",
            "\tTop1_Acc_Exp/eval_phase/test_stream/Task003/Exp003 = 0.0000\n",
            "-- Starting eval on experience 4 (Task 4) from test stream --\n",
            "100%|██████████| 32/32 [00:00<00:00, 87.83it/s]\n",
            "> Eval on experience 4 (Task 4) from test stream ended.\n",
            "\tLoss_Exp/eval_phase/test_stream/Task004/Exp004 = 0.4465\n",
            "\tTop1_Acc_Exp/eval_phase/test_stream/Task004/Exp004 = 0.8000\n",
            "-- >> End of eval phase << --\n",
            "\tLoss_Stream/eval_phase/test_stream/Task004 = 20.7728\n",
            "\tTop1_Acc_Stream/eval_phase/test_stream/Task004 = 0.1600\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Approch 2"
      ],
      "metadata": {
        "id": "kd5NVFDonsxm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# rics_cnn_experiment.py\n",
        "\"\"\"End‑to‑end reproducible experiment script for CIFAR‑10 Class‑IL.\n",
        "\n",
        "It runs three strategies side‑by‑side:\n",
        "* Naïve fine‑tuning (baseline)\n",
        "* EWC       (elastic‑weight consolidation)\n",
        "* RICS      (our proposed method)\n",
        "\n",
        "Requirements (tested with Avalanche 0.4.0):\n",
        "    pip install avalanche-lib torch torchvision\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "SsNyUdKWn2h0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class ClusterAwareReplayFreeCL(SupervisedTemplate):\n",
        "    def __init__(self, *, model, optimizer, lambda_intra=1.0, lambda_anchor=10.0, lambda_logit=1.0, lambda_var=1.0, criterion=nn.CrossEntropyLoss(), **kwargs):\n",
        "        super().__init__(model=model, optimizer=optimizer, criterion=criterion, **kwargs)\n",
        "\n",
        "        # Save base values for decay\n",
        "        self.base_lambda_anchor = lambda_anchor\n",
        "        self.base_lambda_logit = lambda_logit\n",
        "        self.base_lambda_var = lambda_var\n",
        "\n",
        "        self.lambda_intra = lambda_intra\n",
        "        self.lambda_anchor = lambda_anchor\n",
        "        self.lambda_logit = lambda_logit\n",
        "        self.lambda_var = lambda_var\n",
        "        self.prev_centroids: Dict[int, torch.Tensor] = {}\n",
        "        self.prev_variances: Dict[int, torch.Tensor] = {}\n",
        "        self.model_old = None\n",
        "        self.logits = None\n",
        "        self.current_feats = None\n",
        "\n",
        "    def forward(self):\n",
        "        self.current_feats, self.logits = self.model(self.mb_x, return_feats=True)\n",
        "        return self.logits\n",
        "\n",
        "    def criterion(self):\n",
        "        ce_loss = self._criterion(self.logits, self.mb_y)\n",
        "        feats = F.normalize(self.current_feats, p=2, dim=1)\n",
        "        targets = self.mb_y\n",
        "\n",
        "        # Current centroids and variances\n",
        "        curr_centroids, curr_variances = {}, {}\n",
        "        for cls in torch.unique(targets):\n",
        "          mask = (targets == cls)\n",
        "          feats_cls = F.normalize(feats[mask], p=2, dim=1)  # Normalize feature vectors\n",
        "          curr_centroids[cls.item()] = feats_cls.mean(0)\n",
        "          curr_variances[cls.item()] = feats_cls.var(0)\n",
        "\n",
        "        # Intra-task cluster separation\n",
        "        inter_cluster_loss = 0.0\n",
        "        cls_list = list(curr_centroids.keys())\n",
        "        for i in range(len(cls_list)):\n",
        "            for j in range(i + 1, len(cls_list)):\n",
        "                inter_cluster_loss += F.mse_loss(curr_centroids[cls_list[i]], curr_centroids[cls_list[j]])\n",
        "        if len(cls_list) > 1:\n",
        "            inter_cluster_loss /= len(cls_list) * (len(cls_list) - 1) / 2\n",
        "\n",
        "        # Cross-task centroid anchoring\n",
        "        anchor_loss = 0.0\n",
        "        for cls, prev_mu in self.prev_centroids.items():\n",
        "            if cls in curr_centroids:\n",
        "                anchor_loss += F.mse_loss(curr_centroids[cls], prev_mu.to(feats.device))\n",
        "        if self.prev_centroids:\n",
        "            anchor_loss /= len(self.prev_centroids)\n",
        "\n",
        "        # Variance anchoring\n",
        "        var_loss = 0.0\n",
        "        for cls, prev_var in self.prev_variances.items():\n",
        "            if cls in curr_variances:\n",
        "                var_loss += F.mse_loss(curr_variances[cls], prev_var.to(feats.device))\n",
        "        if self.prev_variances:\n",
        "            var_loss /= len(self.prev_variances)\n",
        "\n",
        "        logit_loss = 0.0\n",
        "        if self.model_old is not None:\n",
        "            with torch.no_grad():\n",
        "                old_logits = self.model_old(self.mb_x)\n",
        "            logit_loss = F.mse_loss(self.logits, old_logits)\n",
        "\n",
        "        #logit_loss = 0.0\n",
        "        # if self.model_old is not None:\n",
        "        #     with torch.no_grad():\n",
        "        #         old_logits = self.model_old(self.mb_x)\n",
        "        #     logit_loss = 1 - F.cosine_similarity(self.logits, old_logits, dim=1).mean()\n",
        "\n",
        "        # norm_loss = 0.0\n",
        "        # if self.model_old is not None:\n",
        "        #     for (p_new, p_old) in zip(self.model.parameters(), self.model_old.parameters()):\n",
        "        #         norm_loss += torch.norm(p_new - p_old, p=2)\n",
        "\n",
        "        feat_loss = 0.0\n",
        "        if self.model_old is not None:\n",
        "            with torch.no_grad():\n",
        "                old_feats, _ = self.model_old(self.mb_x, return_feats=True)\n",
        "            feat_loss = F.mse_loss(self.current_feats, old_feats)\n",
        "\n",
        "        return (\n",
        "            ce_loss +\n",
        "            self.lambda_intra * inter_cluster_loss +\n",
        "            self.lambda_anchor * anchor_loss +\n",
        "            self.lambda_logit * logit_loss +\n",
        "            self.lambda_var * var_loss +\n",
        "            0.001 * feat_loss  # small weight to avoid hurting plasticity\n",
        "        )\n",
        "\n",
        "\n",
        "        # return (\n",
        "        #     ce_loss +\n",
        "        #     self.lambda_intra * inter_cluster_loss +\n",
        "        #     self.lambda_anchor * anchor_loss +\n",
        "        #     self.lambda_logit * logit_loss +\n",
        "        #     self.lambda_var * var_loss\n",
        "        #)\n",
        "\n",
        "    def _before_training_iteration(self, **kwargs):\n",
        "        self.logits = None\n",
        "        self.current_feats = None\n",
        "        current_task = self.experience.current_experience\n",
        "        # Adaptive decay\n",
        "        decay_factor = 0.5 ** current_task\n",
        "        self.lambda_anchor = self.base_lambda_anchor * decay_factor\n",
        "        self.lambda_logit  = self.base_lambda_logit * decay_factor\n",
        "        self.lambda_var    = self.base_lambda_var * decay_factor\n",
        "\n",
        "        #print(f\"[λ] Task {current_task} | λ_anchor={self.lambda_anchor:.3f} | λ_logit={self.lambda_logit:.3f} | λ_var={self.lambda_var:.3f}\")\n",
        "\n",
        "        super()._before_training_iteration(**kwargs)\n",
        "\n",
        "    def _after_training_exp(self, **kwargs):\n",
        "        print(\"[Replay-Free CL] Saving centroids, variances, and freezing model.\")\n",
        "        self.model.eval()\n",
        "        dl = DataLoader(self.experience.dataset.eval(), batch_size=256, shuffle=False)\n",
        "        centroids, variances = {}, {}\n",
        "\n",
        "        with torch.no_grad():\n",
        "            for x, y, *_ in dl:\n",
        "                x, y = x.to(self.device), y.to(self.device)\n",
        "                feats, _ = self.model(x, return_feats=True)\n",
        "                feats = F.normalize(feats, p=2, dim=1)\n",
        "                for cls in torch.unique(y):\n",
        "                    mask = y == cls\n",
        "                    feats_cls = feats[mask]\n",
        "                    if mask.any():\n",
        "                        if cls.item() not in centroids:\n",
        "                            centroids[cls.item()] = []\n",
        "                            variances[cls.item()] = []\n",
        "                        centroids[cls.item()].append(feats_cls.mean(0))\n",
        "                        variances[cls.item()].append(feats_cls.var(0))\n",
        "\n",
        "        for cls in centroids:\n",
        "            self.prev_centroids[cls] = torch.stack(centroids[cls]).mean(0).detach().cpu()\n",
        "            self.prev_variances[cls] = torch.stack(variances[cls]).mean(0).detach().cpu()\n",
        "\n",
        "\n",
        "        # Freeze previous model for logit anchoring\n",
        "        self.model_old = SimpleCNN()\n",
        "        self.model_old.load_state_dict(self.model.state_dict())\n",
        "        self.model_old.to(self.device)\n",
        "        self.model_old.eval()\n",
        "\n",
        "        print(f\"[Freeze] Model frozen at task {self.experience.current_experience}\")\n",
        "\n",
        "        for p in self.model_old.parameters():\n",
        "            p.requires_grad = False\n",
        "\n",
        "        self.model.train()\n",
        "        super()._after_training_exp(**kwargs)\n"
      ],
      "metadata": {
        "id": "U-9cgo4PSNA1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Reply based\n"
      ],
      "metadata": {
        "id": "mcG2yndHToq6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = SimpleCNN()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "strategy = ClusterAwareReplayFreeCL(\n",
        "    model=model,\n",
        "    optimizer=optimizer,\n",
        "    train_mb_size=64,\n",
        "    train_epochs=5,\n",
        "    eval_mb_size=128,\n",
        "    device=device,\n",
        "    lambda_intra=5.0,\n",
        "    lambda_logit= 1,\n",
        "    lambda_anchor = 0.5,\n",
        "    lambda_var =0,\n",
        "    evaluator=eval_plugin\n",
        ")\n"
      ],
      "metadata": {
        "id": "lPlU88VbaxWc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# train & eval\n",
        "\n",
        "for experience in benchmark_class_il.train_stream:\n",
        "    current_classes = list(set(experience.dataset.targets))\n",
        "    print(f\"Training on classes: {current_classes}\")\n",
        "    print(\"Training on experience\", experience.current_experience)\n",
        "\n",
        "    strategy.train(experience)\n",
        "\n",
        "    print(\"Evaluating on all seen tasks...\")\n",
        "    strategy.eval(benchmark_class_il.test_stream[: experience.current_experience + 1])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HQsPUJr3TyZP",
        "outputId": "96b91865-4cc5-4898-ac8c-76afcd6366d7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training on classes: [0, 1]\n",
            "Training on experience 0\n",
            "-- >> Start of training phase << --\n",
            "100%|██████████| 157/157 [03:38<00:00,  1.39s/it]\n",
            "Epoch 0 ended.\n",
            "\tLoss_Epoch/train_phase/train_stream/Task000 = 0.4610\n",
            "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.7812\n",
            "100%|██████████| 157/157 [00:03<00:00, 48.92it/s]\n",
            "Epoch 1 ended.\n",
            "\tLoss_Epoch/train_phase/train_stream/Task000 = 0.2887\n",
            "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.8800\n",
            "100%|██████████| 157/157 [00:03<00:00, 44.29it/s]\n",
            "Epoch 2 ended.\n",
            "\tLoss_Epoch/train_phase/train_stream/Task000 = 0.2354\n",
            "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.9026\n",
            "100%|██████████| 157/157 [00:03<00:00, 49.04it/s]\n",
            "Epoch 3 ended.\n",
            "\tLoss_Epoch/train_phase/train_stream/Task000 = 0.2159\n",
            "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.9134\n",
            "100%|██████████| 157/157 [00:03<00:00, 48.11it/s]\n",
            "Epoch 4 ended.\n",
            "\tLoss_Epoch/train_phase/train_stream/Task000 = 0.1959\n",
            "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.9213\n",
            "[Replay-Free CL] Saving centroids, variances, and freezing model.\n",
            "[Freeze] Model frozen at task 0\n",
            "-- >> End of training phase << --\n",
            "Evaluating on all seen tasks...\n",
            "-- >> Start of eval phase << --\n",
            "-- Starting eval on experience 0 (Task 0) from test stream --\n",
            "100%|██████████| 16/16 [00:00<00:00, 35.43it/s]\n",
            "> Eval on experience 0 (Task 0) from test stream ended.\n",
            "\tLoss_Exp/eval_phase/test_stream/Task000/Exp000 = 0.1509\n",
            "\tTop1_Acc_Exp/eval_phase/test_stream/Task000/Exp000 = 0.9425\n",
            "-- >> End of eval phase << --\n",
            "\tLoss_Stream/eval_phase/test_stream/Task000 = 0.1509\n",
            "\tTop1_Acc_Stream/eval_phase/test_stream/Task000 = 0.9425\n",
            "Training on classes: [2, 3]\n",
            "Training on experience 1\n",
            "-- >> Start of training phase << --\n",
            "100%|██████████| 157/157 [00:03<00:00, 39.66it/s]\n",
            "Epoch 0 ended.\n",
            "\tLoss_Epoch/train_phase/train_stream/Task000 = 11.4321\n",
            "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.0000\n",
            "100%|██████████| 157/157 [00:03<00:00, 41.61it/s]\n",
            "Epoch 1 ended.\n",
            "\tLoss_Epoch/train_phase/train_stream/Task000 = 10.9524\n",
            "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.0000\n",
            "100%|██████████| 157/157 [00:03<00:00, 39.62it/s]\n",
            "Epoch 2 ended.\n",
            "\tLoss_Epoch/train_phase/train_stream/Task000 = 10.8286\n",
            "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.0000\n",
            "100%|██████████| 157/157 [00:04<00:00, 38.14it/s]\n",
            "Epoch 3 ended.\n",
            "\tLoss_Epoch/train_phase/train_stream/Task000 = 10.8041\n",
            "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.0000\n",
            "100%|██████████| 157/157 [00:03<00:00, 39.53it/s]\n",
            "Epoch 4 ended.\n",
            "\tLoss_Epoch/train_phase/train_stream/Task000 = 10.7769\n",
            "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.0000\n",
            "[Replay-Free CL] Saving centroids, variances, and freezing model.\n",
            "[Freeze] Model frozen at task 1\n",
            "-- >> End of training phase << --\n",
            "Evaluating on all seen tasks...\n",
            "-- >> Start of eval phase << --\n",
            "-- Starting eval on experience 0 (Task 0) from test stream --\n",
            "100%|██████████| 16/16 [00:00<00:00, 35.80it/s]\n",
            "> Eval on experience 0 (Task 0) from test stream ended.\n",
            "\tLoss_Exp/eval_phase/test_stream/Task000/Exp000 = 0.2990\n",
            "\tTop1_Acc_Exp/eval_phase/test_stream/Task000/Exp000 = 0.9315\n",
            "-- Starting eval on experience 1 (Task 0) from test stream --\n",
            "100%|██████████| 16/16 [00:00<00:00, 34.52it/s]\n",
            "> Eval on experience 1 (Task 0) from test stream ended.\n",
            "\tLoss_Exp/eval_phase/test_stream/Task000/Exp001 = 5.5922\n",
            "\tTop1_Acc_Exp/eval_phase/test_stream/Task000/Exp001 = 0.0000\n",
            "-- >> End of eval phase << --\n",
            "\tLoss_Stream/eval_phase/test_stream/Task000 = 2.9456\n",
            "\tTop1_Acc_Stream/eval_phase/test_stream/Task000 = 0.4657\n",
            "Training on classes: [4, 5]\n",
            "Training on experience 2\n",
            "-- >> Start of training phase << --\n",
            "100%|██████████| 157/157 [00:03<00:00, 39.36it/s]\n",
            "Epoch 0 ended.\n",
            "\tLoss_Epoch/train_phase/train_stream/Task000 = 7.4828\n",
            "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.0059\n",
            "100%|██████████| 157/157 [00:03<00:00, 40.55it/s]\n",
            "Epoch 1 ended.\n",
            "\tLoss_Epoch/train_phase/train_stream/Task000 = 7.1436\n",
            "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.0147\n",
            "100%|██████████| 157/157 [00:04<00:00, 39.09it/s]\n",
            "Epoch 2 ended.\n",
            "\tLoss_Epoch/train_phase/train_stream/Task000 = 7.0939\n",
            "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.0150\n",
            "100%|██████████| 157/157 [00:04<00:00, 38.35it/s]\n",
            "Epoch 3 ended.\n",
            "\tLoss_Epoch/train_phase/train_stream/Task000 = 7.0446\n",
            "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.0187\n",
            "100%|██████████| 157/157 [00:03<00:00, 41.22it/s]\n",
            "Epoch 4 ended.\n",
            "\tLoss_Epoch/train_phase/train_stream/Task000 = 7.0180\n",
            "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.0173\n",
            "[Replay-Free CL] Saving centroids, variances, and freezing model.\n",
            "[Freeze] Model frozen at task 2\n",
            "-- >> End of training phase << --\n",
            "Evaluating on all seen tasks...\n",
            "-- >> Start of eval phase << --\n",
            "-- Starting eval on experience 0 (Task 0) from test stream --\n",
            "100%|██████████| 16/16 [00:00<00:00, 35.93it/s]\n",
            "> Eval on experience 0 (Task 0) from test stream ended.\n",
            "\tLoss_Exp/eval_phase/test_stream/Task000/Exp000 = 0.6082\n",
            "\tTop1_Acc_Exp/eval_phase/test_stream/Task000/Exp000 = 0.9070\n",
            "-- Starting eval on experience 1 (Task 0) from test stream --\n",
            "100%|██████████| 16/16 [00:00<00:00, 32.64it/s]\n",
            "> Eval on experience 1 (Task 0) from test stream ended.\n",
            "\tLoss_Exp/eval_phase/test_stream/Task000/Exp001 = 3.5966\n",
            "\tTop1_Acc_Exp/eval_phase/test_stream/Task000/Exp001 = 0.0190\n",
            "-- Starting eval on experience 2 (Task 0) from test stream --\n",
            "100%|██████████| 16/16 [00:00<00:00, 31.28it/s]\n",
            "> Eval on experience 2 (Task 0) from test stream ended.\n",
            "\tLoss_Exp/eval_phase/test_stream/Task000/Exp002 = 2.9906\n",
            "\tTop1_Acc_Exp/eval_phase/test_stream/Task000/Exp002 = 0.0560\n",
            "-- >> End of eval phase << --\n",
            "\tLoss_Stream/eval_phase/test_stream/Task000 = 2.3985\n",
            "\tTop1_Acc_Stream/eval_phase/test_stream/Task000 = 0.3273\n",
            "Training on classes: [6, 7]\n",
            "Training on experience 3\n",
            "-- >> Start of training phase << --\n",
            "100%|██████████| 157/157 [00:04<00:00, 37.44it/s]\n",
            "Epoch 0 ended.\n",
            "\tLoss_Epoch/train_phase/train_stream/Task000 = 4.9187\n",
            "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.1513\n",
            "100%|██████████| 157/157 [00:04<00:00, 38.63it/s]\n",
            "Epoch 1 ended.\n",
            "\tLoss_Epoch/train_phase/train_stream/Task000 = 4.5814\n",
            "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.2243\n",
            "100%|██████████| 157/157 [00:04<00:00, 35.46it/s]\n",
            "Epoch 2 ended.\n",
            "\tLoss_Epoch/train_phase/train_stream/Task000 = 4.5073\n",
            "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.2399\n",
            "100%|██████████| 157/157 [00:03<00:00, 39.79it/s]\n",
            "Epoch 3 ended.\n",
            "\tLoss_Epoch/train_phase/train_stream/Task000 = 4.4930\n",
            "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.2489\n",
            "100%|██████████| 157/157 [00:03<00:00, 40.64it/s]\n",
            "Epoch 4 ended.\n",
            "\tLoss_Epoch/train_phase/train_stream/Task000 = 4.4701\n",
            "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.2594\n",
            "[Replay-Free CL] Saving centroids, variances, and freezing model.\n",
            "[Freeze] Model frozen at task 3\n",
            "-- >> End of training phase << --\n",
            "Evaluating on all seen tasks...\n",
            "-- >> Start of eval phase << --\n",
            "-- Starting eval on experience 0 (Task 0) from test stream --\n",
            "100%|██████████| 16/16 [00:00<00:00, 32.90it/s]\n",
            "> Eval on experience 0 (Task 0) from test stream ended.\n",
            "\tLoss_Exp/eval_phase/test_stream/Task000/Exp000 = 1.0536\n",
            "\tTop1_Acc_Exp/eval_phase/test_stream/Task000/Exp000 = 0.7690\n",
            "-- Starting eval on experience 1 (Task 0) from test stream --\n",
            "100%|██████████| 16/16 [00:00<00:00, 32.63it/s]\n",
            "> Eval on experience 1 (Task 0) from test stream ended.\n",
            "\tLoss_Exp/eval_phase/test_stream/Task000/Exp001 = 2.7364\n",
            "\tTop1_Acc_Exp/eval_phase/test_stream/Task000/Exp001 = 0.0640\n",
            "-- Starting eval on experience 2 (Task 0) from test stream --\n",
            "100%|██████████| 16/16 [00:00<00:00, 32.61it/s]\n",
            "> Eval on experience 2 (Task 0) from test stream ended.\n",
            "\tLoss_Exp/eval_phase/test_stream/Task000/Exp002 = 2.3776\n",
            "\tTop1_Acc_Exp/eval_phase/test_stream/Task000/Exp002 = 0.0990\n",
            "-- Starting eval on experience 3 (Task 0) from test stream --\n",
            "100%|██████████| 16/16 [00:00<00:00, 32.59it/s]\n",
            "> Eval on experience 3 (Task 0) from test stream ended.\n",
            "\tLoss_Exp/eval_phase/test_stream/Task000/Exp003 = 1.6101\n",
            "\tTop1_Acc_Exp/eval_phase/test_stream/Task000/Exp003 = 0.3805\n",
            "-- >> End of eval phase << --\n",
            "\tLoss_Stream/eval_phase/test_stream/Task000 = 1.9444\n",
            "\tTop1_Acc_Stream/eval_phase/test_stream/Task000 = 0.3281\n",
            "Training on classes: [8, 9]\n",
            "Training on experience 4\n",
            "-- >> Start of training phase << --\n",
            "100%|██████████| 157/157 [00:04<00:00, 37.85it/s]\n",
            "Epoch 0 ended.\n",
            "\tLoss_Epoch/train_phase/train_stream/Task000 = 3.8202\n",
            "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.4935\n",
            "100%|██████████| 157/157 [00:03<00:00, 39.89it/s]\n",
            "Epoch 1 ended.\n",
            "\tLoss_Epoch/train_phase/train_stream/Task000 = 3.5404\n",
            "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.6505\n",
            "100%|██████████| 157/157 [00:04<00:00, 38.75it/s]\n",
            "Epoch 2 ended.\n",
            "\tLoss_Epoch/train_phase/train_stream/Task000 = 3.5070\n",
            "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.6766\n",
            "100%|██████████| 157/157 [00:04<00:00, 39.23it/s]\n",
            "Epoch 3 ended.\n",
            "\tLoss_Epoch/train_phase/train_stream/Task000 = 3.4698\n",
            "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.6967\n",
            "100%|██████████| 157/157 [00:04<00:00, 35.15it/s]\n",
            "Epoch 4 ended.\n",
            "\tLoss_Epoch/train_phase/train_stream/Task000 = 3.4434\n",
            "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.7164\n",
            "[Replay-Free CL] Saving centroids, variances, and freezing model.\n",
            "[Freeze] Model frozen at task 4\n",
            "-- >> End of training phase << --\n",
            "Evaluating on all seen tasks...\n",
            "-- >> Start of eval phase << --\n",
            "-- Starting eval on experience 0 (Task 0) from test stream --\n",
            "100%|██████████| 16/16 [00:00<00:00, 31.46it/s]\n",
            "> Eval on experience 0 (Task 0) from test stream ended.\n",
            "\tLoss_Exp/eval_phase/test_stream/Task000/Exp000 = 1.6799\n",
            "\tTop1_Acc_Exp/eval_phase/test_stream/Task000/Exp000 = 0.2370\n",
            "-- Starting eval on experience 1 (Task 0) from test stream --\n",
            "100%|██████████| 16/16 [00:00<00:00, 31.23it/s]\n",
            "> Eval on experience 1 (Task 0) from test stream ended.\n",
            "\tLoss_Exp/eval_phase/test_stream/Task000/Exp001 = 2.6515\n",
            "\tTop1_Acc_Exp/eval_phase/test_stream/Task000/Exp001 = 0.0390\n",
            "-- Starting eval on experience 2 (Task 0) from test stream --\n",
            "100%|██████████| 16/16 [00:00<00:00, 32.09it/s]\n",
            "> Eval on experience 2 (Task 0) from test stream ended.\n",
            "\tLoss_Exp/eval_phase/test_stream/Task000/Exp002 = 2.4075\n",
            "\tTop1_Acc_Exp/eval_phase/test_stream/Task000/Exp002 = 0.0670\n",
            "-- Starting eval on experience 3 (Task 0) from test stream --\n",
            "100%|██████████| 16/16 [00:00<00:00, 31.71it/s]\n",
            "> Eval on experience 3 (Task 0) from test stream ended.\n",
            "\tLoss_Exp/eval_phase/test_stream/Task000/Exp003 = 1.9196\n",
            "\tTop1_Acc_Exp/eval_phase/test_stream/Task000/Exp003 = 0.1995\n",
            "-- Starting eval on experience 4 (Task 0) from test stream --\n",
            "100%|██████████| 16/16 [00:00<00:00, 31.92it/s]\n",
            "> Eval on experience 4 (Task 0) from test stream ended.\n",
            "\tLoss_Exp/eval_phase/test_stream/Task000/Exp004 = 1.2739\n",
            "\tTop1_Acc_Exp/eval_phase/test_stream/Task000/Exp004 = 0.8255\n",
            "-- >> End of eval phase << --\n",
            "\tLoss_Stream/eval_phase/test_stream/Task000 = 1.9865\n",
            "\tTop1_Acc_Stream/eval_phase/test_stream/Task000 = 0.2736\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from torchvision.models import resnet18\n",
        "\n",
        "model = resnet18(pretrained=False, num_classes=10)\n",
        "model.conv1 = torch.nn.Conv2d(3, 64, kernel_size=3, stride=1, padding=1, bias=False)\n",
        "model.maxpool = torch.nn.Identity()  # remove downsampling for CIFAR\n",
        "\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Vjn3AnBzWyJG",
        "outputId": "3fb86b1a-da3c-4507-ff52-79216c0f7cbb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=None`.\n",
            "  warnings.warn(msg)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# train & eval\n",
        "strategy = ClusterAwareReplayFreeCL(\n",
        "    model=model,\n",
        "    optimizer=optimizer,\n",
        "    train_mb_size=64,\n",
        "    train_epochs=5,\n",
        "    eval_mb_size=128,\n",
        "    device=device,\n",
        "    lambda_intra= 5,\n",
        "    lambda_logit= 0.5,\n",
        "    lambda_anchor = 0.5,\n",
        "    lambda_var = 0,\n",
        "    evaluator=eval_plugin\n",
        ")\n",
        "\n",
        "\n",
        "for experience in benchmark_class_il.train_stream:\n",
        "    current_classes = list(set(experience.dataset.targets))\n",
        "    print(f\"Training on classes: {current_classes}\")\n",
        "    print(\"Training on experience\", experience.current_experience)\n",
        "\n",
        "    strategy.train(experience)\n",
        "\n",
        "    print(\"Evaluating on all seen tasks...\")\n",
        "    strategy.eval(benchmark_class_il.test_stream[: experience.current_experience + 1])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 418
        },
        "outputId": "f3b6258c-e677-4797-8fce-0df8799a79bb",
        "id": "SHLhHuHcWy04"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training on classes: [0, 1]\n",
            "Training on experience 0\n",
            "-- >> Start of training phase << --\n",
            "0it [00:00, ?it/s]"
          ]
        },
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ResNet.forward() got an unexpected keyword argument 'return_feats'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-65-554785999.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     20\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Training on experience\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexperience\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcurrent_experience\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m     \u001b[0mstrategy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexperience\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Evaluating on all seen tasks...\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/avalanche/training/templates/base_sgd.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, experiences, eval_streams, **kwargs)\u001b[0m\n\u001b[1;32m    211\u001b[0m         \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    212\u001b[0m     ):\n\u001b[0;32m--> 213\u001b[0;31m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexperiences\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0meval_streams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    214\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_last_metrics\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    215\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/avalanche/training/templates/base.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, experiences, eval_streams, **kwargs)\u001b[0m\n\u001b[1;32m    161\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperience\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mexperiences_list\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    162\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_before_training_exp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 163\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_train_exp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperience\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0meval_streams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    164\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_after_training_exp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    165\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_after_training\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/avalanche/training/templates/base_sgd.py\u001b[0m in \u001b[0;36m_train_exp\u001b[0;34m(self, experience, eval_streams, **kwargs)\u001b[0m\n\u001b[1;32m    337\u001b[0m                 \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    338\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 339\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtraining_epoch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    340\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_after_training_epoch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    341\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/avalanche/training/templates/update_type/sgd_update.py\u001b[0m in \u001b[0;36mtraining_epoch\u001b[0;34m(self, **kwargs)\u001b[0m\n\u001b[1;32m     29\u001b[0m             \u001b[0;31m# Forward\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_before_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 31\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmb_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     32\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_after_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tmp/ipython-input-9-4103355198.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcurrent_feats\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlogits\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmb_x\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_feats\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlogits\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1737\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1738\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1739\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1740\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1741\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1748\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1749\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1750\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1751\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1752\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: ResNet.forward() got an unexpected keyword argument 'return_feats'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "strategy.train(benchmark_class_il.train_stream)\n",
        "strategy.eval(benchmark_class_il.test_stream)\n"
      ],
      "metadata": {
        "id": "u-kUpYGJa6sZ",
        "outputId": "5d71b1d5-a9c1-4c37-b444-b59a70288ef2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 775
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-- >> Start of training phase << --\n",
            "100%|██████████| 157/157 [05:32<00:00,  2.12s/it]\n",
            "Epoch 0 ended.\n",
            "\tLoss_Epoch/train_phase/train_stream/Task000 = 0.4369\n",
            "\tTime_Epoch/train_phase/train_stream/Task000 = 3.1700\n",
            "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.7977\n",
            "100%|██████████| 157/157 [00:03<00:00, 52.16it/s]\n",
            "Epoch 1 ended.\n",
            "\tLoss_Epoch/train_phase/train_stream/Task000 = 0.2780\n",
            "\tTime_Epoch/train_phase/train_stream/Task000 = 3.0102\n",
            "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.8842\n",
            "100%|██████████| 157/157 [00:03<00:00, 51.48it/s]\n",
            "Epoch 2 ended.\n",
            "\tLoss_Epoch/train_phase/train_stream/Task000 = 0.2310\n",
            "\tTime_Epoch/train_phase/train_stream/Task000 = 3.0501\n",
            "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.9058\n",
            "100%|██████████| 157/157 [00:03<00:00, 48.07it/s]\n",
            "Epoch 3 ended.\n",
            "\tLoss_Epoch/train_phase/train_stream/Task000 = 0.1956\n",
            "\tTime_Epoch/train_phase/train_stream/Task000 = 3.2657\n",
            "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.9216\n",
            "100%|██████████| 157/157 [00:02<00:00, 52.81it/s]\n",
            "Epoch 4 ended.\n",
            "\tLoss_Epoch/train_phase/train_stream/Task000 = 0.1823\n",
            "\tTime_Epoch/train_phase/train_stream/Task000 = 2.9732\n",
            "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.9260\n",
            "[SyntheticReplayCL] Saving centroids + generating synthetic memory...\n",
            "0it [00:00, ?it/s]"
          ]
        },
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "Tensors must have same number of dimensions: got 4 and 2",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-133-2379074400.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mstrategy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbenchmark_class_il\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_stream\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mstrategy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbenchmark_class_il\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtest_stream\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/avalanche/training/templates/base_sgd.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, experiences, eval_streams, **kwargs)\u001b[0m\n\u001b[1;32m    211\u001b[0m         \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    212\u001b[0m     ):\n\u001b[0;32m--> 213\u001b[0;31m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexperiences\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0meval_streams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    214\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_last_metrics\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    215\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/avalanche/training/templates/base.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, experiences, eval_streams, **kwargs)\u001b[0m\n\u001b[1;32m    161\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperience\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mexperiences_list\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    162\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_before_training_exp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 163\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_train_exp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperience\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0meval_streams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    164\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_after_training_exp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    165\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_after_training\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/avalanche/training/templates/base_sgd.py\u001b[0m in \u001b[0;36m_train_exp\u001b[0;34m(self, experience, eval_streams, **kwargs)\u001b[0m\n\u001b[1;32m    337\u001b[0m                 \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    338\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 339\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtraining_epoch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    340\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_after_training_epoch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    341\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/avalanche/training/templates/update_type/sgd_update.py\u001b[0m in \u001b[0;36mtraining_epoch\u001b[0;34m(self, **kwargs)\u001b[0m\n\u001b[1;32m     29\u001b[0m             \u001b[0;31m# Forward\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_before_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 31\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmb_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     32\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_after_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tmp/ipython-input-130-341753708.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     57\u001b[0m             \u001b[0msyn_y\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msyn_y\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 59\u001b[0;31m             \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msyn_x\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     60\u001b[0m             \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msyn_y\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# this is now a local combined label tensor\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     61\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: Tensors must have same number of dimensions: got 4 and 2"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from collections import defaultdict\n",
        "import random\n"
      ],
      "metadata": {
        "id": "0WMYaViKffwQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class EpisodicMemoryBuffer:\n",
        "    def __init__(self, device, max_exemplars_per_class):\n",
        "        self.device = device\n",
        "        self.max_exemplars_per_class = max_exemplars_per_class\n",
        "        self.memory = defaultdict(list)\n",
        "\n",
        "    def add_samples(self, x, y):\n",
        "        for xi, yi in zip(x, y):\n",
        "            cls = yi.item()\n",
        "            if len(self.memory[cls]) < self.max_exemplars_per_class:\n",
        "                self.memory[cls].append((xi.detach().cpu(), yi.detach().cpu()))\n",
        "            else:\n",
        "                idx = torch.randint(0, self.max_exemplars_per_class, (1,)).item()\n",
        "                self.memory[cls][idx] = (xi.detach().cpu(), yi.detach().cpu())\n",
        "\n",
        "    def sample_batch(self, batch_size=32):\n",
        "        if len(self.memory) == 0:\n",
        "            return None, None\n",
        "\n",
        "        class_samples = []\n",
        "        num_classes = len(self.memory)\n",
        "        if num_classes == 0:\n",
        "            return None, None\n",
        "\n",
        "        samples_per_class = max(1, batch_size // num_classes)\n",
        "\n",
        "        for cls, items in self.memory.items():\n",
        "            if len(items) == 0:\n",
        "                continue\n",
        "            n = min(samples_per_class, len(items))\n",
        "            class_samples.extend(random.sample(items, n))\n",
        "\n",
        "        if not class_samples:\n",
        "            return None, None\n",
        "\n",
        "        samples = random.sample(class_samples, min(batch_size, len(class_samples)))\n",
        "        xs, ys = zip(*samples)\n",
        "        return torch.stack(xs).to(self.device), torch.stack(ys).to(self.device)\n"
      ],
      "metadata": {
        "id": "Y_TC8L3v5Rc1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class ClusterAwareMinimalReplayCL(SupervisedTemplate):\n",
        "    def __init__(self, *, model, optimizer, device, lambda_intra, lambda_anchor,\n",
        "                 lambda_logit, lambda_var, criterion=torch.nn.CrossEntropyLoss(),\n",
        "                 max_exemplars_per_class=30, use_replay=True, **kwargs):\n",
        "        super().__init__(model=model, optimizer=optimizer, criterion=criterion, device=device, **kwargs)\n",
        "\n",
        "        self.lambda_intra = lambda_intra\n",
        "        self.lambda_anchor = lambda_anchor\n",
        "        self.lambda_logit = lambda_logit\n",
        "        self.lambda_var = lambda_var\n",
        "        self.device = device\n",
        "\n",
        "        self.prev_centroids = {}\n",
        "        self.prev_variances = {}\n",
        "        self.model_old = None\n",
        "\n",
        "        self.replay_buffer = EpisodicMemoryBuffer(device, max_exemplars_per_class)\n",
        "        self.use_replay = use_replay\n",
        "\n",
        "    def forward(self):\n",
        "        x = self.mb_x\n",
        "        y = self.mb_y\n",
        "\n",
        "        self.clean_x = x\n",
        "        self.clean_y = y\n",
        "        replay_mask = torch.zeros_like(y, dtype=torch.bool)\n",
        "\n",
        "        if self.model.training and self.use_replay:\n",
        "            rx, ry = self.replay_buffer.sample_batch(batch_size=x.size(0))\n",
        "            if rx is not None:\n",
        "                x = torch.cat([x, rx], dim=0)\n",
        "                y = torch.cat([y, ry], dim=0)\n",
        "                replay_mask = torch.cat([torch.zeros_like(self.mb_y, dtype=torch.bool), torch.ones_like(ry, dtype=torch.bool)], dim=0)\n",
        "\n",
        "        self.replay_mask = replay_mask\n",
        "        self.current_x = x\n",
        "        self.current_y = y\n",
        "        self.current_feats, self.logits = self.model(x, return_feats=True)\n",
        "        return self.logits\n",
        "\n",
        "    def criterion(self):\n",
        "        feats = F.normalize(self.current_feats, p=2, dim=1)\n",
        "        targets = self.current_y\n",
        "\n",
        "        current_logits = self.logits[~self.replay_mask]\n",
        "        current_targets = targets[~self.replay_mask]\n",
        "        replay_logits = self.logits[self.replay_mask]\n",
        "        replay_targets = targets[self.replay_mask]\n",
        "\n",
        "        ce_current = self._criterion(current_logits, current_targets)\n",
        "        ce_replay = self._criterion(replay_logits, replay_targets) if len(replay_targets) > 0 else 0.0\n",
        "        ce_loss = ce_current + 0.5 * ce_replay\n",
        "\n",
        "         # Feature regularization (L2 distance between feats and detached copy)\n",
        "        feat_reg = 0.0\n",
        "        if hasattr(self, 'prev_feats') and self.prev_feats is not None:\n",
        "            feat_reg = F.mse_loss(self.current_feats, self.prev_feats)\n",
        "\n",
        "\n",
        "        curr_centroids, curr_variances = {}, {}\n",
        "        for cls in torch.unique(targets):\n",
        "            mask = targets == cls\n",
        "            feats_cls = feats[mask]\n",
        "            curr_centroids[cls.item()] = feats_cls.mean(0)\n",
        "            curr_variances[cls.item()] = feats_cls.var(0, unbiased=False)\n",
        "\n",
        "        inter_cluster_loss = 0.0\n",
        "        cls_list = list(curr_centroids.keys())\n",
        "        for i in range(len(cls_list)):\n",
        "            for j in range(i + 1, len(cls_list)):\n",
        "                inter_cluster_loss += F.mse_loss(curr_centroids[cls_list[i]], curr_centroids[cls_list[j]])\n",
        "        if len(cls_list) > 1:\n",
        "            inter_cluster_loss /= len(cls_list) * (len(cls_list) - 1) / 2\n",
        "\n",
        "        anchor_loss = 0.0\n",
        "        for cls, prev_mu in self.prev_centroids.items():\n",
        "            if cls in curr_centroids:\n",
        "                anchor_loss += F.mse_loss(curr_centroids[cls], prev_mu.to(feats.device))\n",
        "        if self.prev_centroids:\n",
        "            anchor_loss /= len(self.prev_centroids)\n",
        "\n",
        "        var_loss = 0.0\n",
        "        for cls, prev_var in self.prev_variances.items():\n",
        "            if cls in curr_variances:\n",
        "                var_loss += F.mse_loss(curr_variances[cls], prev_var.to(feats.device))\n",
        "        if self.prev_variances:\n",
        "            var_loss /= len(self.prev_variances)\n",
        "\n",
        "        logit_loss = 0.0\n",
        "        if self.model_old is not None and self.replay_mask.any():\n",
        "          with torch.no_grad():\n",
        "              old_replay_logits = self.model_old(self.current_x[self.replay_mask])\n",
        "          logit_loss = F.mse_loss(self.logits[self.replay_mask], old_replay_logits)\n",
        "\n",
        "        softmax = F.softmax(self.logits[~self.replay_mask], dim=1)\n",
        "        entropy = -torch.sum(softmax * torch.log(softmax + 1e-7), dim=1).mean()\n",
        "\n",
        "        return (  ce_loss + 0.1 * feat_reg  + 0.2* entropy\n",
        "                  + self.lambda_intra * inter_cluster_loss\n",
        "                  + self.lambda_anchor * anchor_loss\n",
        "                  + self.lambda_logit * logit_loss\n",
        "                  + self.lambda_var * var_loss )\n",
        "\n",
        "\n",
        "\n",
        "    def _after_training_exp(self, **kwargs):\n",
        "        self.model.eval()\n",
        "        dl = DataLoader(self.adapted_dataset, batch_size=128, shuffle=True)\n",
        "        centroids, variances = defaultdict(list), defaultdict(list)\n",
        "        with torch.no_grad():\n",
        "            for x, y, *_ in dl:\n",
        "                x, y = x.to(self.device), y.to(self.device)\n",
        "                feats, _ = self.model(x, return_feats=True)\n",
        "                feats = F.normalize(feats, p=2, dim=1)\n",
        "                for cls in torch.unique(y):\n",
        "                    mask = y == cls\n",
        "                    if mask.any():\n",
        "                        feats_cls = feats[mask]\n",
        "                        centroids[cls.item()].append(feats_cls.mean(0))\n",
        "                        variances[cls.item()].append(feats_cls.var(0, unbiased=False))\n",
        "                self.replay_buffer.add_samples(x, y)\n",
        "\n",
        "        for cls in centroids:\n",
        "            self.prev_centroids[cls] = torch.stack(centroids[cls]).mean(0).detach().cpu()\n",
        "            self.prev_variances[cls] = torch.stack(variances[cls]).mean(0).detach().cpu()\n",
        "\n",
        "        self.model_old = self.model.__class__()\n",
        "        self.model_old.load_state_dict(self.model.state_dict())\n",
        "        self.model_old.to(self.device)\n",
        "        self.model_old.eval()\n",
        "        for p in self.model_old.parameters():\n",
        "            p.requires_grad = False\n",
        "\n",
        "        self.model.train()\n",
        "        super()._after_training_exp(**kwargs)\n"
      ],
      "metadata": {
        "id": "CF64fR54fpyE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = SimpleCNN()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n"
      ],
      "metadata": {
        "id": "Qy1LrmfBvVgH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "eval_plugin = EvaluationPlugin(\n",
        "    accuracy_metrics(minibatch=False, epoch=False, experience=True, stream=True),\n",
        "    loggers=[InteractiveLogger()]\n",
        ")\n"
      ],
      "metadata": {
        "id": "NoDeBzjHqJMG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")  # ✅ correct\n"
      ],
      "metadata": {
        "id": "SEnZ6Ly6ioJR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# train & eval\n",
        "strategy = ClusterAwareMinimalReplayCL(\n",
        "    model=model,\n",
        "    optimizer=optimizer,\n",
        "    criterion=torch.nn.CrossEntropyLoss(),\n",
        "    train_mb_size=64,\n",
        "    train_epochs=5,\n",
        "    eval_mb_size=128,\n",
        "    device=device,\n",
        "    evaluator=eval_plugin,\n",
        "    lambda_intra= 0.05,\n",
        "    max_exemplars_per_class= 100,\n",
        "    lambda_logit= 0.2,\n",
        "    lambda_anchor = 0.1,\n",
        "    lambda_var = 0\n",
        "\n",
        ")\n",
        "\n",
        "\n",
        "for experience in benchmark_class_il.train_stream:\n",
        "    current_classes = list(set(experience.dataset.targets))\n",
        "    print(f\"Training on classes: {current_classes}\")\n",
        "    print(\"Training on experience\", experience.current_experience)\n",
        "#//strategy.use_replay = True\n",
        "    print(\"Replay active:\", strategy.use_replay)\n",
        "\n",
        "    strategy.train(experience)\n",
        "\n",
        "    print(\"Evaluating on all seen tasks...\")\n",
        "    print(\"Evaluating... Replay should be OFF\")\n",
        "    print(\"Replay active:\", strategy.use_replay)\n",
        "    #strategy.use_replay = False\n",
        "\n",
        "    strategy.eval(benchmark_class_il.test_stream[: experience.current_experience + 1])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "di-SqwETgKce",
        "outputId": "cc3c2243-106a-4878-c83e-7b3807d9dc91"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training on classes: [0, 1]\n",
            "Training on experience 0\n",
            "Replay active: True\n",
            "-- >> Start of training phase << --\n",
            "100%|██████████| 157/157 [00:03<00:00, 48.07it/s]\n",
            "Epoch 0 ended.\n",
            "100%|██████████| 157/157 [00:03<00:00, 48.51it/s]\n",
            "Epoch 1 ended.\n",
            "100%|██████████| 157/157 [00:03<00:00, 47.22it/s]\n",
            "Epoch 2 ended.\n",
            "100%|██████████| 157/157 [00:03<00:00, 49.74it/s]\n",
            "Epoch 3 ended.\n",
            "100%|██████████| 157/157 [00:03<00:00, 43.28it/s]\n",
            "Epoch 4 ended.\n",
            "-- >> End of training phase << --\n",
            "Evaluating on all seen tasks...\n",
            "Evaluating... Replay should be OFF\n",
            "Replay active: True\n",
            "-- >> Start of eval phase << --\n",
            "-- Starting eval on experience 0 (Task 0) from test stream --\n",
            "100%|██████████| 16/16 [00:00<00:00, 46.96it/s]\n",
            "> Eval on experience 0 (Task 0) from test stream ended.\n",
            "\tTop1_Acc_Exp/eval_phase/test_stream/Task000/Exp000 = 0.9485\n",
            "-- >> End of eval phase << --\n",
            "\tTop1_Acc_Stream/eval_phase/test_stream/Task000 = 0.9485\n",
            "Training on classes: [2, 3]\n",
            "Training on experience 1\n",
            "Replay active: True\n",
            "-- >> Start of training phase << --\n",
            "100%|██████████| 157/157 [00:04<00:00, 34.46it/s]\n",
            "Epoch 0 ended.\n",
            "100%|██████████| 157/157 [00:04<00:00, 35.29it/s]\n",
            "Epoch 1 ended.\n",
            "100%|██████████| 157/157 [00:04<00:00, 35.46it/s]\n",
            "Epoch 2 ended.\n",
            "100%|██████████| 157/157 [00:04<00:00, 35.06it/s]\n",
            "Epoch 3 ended.\n",
            "100%|██████████| 157/157 [00:04<00:00, 36.22it/s]\n",
            "Epoch 4 ended.\n",
            "-- >> End of training phase << --\n",
            "Evaluating on all seen tasks...\n",
            "Evaluating... Replay should be OFF\n",
            "Replay active: True\n",
            "-- >> Start of eval phase << --\n",
            "-- Starting eval on experience 0 (Task 0) from test stream --\n",
            "100%|██████████| 16/16 [00:00<00:00, 48.08it/s]\n",
            "> Eval on experience 0 (Task 0) from test stream ended.\n",
            "\tTop1_Acc_Exp/eval_phase/test_stream/Task000/Exp000 = 0.4750\n",
            "-- Starting eval on experience 1 (Task 0) from test stream --\n",
            "100%|██████████| 16/16 [00:00<00:00, 47.27it/s]\n",
            "> Eval on experience 1 (Task 0) from test stream ended.\n",
            "\tTop1_Acc_Exp/eval_phase/test_stream/Task000/Exp001 = 0.8295\n",
            "-- >> End of eval phase << --\n",
            "\tTop1_Acc_Stream/eval_phase/test_stream/Task000 = 0.6522\n",
            "Training on classes: [4, 5]\n",
            "Training on experience 2\n",
            "Replay active: True\n",
            "-- >> Start of training phase << --\n",
            "100%|██████████| 157/157 [00:04<00:00, 33.43it/s]\n",
            "Epoch 0 ended.\n",
            "100%|██████████| 157/157 [00:04<00:00, 33.21it/s]\n",
            "Epoch 1 ended.\n",
            "100%|██████████| 157/157 [00:04<00:00, 31.74it/s]\n",
            "Epoch 2 ended.\n",
            "100%|██████████| 157/157 [00:04<00:00, 33.25it/s]\n",
            "Epoch 3 ended.\n",
            "100%|██████████| 157/157 [00:04<00:00, 33.72it/s]\n",
            "Epoch 4 ended.\n",
            "-- >> End of training phase << --\n",
            "Evaluating on all seen tasks...\n",
            "Evaluating... Replay should be OFF\n",
            "Replay active: True\n",
            "-- >> Start of eval phase << --\n",
            "-- Starting eval on experience 0 (Task 0) from test stream --\n",
            "100%|██████████| 16/16 [00:00<00:00, 48.40it/s]\n",
            "> Eval on experience 0 (Task 0) from test stream ended.\n",
            "\tTop1_Acc_Exp/eval_phase/test_stream/Task000/Exp000 = 0.4570\n",
            "-- Starting eval on experience 1 (Task 0) from test stream --\n",
            "100%|██████████| 16/16 [00:00<00:00, 46.29it/s]\n",
            "> Eval on experience 1 (Task 0) from test stream ended.\n",
            "\tTop1_Acc_Exp/eval_phase/test_stream/Task000/Exp001 = 0.0460\n",
            "-- Starting eval on experience 2 (Task 0) from test stream --\n",
            "100%|██████████| 16/16 [00:00<00:00, 45.05it/s]\n",
            "> Eval on experience 2 (Task 0) from test stream ended.\n",
            "\tTop1_Acc_Exp/eval_phase/test_stream/Task000/Exp002 = 0.8820\n",
            "-- >> End of eval phase << --\n",
            "\tTop1_Acc_Stream/eval_phase/test_stream/Task000 = 0.4617\n",
            "Training on classes: [6, 7]\n",
            "Training on experience 3\n",
            "Replay active: True\n",
            "-- >> Start of training phase << --\n",
            "100%|██████████| 157/157 [00:04<00:00, 35.24it/s]\n",
            "Epoch 0 ended.\n",
            "100%|██████████| 157/157 [00:04<00:00, 32.62it/s]\n",
            "Epoch 1 ended.\n",
            "100%|██████████| 157/157 [00:04<00:00, 33.75it/s]\n",
            "Epoch 2 ended.\n",
            "100%|██████████| 157/157 [00:04<00:00, 35.19it/s]\n",
            "Epoch 3 ended.\n",
            "100%|██████████| 157/157 [00:04<00:00, 34.65it/s]\n",
            "Epoch 4 ended.\n",
            "-- >> End of training phase << --\n",
            "Evaluating on all seen tasks...\n",
            "Evaluating... Replay should be OFF\n",
            "Replay active: True\n",
            "-- >> Start of eval phase << --\n",
            "-- Starting eval on experience 0 (Task 0) from test stream --\n",
            "100%|██████████| 16/16 [00:00<00:00, 46.98it/s]\n",
            "> Eval on experience 0 (Task 0) from test stream ended.\n",
            "\tTop1_Acc_Exp/eval_phase/test_stream/Task000/Exp000 = 0.4300\n",
            "-- Starting eval on experience 1 (Task 0) from test stream --\n",
            "100%|██████████| 16/16 [00:00<00:00, 46.98it/s]\n",
            "> Eval on experience 1 (Task 0) from test stream ended.\n",
            "\tTop1_Acc_Exp/eval_phase/test_stream/Task000/Exp001 = 0.0520\n",
            "-- Starting eval on experience 2 (Task 0) from test stream --\n",
            "100%|██████████| 16/16 [00:00<00:00, 46.75it/s]\n",
            "> Eval on experience 2 (Task 0) from test stream ended.\n",
            "\tTop1_Acc_Exp/eval_phase/test_stream/Task000/Exp002 = 0.0555\n",
            "-- Starting eval on experience 3 (Task 0) from test stream --\n",
            "100%|██████████| 16/16 [00:00<00:00, 45.94it/s]\n",
            "> Eval on experience 3 (Task 0) from test stream ended.\n",
            "\tTop1_Acc_Exp/eval_phase/test_stream/Task000/Exp003 = 0.9500\n",
            "-- >> End of eval phase << --\n",
            "\tTop1_Acc_Stream/eval_phase/test_stream/Task000 = 0.3719\n",
            "Training on classes: [8, 9]\n",
            "Training on experience 4\n",
            "Replay active: True\n",
            "-- >> Start of training phase << --\n",
            "100%|██████████| 157/157 [00:05<00:00, 29.87it/s]\n",
            "Epoch 0 ended.\n",
            "100%|██████████| 157/157 [00:05<00:00, 30.83it/s]\n",
            "Epoch 1 ended.\n",
            "100%|██████████| 157/157 [00:05<00:00, 31.20it/s]\n",
            "Epoch 2 ended.\n",
            "100%|██████████| 157/157 [00:05<00:00, 31.02it/s]\n",
            "Epoch 3 ended.\n",
            "100%|██████████| 157/157 [00:04<00:00, 31.59it/s]\n",
            "Epoch 4 ended.\n",
            "-- >> End of training phase << --\n",
            "Evaluating on all seen tasks...\n",
            "Evaluating... Replay should be OFF\n",
            "Replay active: True\n",
            "-- >> Start of eval phase << --\n",
            "-- Starting eval on experience 0 (Task 0) from test stream --\n",
            "100%|██████████| 16/16 [00:00<00:00, 44.15it/s]\n",
            "> Eval on experience 0 (Task 0) from test stream ended.\n",
            "\tTop1_Acc_Exp/eval_phase/test_stream/Task000/Exp000 = 0.0350\n",
            "-- Starting eval on experience 1 (Task 0) from test stream --\n",
            "100%|██████████| 16/16 [00:00<00:00, 44.43it/s]\n",
            "> Eval on experience 1 (Task 0) from test stream ended.\n",
            "\tTop1_Acc_Exp/eval_phase/test_stream/Task000/Exp001 = 0.0750\n",
            "-- Starting eval on experience 2 (Task 0) from test stream --\n",
            "100%|██████████| 16/16 [00:00<00:00, 44.69it/s]\n",
            "> Eval on experience 2 (Task 0) from test stream ended.\n",
            "\tTop1_Acc_Exp/eval_phase/test_stream/Task000/Exp002 = 0.1615\n",
            "-- Starting eval on experience 3 (Task 0) from test stream --\n",
            "100%|██████████| 16/16 [00:00<00:00, 44.88it/s]\n",
            "> Eval on experience 3 (Task 0) from test stream ended.\n",
            "\tTop1_Acc_Exp/eval_phase/test_stream/Task000/Exp003 = 0.6255\n",
            "-- Starting eval on experience 4 (Task 0) from test stream --\n",
            "100%|██████████| 16/16 [00:00<00:00, 45.49it/s]\n",
            "> Eval on experience 4 (Task 0) from test stream ended.\n",
            "\tTop1_Acc_Exp/eval_phase/test_stream/Task000/Exp004 = 0.9240\n",
            "-- >> End of eval phase << --\n",
            "\tTop1_Acc_Stream/eval_phase/test_stream/Task000 = 0.3642\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Using resnet18"
      ],
      "metadata": {
        "id": "ivFkRJIZFiJ3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "class EpisodicMemoryBuffer:\n",
        "    def __init__(self,device, max_exemplars_per_class=30):\n",
        "        self.device = device\n",
        "        self.max_exemplars_per_class = max_exemplars_per_class\n",
        "        self.memory = defaultdict(list)\n",
        "\n",
        "    def add_samples(self, x, y):\n",
        "        for xi, yi in zip(x, y):\n",
        "            cls = yi.item()\n",
        "            if len(self.memory[cls]) < self.max_exemplars_per_class:\n",
        "                self.memory[cls].append((xi.detach().cpu(), yi.detach().cpu()))\n",
        "            else:\n",
        "                idx = torch.randint(0, self.max_exemplars_per_class, (1,)).item()\n",
        "                self.memory[cls][idx] = (xi.detach().cpu(), yi.detach().cpu())\n",
        "\n",
        "    def sample_batch(self, batch_size=32):\n",
        "        if len(self.memory) == 0:\n",
        "            return None, None\n",
        "\n",
        "        class_samples = []\n",
        "        num_classes = len(self.memory)\n",
        "        if num_classes == 0:\n",
        "            return None, None\n",
        "\n",
        "        samples_per_class = max(1, batch_size // num_classes)\n",
        "\n",
        "        for cls, items in self.memory.items():\n",
        "            if len(items) == 0:\n",
        "                continue\n",
        "            n = min(samples_per_class, len(items))\n",
        "            class_samples.extend(random.sample(items, n))\n",
        "\n",
        "        if not class_samples:\n",
        "            return None, None\n",
        "\n",
        "        samples = random.sample(class_samples, min(batch_size, len(class_samples)))\n",
        "        xs, ys = zip(*samples)\n",
        "        return torch.stack(xs).to(self.device), torch.stack(ys).to(self.device)\n",
        "\n",
        "from copy import deepcopy\n",
        "\n",
        "class ClusterAwareMinimalReplayCL(SupervisedTemplate):\n",
        "    def __init__(self, *, model, optimizer, device, lambda_intra=1.0, lambda_anchor=0.1,\n",
        "                 lambda_logit=0.05, lambda_var=0.0, criterion=torch.nn.CrossEntropyLoss(),\n",
        "                 max_exemplars_per_class=30, use_replay=True, **kwargs):\n",
        "        super().__init__(model=model, optimizer=optimizer, criterion=criterion, device=device, **kwargs)\n",
        "\n",
        "        self.lambda_intra = lambda_intra\n",
        "        self.lambda_anchor = lambda_anchor\n",
        "        self.lambda_logit = lambda_logit\n",
        "        self.lambda_var = lambda_var\n",
        "        self.device = device\n",
        "\n",
        "        self.prev_centroids = {}\n",
        "        self.prev_variances = {}\n",
        "        self.model_old = None\n",
        "        self.old_centroids = {}  # task_id → centroid map\n",
        "        self.task_accuracies = defaultdict(list)\n",
        "        self.max_accuracies = defaultdict(float)\n",
        "\n",
        "        self.replay_buffer = EpisodicMemoryBuffer(device, max_exemplars_per_class)\n",
        "        self.use_replay = use_replay\n",
        "\n",
        "        self.experience = None\n",
        "\n",
        "    def criterion(self):\n",
        "        feats = F.normalize(self.prev_feats, p=2, dim=1)\n",
        "        targets = self.current_y\n",
        "\n",
        "        current_logits = self.logits[~self.replay_mask]\n",
        "        current_targets = targets[~self.replay_mask]\n",
        "        replay_logits = self.logits[self.replay_mask]\n",
        "        replay_targets = targets[self.replay_mask]\n",
        "\n",
        "        ce_current = self._criterion(current_logits, current_targets)\n",
        "        if len(replay_targets) > 0:\n",
        "            # Dynamic weighting: prioritize forgotten or older task classes\n",
        "            weights = torch.ones_like(replay_targets, dtype=torch.float)\n",
        "            for i, y in enumerate(replay_targets):\n",
        "                task_id = y.item() // 2  # assuming class group size 2 (SplitCIFAR10)\n",
        "                if self.task_accuracies[task_id]:\n",
        "                    recent_acc = self.task_accuracies[task_id][-1]\n",
        "                    weights[i] = 1.5 if recent_acc < 0.5 else 1.0\n",
        "            ce_replay = F.cross_entropy(replay_logits, replay_targets, reduction='none')\n",
        "            ce_replay = (ce_replay * weights.to(replay_logits.device)).mean()\n",
        "        else:\n",
        "            ce_replay = 0.0\n",
        "        ce_loss = ce_current + 0.5 * ce_replay\n",
        "\n",
        "        # Feature regularization (L2 distance between feats and detached copy)\n",
        "        feat_reg = 0.0\n",
        "        if hasattr(self, 'prev_feats') and self.prev_feats is not None:\n",
        "            feat_reg = F.mse_loss(self.prev_feats, self.prev_feats.detach())\n",
        "\n",
        "        # Centroids and variance terms\n",
        "        curr_centroids, curr_variances = {}, {}\n",
        "        for cls in torch.unique(targets):\n",
        "            mask = targets == cls\n",
        "            feats_cls = feats[mask]\n",
        "            curr_centroids[cls.item()] = feats_cls.mean(0)\n",
        "            curr_variances[cls.item()] = feats_cls.var(0, unbiased=False)\n",
        "\n",
        "        inter_cluster_loss = 0.0\n",
        "        cls_list = list(curr_centroids.keys())\n",
        "        for i in range(len(cls_list)):\n",
        "            for j in range(i + 1, len(cls_list)):\n",
        "                inter_cluster_loss += F.mse_loss(curr_centroids[cls_list[i]], curr_centroids[cls_list[j]])\n",
        "        if len(cls_list) > 1:\n",
        "            inter_cluster_loss /= len(cls_list) * (len(cls_list) - 1) / 2\n",
        "\n",
        "        anchor_loss = 0.0\n",
        "        for cls, prev_mu in self.prev_centroids.items():\n",
        "            if cls in curr_centroids:\n",
        "                anchor_loss += F.mse_loss(curr_centroids[cls], prev_mu.to(feats.device))\n",
        "        if self.prev_centroids:\n",
        "            anchor_loss /= len(self.prev_centroids)\n",
        "\n",
        "        var_loss = 0.0\n",
        "        for cls, prev_var in self.prev_variances.items():\n",
        "            if cls in curr_variances:\n",
        "                var_loss += F.mse_loss(curr_variances[cls], prev_var.to(feats.device))\n",
        "        if self.prev_variances:\n",
        "            var_loss /= len(self.prev_variances)\n",
        "\n",
        "        logit_loss = 0.0\n",
        "        if self.model_old is not None and self.replay_mask.any():\n",
        "            with torch.no_grad():\n",
        "                old_logits = self.model_old(self.current_x[self.replay_mask])\n",
        "            logit_loss = F.mse_loss(self.logits[self.replay_mask], old_logits)\n",
        "\n",
        "        return ce_loss + self.lambda_intra * inter_cluster_loss + \\\n",
        "               self.lambda_anchor * anchor_loss + \\\n",
        "               self.lambda_logit * logit_loss + \\\n",
        "               self.lambda_var * var_loss + 0.1 * feat_reg\n",
        "\n",
        "    def forward(self):\n",
        "        x = self.mb_x\n",
        "        y = self.mb_y\n",
        "\n",
        "        self.clean_x = x\n",
        "        self.clean_y = y\n",
        "        replay_mask = torch.zeros_like(y, dtype=torch.bool)\n",
        "\n",
        "        if self.model.training and self.use_replay:\n",
        "            rx, ry = self.replay_buffer.sample_batch(batch_size=x.size(0))\n",
        "            if rx is not None:\n",
        "                x = torch.cat([x, rx], dim=0)\n",
        "                y = torch.cat([y, ry], dim=0)\n",
        "                replay_mask = torch.cat([\n",
        "                    torch.zeros_like(self.mb_y, dtype=torch.bool),\n",
        "                    torch.ones_like(ry, dtype=torch.bool)\n",
        "                ], dim=0)\n",
        "\n",
        "        self.replay_mask = replay_mask\n",
        "        self.current_x = x\n",
        "        self.current_y = y\n",
        "        if hasattr(self.model, 'forward_features'):\n",
        "            feats = self.model.forward_features(x)\n",
        "        else:\n",
        "            feats = self.model.avgpool(\n",
        "                self.model.layer4(\n",
        "                    self.model.layer3(\n",
        "                        self.model.layer2(\n",
        "                            self.model.layer1(\n",
        "                                self.model.relu(self.model.bn1(self.model.conv1(x)))\n",
        "                            )\n",
        "                        )\n",
        "                    )\n",
        "                )\n",
        "            )\n",
        "            feats = torch.flatten(feats, 1)\n",
        "        self.prev_feats = feats\n",
        "        self.logits = self.model.fc(feats)\n",
        "        return self.logits\n",
        "\n",
        "    def _after_training_exp(self, **kwargs):\n",
        "        self.model.eval()\n",
        "        dl = DataLoader(self.adapted_dataset, batch_size=128, shuffle=True)\n",
        "        centroids, variances = defaultdict(list), defaultdict(list)\n",
        "        with torch.no_grad():\n",
        "            for x, y, *_ in dl:\n",
        "                x, y = x.to(self.device), y.to(self.device)\n",
        "                feats = self.model.forward_features(x) if hasattr(self.model, 'forward_features') else torch.flatten(self.model.avgpool(\n",
        "                    self.model.layer4(\n",
        "                        self.model.layer3(\n",
        "                            self.model.layer2(\n",
        "                                self.model.layer1(\n",
        "                                    self.model.relu(self.model.bn1(self.model.conv1(x)))\n",
        "                                )\n",
        "                            )\n",
        "                        )\n",
        "                    )), 1)\n",
        "                for cls in torch.unique(y):\n",
        "                    mask = y == cls\n",
        "                    if mask.any():\n",
        "                        feats_cls = feats[mask]\n",
        "                        centroids[cls.item()].append(feats_cls.mean(0))\n",
        "                        variances[cls.item()].append(feats_cls.var(0, unbiased=False))\n",
        "                self.replay_buffer.add_samples(x, y)\n",
        "\n",
        "        task_id = self.experience.current_experience\n",
        "        self.old_centroids[task_id] = centroids  # Store for future reference\n",
        "\n",
        "        for cls in centroids:\n",
        "            self.prev_centroids[cls] = torch.stack(centroids[cls]).mean(0).detach().cpu()\n",
        "            self.prev_variances[cls] = torch.stack(variances[cls]).mean(0).detach().cpu()\n",
        "\n",
        "        self.model_old = deepcopy(self.model)\n",
        "        self.model_old.to(self.device)\n",
        "        self.model_old.eval()\n",
        "        for p in self.model_old.parameters():\n",
        "            p.requires_grad = False\n",
        "\n",
        "        self.model.train()\n",
        "        super()._after_training_exp(**kwargs)\n"
      ],
      "metadata": {
        "id": "G5QF6xA3Fe4W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torchvision.models import resnet18\n",
        "\n",
        "model = resnet18(pretrained=False, num_classes=10)\n",
        "model.fc = torch.nn.Linear(model.fc.in_features, 10)\n",
        "model.conv1 = torch.nn.Conv2d(3, 64, kernel_size=3, stride=1, padding=1, bias=False)\n",
        "model.maxpool = torch.nn.Identity()  # remove downsampling for CIFAR\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n"
      ],
      "metadata": {
        "id": "pey9T-sIGk_U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# train & eval\n",
        "strategy = ClusterAwareMinimalReplayCL(\n",
        "    model=model,\n",
        "    optimizer=optimizer,\n",
        "    criterion=torch.nn.CrossEntropyLoss(),\n",
        "    train_mb_size=64,\n",
        "    train_epochs=5,\n",
        "    eval_mb_size=128,\n",
        "    device=device,\n",
        "    evaluator=eval_plugin,\n",
        "    lambda_intra= 1,\n",
        "    max_exemplars_per_class= 30,\n",
        "    lambda_logit= 1,\n",
        "    lambda_anchor = 0.5,\n",
        "    lambda_var = 0\n",
        "\n",
        ")\n",
        "\n",
        "\n",
        "for experience in benchmark_class_il.train_stream:\n",
        "    current_classes = list(set(experience.dataset.targets))\n",
        "    print(f\"Training on classes: {current_classes}\")\n",
        "    print(\"Training on experience\", experience.current_experience)\n",
        "#//strategy.use_replay = True\n",
        "\n",
        "    strategy.train(experience)\n",
        "\n",
        "    print(\"Evaluating on all seen tasks...\")\n",
        "    print(\"Evaluating... Replay should be OFF\")\n",
        "\n",
        "    #strategy.use_replay = False\n",
        "\n",
        "    strategy.eval(benchmark_class_il.test_stream[: experience.current_experience + 1])\n",
        "\n",
        "    results = strategy.evaluator.get_last_metrics()\n",
        "\n",
        "    # Update task accuracy\n",
        "    for key, value in results.items():\n",
        "        if \"Top1_Acc_Exp\" in key:\n",
        "            task_id = int(key.split(\"Exp\")[-1])\n",
        "            strategy.task_accuracies[task_id].append(value)\n",
        "            strategy.max_accuracies[task_id] = max(\n",
        "                strategy.max_accuracies[task_id], value)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7gkbAuWuGu2j",
        "outputId": "2176d9f7-b7e4-41ee-dc52-34eb4361b3e3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training on classes: [0, 1]\n",
            "Training on experience 0\n",
            "-- >> Start of training phase << --\n",
            "100%|██████████| 157/157 [00:37<00:00,  4.14it/s]\n",
            "Epoch 0 ended.\n",
            "100%|██████████| 157/157 [00:36<00:00,  4.25it/s]\n",
            "Epoch 1 ended.\n",
            "100%|██████████| 157/157 [00:36<00:00,  4.29it/s]\n",
            "Epoch 2 ended.\n",
            "100%|██████████| 157/157 [00:38<00:00,  4.05it/s]\n",
            "Epoch 3 ended.\n",
            "100%|██████████| 157/157 [00:41<00:00,  3.82it/s]\n",
            "Epoch 4 ended.\n",
            "-- >> End of training phase << --\n",
            "Evaluating on all seen tasks...\n",
            "Evaluating... Replay should be OFF\n",
            "-- >> Start of eval phase << --\n",
            "-- Starting eval on experience 0 (Task 0) from test stream --\n",
            "100%|██████████| 16/16 [00:02<00:00,  6.35it/s]\n",
            "> Eval on experience 0 (Task 0) from test stream ended.\n",
            "\tTop1_Acc_Exp/eval_phase/test_stream/Task000/Exp000 = 0.9880\n",
            "-- >> End of eval phase << --\n",
            "\tTop1_Acc_Stream/eval_phase/test_stream/Task000 = 0.9880\n",
            "Training on classes: [2, 3]\n",
            "Training on experience 1\n",
            "-- >> Start of training phase << --\n",
            "100%|██████████| 157/157 [01:23<00:00,  1.89it/s]\n",
            "Epoch 0 ended.\n",
            "100%|██████████| 157/157 [01:22<00:00,  1.91it/s]\n",
            "Epoch 1 ended.\n",
            "100%|██████████| 157/157 [01:22<00:00,  1.91it/s]\n",
            "Epoch 2 ended.\n",
            "100%|██████████| 157/157 [01:06<00:00,  2.38it/s]\n",
            "Epoch 3 ended.\n",
            "100%|██████████| 157/157 [01:19<00:00,  1.97it/s]\n",
            "Epoch 4 ended.\n",
            "-- >> End of training phase << --\n",
            "Evaluating on all seen tasks...\n",
            "Evaluating... Replay should be OFF\n",
            "-- >> Start of eval phase << --\n",
            "-- Starting eval on experience 0 (Task 0) from test stream --\n",
            "100%|██████████| 16/16 [00:02<00:00,  6.39it/s]\n",
            "> Eval on experience 0 (Task 0) from test stream ended.\n",
            "\tTop1_Acc_Exp/eval_phase/test_stream/Task000/Exp000 = 0.6670\n",
            "-- Starting eval on experience 1 (Task 0) from test stream --\n",
            "100%|██████████| 16/16 [00:02<00:00,  6.73it/s]\n",
            "> Eval on experience 1 (Task 0) from test stream ended.\n",
            "\tTop1_Acc_Exp/eval_phase/test_stream/Task000/Exp001 = 0.9395\n",
            "-- >> End of eval phase << --\n",
            "\tTop1_Acc_Stream/eval_phase/test_stream/Task000 = 0.8033\n",
            "Training on classes: [4, 5]\n",
            "Training on experience 2\n",
            "-- >> Start of training phase << --\n",
            "100%|██████████| 157/157 [01:17<00:00,  2.01it/s]\n",
            "Epoch 0 ended.\n",
            "100%|██████████| 157/157 [01:25<00:00,  1.84it/s]\n",
            "Epoch 1 ended.\n",
            "100%|██████████| 157/157 [01:27<00:00,  1.80it/s]\n",
            "Epoch 2 ended.\n",
            "100%|██████████| 157/157 [01:24<00:00,  1.85it/s]\n",
            "Epoch 3 ended.\n",
            "100%|██████████| 157/157 [01:17<00:00,  2.01it/s]\n",
            "Epoch 4 ended.\n",
            "-- >> End of training phase << --\n",
            "Evaluating on all seen tasks...\n",
            "Evaluating... Replay should be OFF\n",
            "-- >> Start of eval phase << --\n",
            "-- Starting eval on experience 0 (Task 0) from test stream --\n",
            "100%|██████████| 16/16 [00:01<00:00,  9.23it/s]\n",
            "> Eval on experience 0 (Task 0) from test stream ended.\n",
            "\tTop1_Acc_Exp/eval_phase/test_stream/Task000/Exp000 = 0.6630\n",
            "-- Starting eval on experience 1 (Task 0) from test stream --\n",
            "100%|██████████| 16/16 [00:01<00:00,  9.21it/s]\n",
            "> Eval on experience 1 (Task 0) from test stream ended.\n",
            "\tTop1_Acc_Exp/eval_phase/test_stream/Task000/Exp001 = 0.1405\n",
            "-- Starting eval on experience 2 (Task 0) from test stream --\n",
            "100%|██████████| 16/16 [00:01<00:00,  9.92it/s]\n",
            "> Eval on experience 2 (Task 0) from test stream ended.\n",
            "\tTop1_Acc_Exp/eval_phase/test_stream/Task000/Exp002 = 0.9585\n",
            "-- >> End of eval phase << --\n",
            "\tTop1_Acc_Stream/eval_phase/test_stream/Task000 = 0.5873\n",
            "Training on classes: [6, 7]\n",
            "Training on experience 3\n",
            "-- >> Start of training phase << --\n",
            "100%|██████████| 157/157 [01:13<00:00,  2.14it/s]\n",
            "Epoch 0 ended.\n",
            "100%|██████████| 157/157 [01:23<00:00,  1.87it/s]\n",
            "Epoch 1 ended.\n",
            "100%|██████████| 157/157 [01:06<00:00,  2.38it/s]\n",
            "Epoch 2 ended.\n",
            "100%|██████████| 157/157 [01:14<00:00,  2.10it/s]\n",
            "Epoch 3 ended.\n",
            "100%|██████████| 157/157 [01:12<00:00,  2.17it/s]\n",
            "Epoch 4 ended.\n",
            "-- >> End of training phase << --\n",
            "Evaluating on all seen tasks...\n",
            "Evaluating... Replay should be OFF\n",
            "-- >> Start of eval phase << --\n",
            "-- Starting eval on experience 0 (Task 0) from test stream --\n",
            "100%|██████████| 16/16 [00:02<00:00,  6.40it/s]\n",
            "> Eval on experience 0 (Task 0) from test stream ended.\n",
            "\tTop1_Acc_Exp/eval_phase/test_stream/Task000/Exp000 = 0.6250\n",
            "-- Starting eval on experience 1 (Task 0) from test stream --\n",
            "100%|██████████| 16/16 [00:02<00:00,  6.40it/s]\n",
            "> Eval on experience 1 (Task 0) from test stream ended.\n",
            "\tTop1_Acc_Exp/eval_phase/test_stream/Task000/Exp001 = 0.0645\n",
            "-- Starting eval on experience 2 (Task 0) from test stream --\n",
            "100%|██████████| 16/16 [00:02<00:00,  6.24it/s]\n",
            "> Eval on experience 2 (Task 0) from test stream ended.\n",
            "\tTop1_Acc_Exp/eval_phase/test_stream/Task000/Exp002 = 0.3645\n",
            "-- Starting eval on experience 3 (Task 0) from test stream --\n",
            "100%|██████████| 16/16 [00:02<00:00,  6.34it/s]\n",
            "> Eval on experience 3 (Task 0) from test stream ended.\n",
            "\tTop1_Acc_Exp/eval_phase/test_stream/Task000/Exp003 = 0.9790\n",
            "-- >> End of eval phase << --\n",
            "\tTop1_Acc_Stream/eval_phase/test_stream/Task000 = 0.5082\n",
            "Training on classes: [8, 9]\n",
            "Training on experience 4\n",
            "-- >> Start of training phase << --\n",
            "100%|██████████| 157/157 [01:18<00:00,  1.99it/s]\n",
            "Epoch 0 ended.\n",
            "100%|██████████| 157/157 [01:15<00:00,  2.08it/s]\n",
            "Epoch 1 ended.\n",
            "100%|██████████| 157/157 [01:15<00:00,  2.07it/s]\n",
            "Epoch 2 ended.\n",
            "100%|██████████| 157/157 [01:23<00:00,  1.87it/s]\n",
            "Epoch 3 ended.\n",
            "100%|██████████| 157/157 [01:28<00:00,  1.78it/s]\n",
            "Epoch 4 ended.\n",
            "-- >> End of training phase << --\n",
            "Evaluating on all seen tasks...\n",
            "Evaluating... Replay should be OFF\n",
            "-- >> Start of eval phase << --\n",
            "-- Starting eval on experience 0 (Task 0) from test stream --\n",
            "100%|██████████| 16/16 [00:02<00:00,  6.67it/s]\n",
            "> Eval on experience 0 (Task 0) from test stream ended.\n",
            "\tTop1_Acc_Exp/eval_phase/test_stream/Task000/Exp000 = 0.1605\n",
            "-- Starting eval on experience 1 (Task 0) from test stream --\n",
            "100%|██████████| 16/16 [00:02<00:00,  6.69it/s]\n",
            "> Eval on experience 1 (Task 0) from test stream ended.\n",
            "\tTop1_Acc_Exp/eval_phase/test_stream/Task000/Exp001 = 0.0980\n",
            "-- Starting eval on experience 2 (Task 0) from test stream --\n",
            "100%|██████████| 16/16 [00:02<00:00,  6.68it/s]\n",
            "> Eval on experience 2 (Task 0) from test stream ended.\n",
            "\tTop1_Acc_Exp/eval_phase/test_stream/Task000/Exp002 = 0.4705\n",
            "-- Starting eval on experience 3 (Task 0) from test stream --\n",
            "100%|██████████| 16/16 [00:02<00:00,  6.64it/s]\n",
            "> Eval on experience 3 (Task 0) from test stream ended.\n",
            "\tTop1_Acc_Exp/eval_phase/test_stream/Task000/Exp003 = 0.8160\n",
            "-- Starting eval on experience 4 (Task 0) from test stream --\n",
            "100%|██████████| 16/16 [00:02<00:00,  6.66it/s]\n",
            "> Eval on experience 4 (Task 0) from test stream ended.\n",
            "\tTop1_Acc_Exp/eval_phase/test_stream/Task000/Exp004 = 0.9820\n",
            "-- >> End of eval phase << --\n",
            "\tTop1_Acc_Stream/eval_phase/test_stream/Task000 = 0.5054\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Wp-myA_3Gu9z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class EpisodicMemoryBuffer:\n",
        "    def __init__(self, device,  max_exemplars_per_class=30):\n",
        "        self.device = device\n",
        "        self.max_exemplars_per_class = max_exemplars_per_class\n",
        "        self.memory = defaultdict(list)\n",
        "\n",
        "    def add_samples(self, x, y):\n",
        "        for xi, yi in zip(x, y):\n",
        "            cls = yi.item()\n",
        "            if len(self.memory[cls]) < self.max_exemplars_per_class:\n",
        "                self.memory[cls].append((xi.detach().cpu(), yi.detach().cpu()))\n",
        "            else:\n",
        "                idx = torch.randint(0, self.max_exemplars_per_class, (1,)).item()\n",
        "                self.memory[cls][idx] = (xi.detach().cpu(), yi.detach().cpu())\n",
        "\n",
        "    def sample_batch(self, batch_size=32):\n",
        "        if len(self.memory) == 0:\n",
        "            return None, None\n",
        "\n",
        "        class_samples = []\n",
        "        num_classes = len(self.memory)\n",
        "        if num_classes == 0:\n",
        "            return None, None\n",
        "\n",
        "        samples_per_class = max(1, batch_size // num_classes)\n",
        "\n",
        "        for cls, items in self.memory.items():\n",
        "            if len(items) == 0:\n",
        "                continue\n",
        "            n = min(samples_per_class, len(items))\n",
        "            class_samples.extend(random.sample(items, n))\n",
        "\n",
        "        if not class_samples:\n",
        "            return None, None\n",
        "\n",
        "        samples = random.sample(class_samples, min(batch_size, len(class_samples)))\n",
        "        xs, ys = zip(*samples)\n",
        "        return torch.stack(xs).to(self.device), torch.stack(ys).to(self.device)\n",
        "\n",
        "from copy import deepcopy\n",
        "\n",
        "class ClusterAwareMinimalReplayCL(SupervisedTemplate):\n",
        "    def __init__(self, *, model, optimizer, device, lambda_intra=1.0, lambda_anchor=0.1,\n",
        "                 lambda_logit=0.05, lambda_var=0.0, criterion=torch.nn.CrossEntropyLoss(),\n",
        "                 max_exemplars_per_class=30, use_replay=True, **kwargs):\n",
        "        super().__init__(model=model, optimizer=optimizer, criterion=criterion, device=device, **kwargs)\n",
        "\n",
        "        self.lambda_intra = lambda_intra\n",
        "        self.lambda_anchor = lambda_anchor\n",
        "        self.lambda_logit = lambda_logit\n",
        "        self.lambda_var = lambda_var\n",
        "        self.device = device\n",
        "\n",
        "        self.prev_centroids = {}\n",
        "        self.prev_variances = {}\n",
        "        self.model_old = None\n",
        "        self.old_centroids = {}  # task_id → centroid map\n",
        "        self.task_accuracies = defaultdict(list)\n",
        "        self.max_accuracies = defaultdict(float)\n",
        "\n",
        "        self.replay_buffer = EpisodicMemoryBuffer(device, max_exemplars_per_class)\n",
        "        self.use_replay = use_replay\n",
        "\n",
        "        self.experience = None\n",
        "\n",
        "        # -------------------------\n",
        "    # 🎯 Accuracy + Replay Debug Logic\n",
        "    # -------------------------\n",
        "\n",
        "    def update_task_accuracy(self, results):\n",
        "        for key, value in results.items():\n",
        "            if \"Top1_Acc_Exp\" in key:\n",
        "                task_id = int(key.split(\"Exp\")[-1])\n",
        "                self.task_accuracies[task_id].append(value)\n",
        "                self.max_accuracies[task_id] = max(self.max_accuracies[task_id], value)\n",
        "\n",
        "    # -------------------------\n",
        "    # 🔍 Loss Function (with dynamic replay weight)\n",
        "    # -------------------------\n",
        "\n",
        "    def criterion(self):\n",
        "        feats = F.normalize(self.prev_feats, p=2, dim=1)\n",
        "        targets = self.current_y\n",
        "\n",
        "        current_logits = self.logits[~self.replay_mask]\n",
        "        current_targets = targets[~self.replay_mask]\n",
        "        replay_logits = self.logits[self.replay_mask]\n",
        "        replay_targets = targets[self.replay_mask]\n",
        "\n",
        "        ce_current = self._criterion(current_logits, current_targets)\n",
        "        # if len(replay_targets) > 0:\n",
        "        #     # Dynamic weighting: prioritize forgotten or older task classes\n",
        "        #     weights = torch.ones_like(replay_targets, dtype=torch.float)\n",
        "        #     for i, y in enumerate(replay_targets):\n",
        "        #         task_id = y.item() // 2  # assuming class group size 2 (SplitCIFAR10)\n",
        "        #         if self.task_accuracies[task_id]:\n",
        "        #             recent_acc = self.task_accuracies[task_id][-1]\n",
        "        #             weights[i] = 1.5 if recent_acc < 0.5 else 1.0\n",
        "        #     ce_replay = F.cross_entropy(replay_logits, replay_targets, reduction='none')\n",
        "        #     ce_replay = (ce_replay * weights.to(replay_logits.device)).mean()\n",
        "        # else:\n",
        "        #     ce_replay = 0.0\n",
        "        ce_replay = self._criterion(replay_logits, replay_targets) if len(replay_targets) > 0 else 0.0\n",
        "        ce_loss = ce_current + 0.5 * ce_replay\n",
        "\n",
        "        #ce_loss = ce_current + 0.5 * ce_replay\n",
        "\n",
        "        # Feature regularization (L2 distance between feats and detached copy)\n",
        "        feat_reg = 0.0\n",
        "        if hasattr(self, 'prev_feats') and self.prev_feats is not None:\n",
        "            feat_reg = F.mse_loss(self.prev_feats, self.prev_feats.detach())\n",
        "\n",
        "        # Centroids and variance terms\n",
        "        curr_centroids, curr_variances = {}, {}\n",
        "        for cls in torch.unique(targets):\n",
        "            mask = targets == cls\n",
        "            feats_cls = feats[mask]\n",
        "            curr_centroids[cls.item()] = feats_cls.mean(0)\n",
        "            curr_variances[cls.item()] = feats_cls.var(0, unbiased=False)\n",
        "\n",
        "        inter_cluster_loss = 0.0\n",
        "        cls_list = list(curr_centroids.keys())\n",
        "        for i in range(len(cls_list)):\n",
        "            for j in range(i + 1, len(cls_list)):\n",
        "                inter_cluster_loss += F.mse_loss(curr_centroids[cls_list[i]], curr_centroids[cls_list[j]])\n",
        "        if len(cls_list) > 1:\n",
        "            inter_cluster_loss /= len(cls_list) * (len(cls_list) - 1) / 2\n",
        "\n",
        "        anchor_loss = 0.0\n",
        "        for cls, prev_mu in self.prev_centroids.items():\n",
        "            if cls in curr_centroids:\n",
        "                anchor_loss += F.mse_loss(curr_centroids[cls], prev_mu.to(feats.device))\n",
        "        if self.prev_centroids:\n",
        "            anchor_loss /= len(self.prev_centroids)\n",
        "\n",
        "        var_loss = 0.0\n",
        "        for cls, prev_var in self.prev_variances.items():\n",
        "            if cls in curr_variances:\n",
        "                var_loss += F.mse_loss(curr_variances[cls], prev_var.to(feats.device))\n",
        "        if self.prev_variances:\n",
        "            var_loss /= len(self.prev_variances)\n",
        "\n",
        "        logit_loss = 0.0\n",
        "        if self.model_old is not None and self.replay_mask.any():\n",
        "            with torch.no_grad():\n",
        "                old_logits = self.model_old(self.current_x[self.replay_mask])\n",
        "            logit_loss = F.mse_loss(self.logits[self.replay_mask], old_logits)\n",
        "\n",
        "        return ce_loss + self.lambda_intra * inter_cluster_loss + \\\n",
        "               self.lambda_anchor * anchor_loss + \\\n",
        "               self.lambda_logit * logit_loss + \\\n",
        "               self.lambda_var * var_loss + 0.1 * feat_reg\n",
        "\n",
        "    def forward(self):\n",
        "        x = self.mb_x\n",
        "        y = self.mb_y\n",
        "\n",
        "        self.clean_x = x\n",
        "        self.clean_y = y\n",
        "        replay_mask = torch.zeros_like(y, dtype=torch.bool)\n",
        "\n",
        "        if self.model.training and self.use_replay:\n",
        "            rx, ry = self.replay_buffer.sample_batch(batch_size=x.size(0))\n",
        "            if rx is not None:\n",
        "                x = torch.cat([x, rx], dim=0)\n",
        "                y = torch.cat([y, ry], dim=0)\n",
        "                replay_mask = torch.cat([\n",
        "                    torch.zeros_like(self.mb_y, dtype=torch.bool),\n",
        "                    torch.ones_like(ry, dtype=torch.bool)\n",
        "                ], dim=0)\n",
        "\n",
        "        self.replay_mask = replay_mask\n",
        "        self.current_x = x\n",
        "        self.current_y = y\n",
        "        if hasattr(self.model, 'forward_features'):\n",
        "            feats = self.model.forward_features(x)\n",
        "        else:\n",
        "            feats = self.model.avgpool(\n",
        "                self.model.layer4(\n",
        "                    self.model.layer3(\n",
        "                        self.model.layer2(\n",
        "                            self.model.layer1(\n",
        "                                self.model.relu(self.model.bn1(self.model.conv1(x)))\n",
        "                            )\n",
        "                        )\n",
        "                    )\n",
        "                )\n",
        "            )\n",
        "            feats = torch.flatten(feats, 1)\n",
        "        self.prev_feats = feats\n",
        "        self.logits = self.model.fc(feats)\n",
        "        return self.logits\n",
        "\n",
        "    def _after_training_exp(self, **kwargs):\n",
        "        self.model.eval()\n",
        "        dl = DataLoader(self.adapted_dataset, batch_size=128, shuffle=True)\n",
        "        centroids, variances = defaultdict(list), defaultdict(list)\n",
        "        with torch.no_grad():\n",
        "            for x, y, *_ in dl:\n",
        "                x, y = x.to(self.device), y.to(self.device)\n",
        "                feats = self.model.forward_features(x) if hasattr(self.model, 'forward_features') else torch.flatten(self.model.avgpool(\n",
        "                    self.model.layer4(\n",
        "                        self.model.layer3(\n",
        "                            self.model.layer2(\n",
        "                                self.model.layer1(\n",
        "                                    self.model.relu(self.model.bn1(self.model.conv1(x)))\n",
        "                                )\n",
        "                            )\n",
        "                        )\n",
        "                    )), 1)\n",
        "                for cls in torch.unique(y):\n",
        "                    mask = y == cls\n",
        "                    if mask.any():\n",
        "                        feats_cls = feats[mask]\n",
        "                        centroids[cls.item()].append(feats_cls.mean(0))\n",
        "                        variances[cls.item()].append(feats_cls.var(0, unbiased=False))\n",
        "                self.replay_buffer.add_samples(x, y)\n",
        "\n",
        "        task_id = self.experience.current_experience\n",
        "        self.old_centroids[task_id] = centroids  # Store for future reference\n",
        "\n",
        "        for cls in centroids:\n",
        "            self.prev_centroids[cls] = torch.stack(centroids[cls]).mean(0).detach().cpu()\n",
        "            self.prev_variances[cls] = torch.stack(variances[cls]).mean(0).detach().cpu()\n",
        "\n",
        "        self.model_old = resnet18(pretrained=False, num_classes=self.model.fc.out_features)\n",
        "        self.model_old.conv1 = torch.nn.Conv2d(3, 64, kernel_size=3, stride=1, padding=1, bias=False)\n",
        "        self.model_old.maxpool = torch.nn.Identity()\n",
        "        self.model_old.load_state_dict(self.model.state_dict())\n",
        "        self.model_old.to(self.device)\n",
        "        self.model_old.eval()\n",
        "        for p in self.model_old.parameters():\n",
        "            p.requires_grad = False\n",
        "\n",
        "        self.model.train()\n",
        "        super()._after_training_exp(**kwargs)\n"
      ],
      "metadata": {
        "id": "N6d3q2a0UnHe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# train & eval\n",
        "strategy = ClusterAwareMinimalReplayCL(\n",
        "    model=model,\n",
        "    optimizer=optimizer,\n",
        "    criterion=torch.nn.CrossEntropyLoss(),\n",
        "    train_mb_size=64,\n",
        "    train_epochs=5,\n",
        "    eval_mb_size=128,\n",
        "    device=device,\n",
        "    evaluator=eval_plugin,\n",
        "    lambda_intra= 1,\n",
        "    max_exemplars_per_class= 30,\n",
        "    lambda_logit= 1,\n",
        "    lambda_anchor = 0.5,\n",
        "    lambda_var = 0\n",
        "\n",
        ")\n",
        "\n",
        "\n",
        "for experience in benchmark_class_il.train_stream:\n",
        "    current_classes = list(set(experience.dataset.targets))\n",
        "    print(f\"Training on classes: {current_classes}\")\n",
        "    print(\"Training on experience\", experience.current_experience)\n",
        "#//strategy.use_replay = True\n",
        "\n",
        "    strategy.train(experience)\n",
        "\n",
        "    print(\"Evaluating on all seen tasks...\")\n",
        "    print(\"Evaluating... Replay should be OFF\")\n",
        "\n",
        "    #strategy.use_replay = False\n",
        "\n",
        "    strategy.eval(benchmark_class_il.test_stream[: experience.current_experience + 1])\n",
        "\n",
        "    #results = strategy.evaluator.get_last_metrics()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "D2M3UAEYUv4W",
        "outputId": "04a46678-ed10-421a-fdae-da0c1a835dcd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training on classes: [0, 1]\n",
            "Training on experience 0\n",
            "-- >> Start of training phase << --\n",
            "100%|██████████| 157/157 [00:34<00:00,  4.51it/s]\n",
            "Epoch 0 ended.\n",
            "100%|██████████| 157/157 [00:39<00:00,  4.01it/s]\n",
            "Epoch 1 ended.\n",
            "100%|██████████| 157/157 [00:36<00:00,  4.35it/s]\n",
            "Epoch 2 ended.\n",
            "100%|██████████| 157/157 [00:39<00:00,  3.97it/s]\n",
            "Epoch 3 ended.\n",
            "100%|██████████| 157/157 [00:39<00:00,  4.00it/s]\n",
            "Epoch 4 ended.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=None`.\n",
            "  warnings.warn(msg)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-- >> End of training phase << --\n",
            "Evaluating on all seen tasks...\n",
            "Evaluating... Replay should be OFF\n",
            "-- >> Start of eval phase << --\n",
            "-- Starting eval on experience 0 (Task 0) from test stream --\n",
            "100%|██████████| 16/16 [00:02<00:00,  7.39it/s]\n",
            "> Eval on experience 0 (Task 0) from test stream ended.\n",
            "\tTop1_Acc_Exp/eval_phase/test_stream/Task000/Exp000 = 0.9855\n",
            "-- >> End of eval phase << --\n",
            "\tTop1_Acc_Stream/eval_phase/test_stream/Task000 = 0.9855\n",
            "Training on classes: [2, 3]\n",
            "Training on experience 1\n",
            "-- >> Start of training phase << --\n",
            "100%|██████████| 157/157 [01:11<00:00,  2.18it/s]\n",
            "Epoch 0 ended.\n",
            "100%|██████████| 157/157 [01:15<00:00,  2.08it/s]\n",
            "Epoch 1 ended.\n",
            "100%|██████████| 157/157 [01:19<00:00,  1.99it/s]\n",
            "Epoch 2 ended.\n",
            "100%|██████████| 157/157 [01:07<00:00,  2.32it/s]\n",
            "Epoch 3 ended.\n",
            "100%|██████████| 157/157 [01:04<00:00,  2.44it/s]\n",
            "Epoch 4 ended.\n",
            "-- >> End of training phase << --\n",
            "Evaluating on all seen tasks...\n",
            "Evaluating... Replay should be OFF\n",
            "-- >> Start of eval phase << --\n",
            "-- Starting eval on experience 0 (Task 0) from test stream --\n",
            "100%|██████████| 16/16 [00:02<00:00,  7.18it/s]\n",
            "> Eval on experience 0 (Task 0) from test stream ended.\n",
            "\tTop1_Acc_Exp/eval_phase/test_stream/Task000/Exp000 = 0.6495\n",
            "-- Starting eval on experience 1 (Task 0) from test stream --\n",
            "100%|██████████| 16/16 [00:02<00:00,  7.21it/s]\n",
            "> Eval on experience 1 (Task 0) from test stream ended.\n",
            "\tTop1_Acc_Exp/eval_phase/test_stream/Task000/Exp001 = 0.9385\n",
            "-- >> End of eval phase << --\n",
            "\tTop1_Acc_Stream/eval_phase/test_stream/Task000 = 0.7940\n",
            "Training on classes: [4, 5]\n",
            "Training on experience 2\n",
            "-- >> Start of training phase << --\n",
            "100%|██████████| 157/157 [01:22<00:00,  1.91it/s]\n",
            "Epoch 0 ended.\n",
            "100%|██████████| 157/157 [01:29<00:00,  1.76it/s]\n",
            "Epoch 1 ended.\n",
            "100%|██████████| 157/157 [01:19<00:00,  1.99it/s]\n",
            "Epoch 2 ended.\n",
            "100%|██████████| 157/157 [01:10<00:00,  2.22it/s]\n",
            "Epoch 3 ended.\n",
            "100%|██████████| 157/157 [01:18<00:00,  2.00it/s]\n",
            "Epoch 4 ended.\n",
            "-- >> End of training phase << --\n",
            "Evaluating on all seen tasks...\n",
            "Evaluating... Replay should be OFF\n",
            "-- >> Start of eval phase << --\n",
            "-- Starting eval on experience 0 (Task 0) from test stream --\n",
            "100%|██████████| 16/16 [00:02<00:00,  7.32it/s]\n",
            "> Eval on experience 0 (Task 0) from test stream ended.\n",
            "\tTop1_Acc_Exp/eval_phase/test_stream/Task000/Exp000 = 0.6285\n",
            "-- Starting eval on experience 1 (Task 0) from test stream --\n",
            "100%|██████████| 16/16 [00:02<00:00,  7.34it/s]\n",
            "> Eval on experience 1 (Task 0) from test stream ended.\n",
            "\tTop1_Acc_Exp/eval_phase/test_stream/Task000/Exp001 = 0.1625\n",
            "-- Starting eval on experience 2 (Task 0) from test stream --\n",
            "100%|██████████| 16/16 [00:02<00:00,  7.28it/s]\n",
            "> Eval on experience 2 (Task 0) from test stream ended.\n",
            "\tTop1_Acc_Exp/eval_phase/test_stream/Task000/Exp002 = 0.9615\n",
            "-- >> End of eval phase << --\n",
            "\tTop1_Acc_Stream/eval_phase/test_stream/Task000 = 0.5842\n",
            "Training on classes: [6, 7]\n",
            "Training on experience 3\n",
            "-- >> Start of training phase << --\n",
            " 46%|████▌     | 72/157 [00:27<00:37,  2.25it/s]"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-122-2548203900.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;31m#//strategy.use_replay = True\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m     \u001b[0mstrategy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexperience\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     27\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Evaluating on all seen tasks...\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/avalanche/training/templates/base_sgd.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, experiences, eval_streams, **kwargs)\u001b[0m\n\u001b[1;32m    211\u001b[0m         \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    212\u001b[0m     ):\n\u001b[0;32m--> 213\u001b[0;31m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexperiences\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0meval_streams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    214\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_last_metrics\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    215\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/avalanche/training/templates/base.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, experiences, eval_streams, **kwargs)\u001b[0m\n\u001b[1;32m    161\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperience\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mexperiences_list\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    162\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_before_training_exp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 163\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_train_exp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperience\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0meval_streams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    164\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_after_training_exp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    165\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_after_training\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/avalanche/training/templates/base_sgd.py\u001b[0m in \u001b[0;36m_train_exp\u001b[0;34m(self, experience, eval_streams, **kwargs)\u001b[0m\n\u001b[1;32m    337\u001b[0m                 \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    338\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 339\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtraining_epoch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    340\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_after_training_epoch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    341\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/avalanche/training/templates/update_type/sgd_update.py\u001b[0m in \u001b[0;36mtraining_epoch\u001b[0;34m(self, **kwargs)\u001b[0m\n\u001b[1;32m     36\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_before_backward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 38\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     39\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_after_backward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/avalanche/training/templates/base_sgd.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    259\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    260\u001b[0m         \u001b[0;34m\"\"\"Run the backward pass.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 261\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mretain_graph\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mretain_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    262\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    263\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0moptimizer_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    624\u001b[0m                 \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    625\u001b[0m             )\n\u001b[0;32m--> 626\u001b[0;31m         torch.autograd.backward(\n\u001b[0m\u001b[1;32m    627\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    628\u001b[0m         )\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    345\u001b[0m     \u001b[0;31m# some Python versions print out the first line of a multi-line function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    346\u001b[0m     \u001b[0;31m# calls in the traceback and some print out the last line\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 347\u001b[0;31m     _engine_run_backward(\n\u001b[0m\u001b[1;32m    348\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    349\u001b[0m         \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\u001b[0m in \u001b[0;36m_engine_run_backward\u001b[0;34m(t_outputs, *args, **kwargs)\u001b[0m\n\u001b[1;32m    821\u001b[0m         \u001b[0munregister_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_register_logging_hooks_on_whole_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt_outputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    822\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 823\u001b[0;31m         return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n\u001b[0m\u001b[1;32m    824\u001b[0m             \u001b[0mt_outputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    825\u001b[0m         )  # Calls into the C++ engine to run the backward pass\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from avalanche.training.supervised import Replay\n",
        "\n",
        "strategy = Naive(\n",
        "    model=model,\n",
        "    optimizer=optimizer,\n",
        "    criterion=torch.nn.CrossEntropyLoss(),\n",
        "    train_mb_size=64,\n",
        "    train_epochs=5,\n",
        "    eval_mb_size=128,\n",
        "    device=device,\n",
        ")\n",
        "\n",
        "for experience in benchmark_class_il.train_stream:\n",
        "    current_classes = list(set(experience.dataset.targets))\n",
        "    print(f\"Training on classes: {current_classes}\")\n",
        "    print(\"Training on experience\", experience.current_experience)\n",
        "\n",
        "    strategy.train(experience)\n",
        "\n",
        "    print(\"Evaluating on all seen tasks...\")\n",
        "\n",
        "    strategy.eval(benchmark_class_il.test_stream[: experience.current_experience + 1])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 418
        },
        "id": "hPsA__yIuSiu",
        "outputId": "728b1003-6daf-46cf-dbea-98937ad947eb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training on classes: [0, 1]\n",
            "Training on experience 0\n",
            "-- >> Start of training phase << --\n",
            " 22%|██▏       | 34/157 [00:06<00:21,  5.72it/s]"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-69-3323712590.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     16\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Training on experience\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexperience\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcurrent_experience\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m     \u001b[0mstrategy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexperience\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Evaluating on all seen tasks...\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/avalanche/training/templates/base_sgd.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, experiences, eval_streams, **kwargs)\u001b[0m\n\u001b[1;32m    211\u001b[0m         \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    212\u001b[0m     ):\n\u001b[0;32m--> 213\u001b[0;31m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexperiences\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0meval_streams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    214\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_last_metrics\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    215\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/avalanche/training/templates/base.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, experiences, eval_streams, **kwargs)\u001b[0m\n\u001b[1;32m    161\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperience\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mexperiences_list\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    162\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_before_training_exp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 163\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_train_exp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperience\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0meval_streams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    164\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_after_training_exp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    165\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_after_training\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/avalanche/training/templates/base_sgd.py\u001b[0m in \u001b[0;36m_train_exp\u001b[0;34m(self, experience, eval_streams, **kwargs)\u001b[0m\n\u001b[1;32m    337\u001b[0m                 \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    338\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 339\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtraining_epoch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    340\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_after_training_epoch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    341\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/avalanche/training/templates/update_type/sgd_update.py\u001b[0m in \u001b[0;36mtraining_epoch\u001b[0;34m(self, **kwargs)\u001b[0m\n\u001b[1;32m     36\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_before_backward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 38\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     39\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_after_backward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/avalanche/training/templates/base_sgd.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    259\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    260\u001b[0m         \u001b[0;34m\"\"\"Run the backward pass.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 261\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mretain_graph\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mretain_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    262\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    263\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0moptimizer_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    624\u001b[0m                 \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    625\u001b[0m             )\n\u001b[0;32m--> 626\u001b[0;31m         torch.autograd.backward(\n\u001b[0m\u001b[1;32m    627\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    628\u001b[0m         )\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    345\u001b[0m     \u001b[0;31m# some Python versions print out the first line of a multi-line function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    346\u001b[0m     \u001b[0;31m# calls in the traceback and some print out the last line\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 347\u001b[0;31m     _engine_run_backward(\n\u001b[0m\u001b[1;32m    348\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    349\u001b[0m         \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\u001b[0m in \u001b[0;36m_engine_run_backward\u001b[0;34m(t_outputs, *args, **kwargs)\u001b[0m\n\u001b[1;32m    821\u001b[0m         \u001b[0munregister_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_register_logging_hooks_on_whole_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt_outputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    822\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 823\u001b[0;31m         return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n\u001b[0m\u001b[1;32m    824\u001b[0m             \u001b[0mt_outputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    825\u001b[0m         )  # Calls into the C++ engine to run the backward pass\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "xZ8H9qwichwJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from avalanche.training.supervised import Replay\n",
        "\n",
        "strategy = Replay(\n",
        "    model=model,\n",
        "    optimizer=optimizer,\n",
        "    criterion=torch.nn.CrossEntropyLoss(),\n",
        "    mem_size=200,\n",
        "    train_mb_size=64,\n",
        "    train_epochs=5,\n",
        "    eval_mb_size=128,\n",
        "    device=device,\n",
        ")\n",
        "\n",
        "for experience in benchmark_class_il.train_stream:\n",
        "    current_classes = list(set(experience.dataset.targets))\n",
        "    print(f\"Training on classes: {current_classes}\")\n",
        "    print(\"Training on experience\", experience.current_experience)\n",
        "\n",
        "    strategy.train(experience)\n",
        "\n",
        "    print(\"Evaluating on all seen tasks...\")\n",
        "\n",
        "    strategy.eval(benchmark_class_il.test_stream[: experience.current_experience + 1])"
      ],
      "metadata": {
        "id": "cIwt5HzJ7PGu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# EWC baseline ------------------------------------------------------------\n",
        "from avalanche.training.supervised import EWC\n",
        "\n",
        "strategy = EWC(\n",
        "    model=model,\n",
        "    optimizer=optimizer,\n",
        "    criterion=torch.nn.CrossEntropyLoss(),\n",
        "    ewc_lambda=0.4,  # importance of penalty\n",
        "    mode='separate',  # one FIM per task\n",
        "    train_mb_size=64,\n",
        "    train_epochs=5,\n",
        "    eval_mb_size=128,\n",
        "    device=device,\n",
        ")\n",
        "\n",
        "for experience in benchmark_class_il.train_stream:\n",
        "    current_classes = list(set(experience.dataset.targets))\n",
        "    print(f\"Training on classes: {current_classes}\")\n",
        "    print(\"Training on experience\", experience.current_experience)\n",
        "\n",
        "    strategy.train(experience)\n",
        "\n",
        "    print(\"Evaluating on all seen tasks...\")\n",
        "\n",
        "    strategy.eval(benchmark_class_il.test_stream[: experience.current_experience + 1])"
      ],
      "metadata": {
        "id": "vCKlAm5kuufM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class ResNet18(nn.Module):\n",
        "    \"\"\"A ResNet-18 model adapted for feature extraction.\"\"\"\n",
        "    def __init__(self, num_classes=10):\n",
        "        super(ResNet18, self).__init__()\n",
        "        base_model = resnet18(weights=None)\n",
        "        self.features = nn.Sequential(*list(base_model.children())[:-1])\n",
        "        self.classifier = nn.Linear(base_model.fc.in_features, num_classes)\n",
        "\n",
        "    def forward(self, x):\n",
        "        f = self.features(x)\n",
        "        f = f.view(f.size(0), -1)\n",
        "        y = self.classifier(f)\n",
        "        return y\n",
        "\n",
        "# =============================================================================\n",
        "# 2. DATA HANDLING & REPLAY BUFFER\n",
        "# =============================================================================\n",
        "\n",
        "class TaskDataset(Dataset):\n",
        "    \"\"\"A custom dataset to provide data for a specific task (a set of classes).\"\"\"\n",
        "    def __init__(self, dataset, task_classes):\n",
        "        self.dataset = dataset\n",
        "        self.task_classes = task_classes\n",
        "        self.indices = []\n",
        "        targets = np.array(self.dataset.targets)\n",
        "        for cls in task_classes:\n",
        "            self.indices.extend(np.where(targets == cls)[0])\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.indices)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        return self.dataset[self.indices[idx]]\n",
        "\n",
        "class ReplayBuffer(Dataset):\n",
        "    \"\"\"A tiny memory buffer to store exemplars from past tasks.\"\"\"\n",
        "    def __init__(self, exemplars_per_class=10):\n",
        "        self.exemplars_per_class = exemplars_per_class\n",
        "        self.memory = {}\n",
        "\n",
        "    def add_exemplars(self, dataset, task_classes):\n",
        "        \"\"\"Adds exemplars for the given classes to the memory.\"\"\"\n",
        "        for cls in task_classes:\n",
        "            cls_dataset = TaskDataset(dataset, [cls])\n",
        "            self.memory[cls] = [cls_dataset[i] for i in range(len(cls_dataset))]\n",
        "            if len(self.memory[cls]) > self.exemplars_per_class:\n",
        "                self.memory[cls] = random.sample(self.memory[cls], self.exemplars_per_class)\n",
        "\n",
        "    def __len__(self):\n",
        "        return sum(len(samples) for samples in self.memory.values())\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        for cls, samples in self.memory.items():\n",
        "            if idx < len(samples):\n",
        "                return samples[idx]\n",
        "            idx -= len(samples)\n",
        "        raise IndexError(\"Index out of range\")\n",
        "\n",
        "# =============================================================================\n",
        "# 3. CUSTOM LOSS FUNCTION (FITNESS FUNCTION)\n",
        "# =============================================================================\n",
        "\n",
        "class InterClusterLoss(nn.Module):\n",
        "    \"\"\"\n",
        "    This loss acts as a \"fitness function\" to maximize the inter-cluster distance.\n",
        "    It pushes the feature clusters of new classes away from the centroids of old classes.\n",
        "    \"\"\"\n",
        "    def __init__(self, lambda_reg=1.0):\n",
        "        super(InterClusterLoss, self).__init__()\n",
        "        self.lambda_reg = lambda_reg\n",
        "        self.class_centroids = {}\n",
        "\n",
        "    def forward(self, features, targets):\n",
        "        \"\"\"Calculates the fitness by maximizing Euclidean distance between NORMALIZED features.\"\"\"\n",
        "        if not self.class_centroids:\n",
        "            return torch.tensor(0.0, device=features.device)\n",
        "\n",
        "        # *** CRITICAL FIX: Normalize features to have a unit length (L2 norm = 1) ***\n",
        "        # This prevents the loss from exploding by stopping the model from making feature vectors infinitely long.\n",
        "        features = F.normalize(features.view(features.size(0), -1), p=2, dim=1)\n",
        "\n",
        "        loss = torch.tensor(0.0, device=features.device)\n",
        "        count = 0\n",
        "        current_classes = torch.unique(targets)\n",
        "\n",
        "        for cls_idx in current_classes:\n",
        "            class_features = features[targets == cls_idx]\n",
        "            for old_cls_idx, old_centroid in self.class_centroids.items():\n",
        "                if cls_idx.item() != old_cls_idx:\n",
        "                    distance = torch.cdist(class_features, old_centroid.unsqueeze(0), p=2).mean()\n",
        "                    loss += -distance\n",
        "                    count += 1\n",
        "\n",
        "        if count == 0:\n",
        "            return torch.tensor(0.0, device=features.device)\n",
        "        return self.lambda_reg * (loss / count)\n",
        "\n",
        "    def update_centroids(self, model, dataset, task_classes, device):\n",
        "        \"\"\"Updates centroids for the new classes using NORMALIZED features.\"\"\"\n",
        "        model.eval()\n",
        "        with torch.no_grad():\n",
        "            for cls in task_classes:\n",
        "                class_dataset = TaskDataset(dataset, [cls])\n",
        "                loader = DataLoader(class_dataset, batch_size=64, shuffle=False)\n",
        "                class_features = []\n",
        "                for inputs, _ in loader:\n",
        "                    inputs = inputs.to(device)\n",
        "                    # *** CRITICAL FIX: Normalize features before averaging to create centroids ***\n",
        "                    features = model.features(inputs)\n",
        "                    normalized_features = F.normalize(features.view(features.size(0), -1), p=2, dim=1)\n",
        "                    class_features.append(normalized_features)\n",
        "\n",
        "                self.class_centroids[cls] = torch.cat(class_features, dim=0).mean(dim=0).detach()\n",
        "        print(f\"Updated centroids. Now tracking: {list(self.class_centroids.keys())}\")\n",
        "\n",
        "# =============================================================================\n",
        "# 4. TRAINING & EVALUATION\n",
        "# =============================================================================\n",
        "\n",
        "def train(model, loader, optimizer, criterion_ce, criterion_inter_cluster, device):\n",
        "    \"\"\"Training loop for one epoch, now handles combined current and replay data.\"\"\"\n",
        "    model.train()\n",
        "    total_loss = 0\n",
        "    for inputs, targets in loader:\n",
        "        inputs, targets = inputs.to(device), targets.to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # We need the raw (non-normalized) features for the classifier\n",
        "        features_raw = model.features(inputs)\n",
        "        outputs = model.classifier(features_raw.view(features_raw.size(0), -1))\n",
        "\n",
        "        loss_ce = criterion_ce(outputs, targets)\n",
        "        # The inter-cluster loss will handle normalization internally\n",
        "        loss_inter = criterion_inter_cluster(features_raw, targets)\n",
        "        loss = loss_ce + loss_inter\n",
        "\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        total_loss += loss.item()\n",
        "\n",
        "    return total_loss / len(loader)\n",
        "\n",
        "def evaluate(model, loader, device):\n",
        "    \"\"\"Evaluation loop.\"\"\"\n",
        "    model.eval()\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    with torch.no_grad():\n",
        "        for inputs, targets in loader:\n",
        "            inputs, targets = inputs.to(device), targets.to(device)\n",
        "            outputs = model(inputs)\n",
        "            _, predicted = torch.max(outputs.data, 1)\n",
        "            total += targets.size(0)\n",
        "            correct += (predicted == targets).sum().item()\n",
        "    return 100 * correct / total\n",
        "\n",
        "# =============================================================================\n",
        "# 5. MAIN SCRIPT\n",
        "# ===================================================="
      ],
      "metadata": {
        "id": "LvN2S_Pyckhi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "    NUM_TASKS = 5\n",
        "    CLASSES_PER_TASK = 2\n",
        "    EPOCHS_PER_TASK = 10\n",
        "    BATCH_SIZE = 32\n",
        "    LEARNING_RATE = 0.001\n",
        "    # *** CRITICAL FIX: Reduced lambda to a more reasonable starting value for a stabilized loss ***\n",
        "    LAMBDA_REG = 10.0\n",
        "    EXEMPLARS_PER_CLASS = 20\n",
        "    DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "    print(f\"Using device: {DEVICE}\")\n",
        "\n",
        "    # --- Data Preparation ---\n",
        "    transform = transforms.Compose([\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
        "    ])\n",
        "    train_dataset = torchvision.datasets.CIFAR10(root='./data', train=True, download=True, transform=transform)\n",
        "    test_dataset = torchvision.datasets.CIFAR10(root='./data', train=False, download=True, transform=transform)\n",
        "\n",
        "    class_order = np.arange(10)\n",
        "    tasks = [class_order[i:i+CLASSES_PER_TASK] for i in range(0, 10, CLASSES_PER_TASK)]\n",
        "\n",
        "    # --- Model and Loss Initialization ---\n",
        "    device = torch.device(DEVICE)\n",
        "    model = ResNet18(num_classes=10).to(device)\n",
        "    criterion_ce = nn.CrossEntropyLoss()\n",
        "    criterion_inter_cluster = InterClusterLoss(lambda_reg=LAMBDA_REG).to(device)\n",
        "    replay_buffer = ReplayBuffer(exemplars_per_class=EXEMPLARS_PER_CLASS)\n",
        "\n",
        "    # --- Continual Learning Loop ---\n",
        "    for task_id, task_classes in enumerate(tasks):\n",
        "        print(f\"\\n--- Training on Task {task_id+1}/{NUM_TASKS} (Classes: {task_classes}) ---\")\n",
        "\n",
        "        current_task_dataset = TaskDataset(train_dataset, task_classes)\n",
        "\n",
        "        if len(replay_buffer) > 0:\n",
        "            combined_dataset = ConcatDataset([current_task_dataset, replay_buffer])\n",
        "            train_loader = DataLoader(combined_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
        "        else:\n",
        "            train_loader = DataLoader(current_task_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
        "\n",
        "        optimizer = optim.Adam(model.parameters(), lr=LEARNING_RATE)\n",
        "\n",
        "        for epoch in range(EPOCHS_PER_TASK):\n",
        "            train_loss = train(model, train_loader, optimizer, criterion_ce, criterion_inter_cluster, device)\n",
        "            print(f\"Epoch {epoch+1}/{EPOCHS_PER_TASK}, Loss: {train_loss:.4f}\")\n",
        "\n",
        "        criterion_inter_cluster.update_centroids(model, train_dataset, task_classes, device)\n",
        "        replay_buffer.add_exemplars(train_dataset, task_classes)\n",
        "        print(f\"Replay buffer size: {len(replay_buffer)} samples\")\n",
        "\n",
        "    # --- Final Evaluation ---\n",
        "    print(\"\\n--- Final Evaluation after all tasks ---\")\n",
        "    accuracies = []\n",
        "    for task_id, task_classes in enumerate(tasks):\n",
        "        test_task_dataset = TaskDataset(test_dataset, task_classes)\n",
        "        test_loader = DataLoader(test_task_dataset, batch_size=BATCH_SIZE, shuffle=False)\n",
        "        acc = evaluate(model, test_loader, device)\n",
        "        print(f\"Accuracy on Task {task_id+1} (Classes {task_classes}): {acc:.2f}%\")\n",
        "        accuracies.append(acc)\n",
        "\n",
        "    average_accuracy = np.mean(accuracies)\n",
        "    print(f\"\\nAverage Accuracy across all tasks: {average_accuracy:.2f}%\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gFIeoaK_cyha",
        "outputId": "f77ff2d5-4492-4178-fa78-8af0b5d2291c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using device: cpu\n",
            "\n",
            "--- Training on Task 1/5 (Classes: [0 1]) ---\n",
            "Epoch 1/10, Loss: 0.3603\n",
            "Epoch 2/10, Loss: 0.2057\n",
            "Epoch 3/10, Loss: 0.1425\n",
            "Epoch 4/10, Loss: 0.1222\n",
            "Epoch 5/10, Loss: 0.1029\n",
            "Epoch 6/10, Loss: 0.0840\n",
            "Epoch 7/10, Loss: 0.0723\n",
            "Epoch 8/10, Loss: 0.0588\n",
            "Epoch 9/10, Loss: 0.0619\n",
            "Epoch 10/10, Loss: 0.0465\n",
            "Updated centroids. Now tracking: [np.int64(0), np.int64(1)]\n",
            "Replay buffer size: 40 samples\n",
            "\n",
            "--- Training on Task 2/5 (Classes: [2 3]) ---\n",
            "Epoch 1/10, Loss: -11.4391\n",
            "Epoch 2/10, Loss: -12.5402\n",
            "Epoch 3/10, Loss: -12.5743\n",
            "Epoch 4/10, Loss: -12.6792\n",
            "Epoch 5/10, Loss: -12.7201\n",
            "Epoch 6/10, Loss: -12.7619\n",
            "Epoch 7/10, Loss: -12.8041\n",
            "Epoch 8/10, Loss: -12.8292\n",
            "Epoch 9/10, Loss: -12.8973\n",
            "Epoch 10/10, Loss: -12.9597\n",
            "Updated centroids. Now tracking: [np.int64(0), np.int64(1), np.int64(2), np.int64(3)]\n",
            "Replay buffer size: 80 samples\n",
            "\n",
            "--- Training on Task 3/5 (Classes: [4 5]) ---\n",
            "Epoch 1/10, Loss: -8.4615\n",
            "Epoch 2/10, Loss: -12.3687\n",
            "Epoch 3/10, Loss: -12.5249\n",
            "Epoch 4/10, Loss: -12.5977\n",
            "Epoch 5/10, Loss: -12.6772\n",
            "Epoch 6/10, Loss: -12.7321\n",
            "Epoch 7/10, Loss: -12.8247\n",
            "Epoch 8/10, Loss: -12.8226\n",
            "Epoch 9/10, Loss: -12.7619\n",
            "Epoch 10/10, Loss: -12.8800\n",
            "Updated centroids. Now tracking: [np.int64(0), np.int64(1), np.int64(2), np.int64(3), np.int64(4), np.int64(5)]\n",
            "Replay buffer size: 120 samples\n",
            "\n",
            "--- Training on Task 4/5 (Classes: [6 7]) ---\n",
            "Epoch 1/10, Loss: -7.7332\n",
            "Epoch 2/10, Loss: -12.4834\n",
            "Epoch 3/10, Loss: -12.6359\n",
            "Epoch 4/10, Loss: -12.7289\n",
            "Epoch 5/10, Loss: -12.7314\n",
            "Epoch 6/10, Loss: -12.7521\n",
            "Epoch 7/10, Loss: -12.8076\n",
            "Epoch 8/10, Loss: -12.7798\n",
            "Epoch 9/10, Loss: -12.8102\n",
            "Epoch 10/10, Loss: -12.8529\n",
            "Updated centroids. Now tracking: [np.int64(0), np.int64(1), np.int64(2), np.int64(3), np.int64(4), np.int64(5), np.int64(6), np.int64(7)]\n",
            "Replay buffer size: 160 samples\n",
            "\n",
            "--- Training on Task 5/5 (Classes: [8 9]) ---\n",
            "Epoch 1/10, Loss: -8.3267\n",
            "Epoch 2/10, Loss: -12.4784\n",
            "Epoch 3/10, Loss: -12.6246\n",
            "Epoch 4/10, Loss: -12.6880\n",
            "Epoch 5/10, Loss: -12.7415\n",
            "Epoch 6/10, Loss: -12.7606\n",
            "Epoch 7/10, Loss: -12.7714\n",
            "Epoch 8/10, Loss: -12.8075\n",
            "Epoch 9/10, Loss: -12.8472\n",
            "Epoch 10/10, Loss: -12.8616\n",
            "Updated centroids. Now tracking: [np.int64(0), np.int64(1), np.int64(2), np.int64(3), np.int64(4), np.int64(5), np.int64(6), np.int64(7), np.int64(8), np.int64(9)]\n",
            "Replay buffer size: 200 samples\n",
            "\n",
            "--- Final Evaluation after all tasks ---\n",
            "Accuracy on Task 1 (Classes [0 1]): 0.00%\n",
            "Accuracy on Task 2 (Classes [2 3]): 4.05%\n",
            "Accuracy on Task 3 (Classes [4 5]): 0.30%\n",
            "Accuracy on Task 4 (Classes [6 7]): 0.00%\n",
            "Accuracy on Task 5 (Classes [8 9]): 90.60%\n",
            "\n",
            "Average Accuracy across all tasks: 18.99%\n"
          ]
        }
      ]
    }
  ]
}